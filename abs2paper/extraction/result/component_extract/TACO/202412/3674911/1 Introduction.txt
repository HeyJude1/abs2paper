1 Introduction
The sparse triangular solve (SpTRSV) is one of the most important kernels in the field of sparse matrix computation and plays an indispensable role in many numerical algorithms, e.g., the preconditioners of sparse iterative solvers . It is widely used in various scientific applications, such as computational fluid dynamics (CFD) , machine learning , and graph algorithms . SpTRSV solves a linear system Ax = b, where A is a sparse lower/upper triangular matrix, b is the right-hand side vector, and x is the solution. Compared with other well-known linear algebra routines, such as sparse matrix-vector multiplication (SpMV) , sparse matrix-matrix multiplication (SpMM) , and sparse matrix transposition , SpTRSV faces more difficulties in parallelization due to its internal data dependencies.
Graphics processing units (GPUs) are capable of processing floating point operations at extreme rates and have become one of the most widely used accelerators in the field of scientific computing. However, it is challenging to implement an efficient SpTRSV kernel on GPUs. Difficulties can be summarized as follows:
-Low parallelism and high synchronization overhead. SpTRSV has a sequential nature due to dependencies, making it difficult to exploit the parallelism. Synchronizations are involved with such data dependencies. Due to the complex synchronization mechanisms of GPUs, a meticulous design is required. -Complex task partitioning and scheduling. The irregular and sparse data distribution significantly impacts performance, which is similar to many other sparse matrix kernels. Any task partitioning or scheduling potentially changes the data dependencies in the solution. Thus, determining the appropriate strategies is extremely challenging. -Input sensitivity. The sparse patterns of input matrices vary significantly across different application scenarios. There is no "one-for-all"solution, which requires heavy and tedious manual efforts of algorithm redesigning and parameter fine-tuning. To exploit the parallelism of SpTRSV, the level-set method (also known as wavefront parallelization) proposes to partition the solution into multiple levels with no internal dependencies. Synchronization is only involved for inter-level dependencies. However, it cannot be directly applied on GPUs as the global synchronization involves excessive overhead. Considering the hardware characteristics of GPUs, the "synchronization-free" methods use fine-grained pointto-point communication to resolve data dependencies, specifically with in-memory data exchange and atomic operations. Simultaneously, different levels of parallelism can be exploited, including warp-level , thread-level , and adaptive heuristics . Furthermore, the parallel libraries by vendors such as cuSPARSE provide well-optimized implementations of SpTRSV on GPUs.
Despite the fact that existing implementations perform well on certain matrices, they fail to consistently achieve good performance on matrices with various sparsity patterns due to the dedicated algorithm design and the lack of adaptability. Here, we test and compare the performance of the state-of-the-art implementations on GPUs, including the Compressed Sparse Column (CSC)-based synchronization-free method (Sync-free for short), YuenyeungSpTRSV AG-SpTRSV: An Automatic Framework to Optimize Sparse Triangular Solve on GPUs 70:3 (YYSpTRSV for short), and SpTRSV solve in the NVIDIA cuSPARSE library (cuSPARSE for short). Test matrices are derived from applications in various fields (detailed information is listed in Table ). As is shown in Figure , the three implementations exhibit performance advantages on matrices with different sparsity patterns. For example, YYSpTRSV performs well on matrices with high parallelism, whereas Sync-free is more suitable for matrices with low parallelism. However, none of them can consistently achieve high performance across all the test cases. Moreover, significant performance gaps can be observed in a single test case. To fully optimize the performance of SpTRSV on GPUs, we argue that a more comprehensive design is expected, which addresses the performance bottlenecks introduced by irregular data distribution and data dependencies while adaptively dealing with diverse sparsity patterns of different matrices.
In this article, we first measure and characterize the performance of SpTRSV. We derive several observations that provide guidance for the design of the optimization space. Based on these observations, we propose AG-SpTRSV, an automatic framework to optimize SpTRSV on GPUs. AG-SpTRSV consists of four stages. In the Prepare stage, AG-SpTRSV prepares a series of code variants based on a unified template that support dynamic fine-grained parallelism and enable code optimizations under specific conditions. In the Transform stage, the original computation graph is transformed into candidate graphs with merging and reordering operations. In the Schedule stage, the tasks in candidate graphs are mapped to the hardware through multi-hierarchy heuristic strategies. We refer to the entire process of code variant preparation, graph transformation, and scheduling as a scheme. In the Select stage, AG-SpTRSV finds the scheme with the best expected performance, with either exhaustive search or a learned lightweight model. AG-SpTRSV outperforms state-of-the-art SpTRSV implementations on GPUs and achieves good performance across matrices with various sparsity paterns.
The contributions of this article can be summarized as follows.
-We characterize the performance of GPU-based SpTRSV through experimental measurements and derive several observations that help with performance optimization. -We represent the optimization space of SpTRSV as the scheme, which considers dynamic parallelism, adaptive code optimization, computation graph transformation, and scheduling. We design a series of strategies to construct a comprehensive space that accommodates inputs with various sparsity patterns. -We propose AG-SpTRSV, an automatic framework to optimize GPU-based SpTRSV, which generates a series of schemes for execution and searches for the best. We also adopt a lightweight model based on historical results to reduce search costs. -Experimental results on NVIDIA Tesla A100 and RTX 3080Ti show that AG-SpTRSV is able to outperform the state-of-the-art SpTRSV implementations, including Sync-free,  YYSpTRSV and cuSPARSE, with geometric average speedups of 2.12x âˆ¼ 3.99x. With the proposed performance model, the preprocessing time of AG-SpTRSV ranges from 3.4 to 245 times of the execution time. -The source code of AG-SpTRSV is available at https://github.com/USTC-ADA/AG-SpTRSV.git.