7 Related Work
As far as we know, this is the first work to introduce a core power state that provides both low transition/cold-start latency and low power consumption. While low server efficiency for latencycritical workloads has been studied before, previous work proposed management and scheduling techniques to mitigate the problem.
Modern Cloud Applications . Interactive latency-sensitive cloud applications are gradually shifting to a modular architecture based on loosely coupled microservices to meet their software maintenance, scalability, and availability requirements . However, the decoupled nature of microservices exacerbates the strict tail latency requirements of such applications. Recent work that characterizes microservices at Alibaba clusters shows that a user request relies on multiple microservices, whose individual times can accumulate into significant end-to-end latency. The same Alibaba study reveals that servers running latency-sensitive microservices operate at 10% utilization to keep the tail under control. This aligns with works from industry and academia that report the utilization of latency-sensitive applications to be 5% -20% . Servers at low utilization have poor energy efficiency, partly because they disable deep C-states to avoid several microsecond penalty of transitioning out of such deep C-states . This emphasizes the need for deep C-states with low transition latency and high power savings.
Fine-Grained, Latency-Aware DVFS Management . Besides C-states, the other major power management feature of modern processors is DVFS. Previous work proposes fine-grained DVFS control to save power while avoiding excessive latency degradation. Rubik scales core frequency at the sub-millisecond scale based on a statistical performance model to save power while meeting a target tail latency. Swan extends this idea to computational sprinting (e.g., Intel Turbo Boost ): requests are initially served on a core operating at low frequency, and depending on the load, Swan scales up the frequency (including sprinting levels) to catch up and meet latency requirements. The new C6Awarm state of AW facilitates the effective use of idle states and could make a simple race-to-halt approach more attractive than complex DVFS management techniques.
Workload-Aware Idle State Management . Various proposals exist for techniques that profile incoming request streams and use that information to improve power management. SleepScale is a runtime power management technique that selects the most efficient C-state and DVFS setting for a given QoS constraint based on workload profiling information. CARB packs requests into a subset of cores, while limiting latency degradation, so that the other cores have longer quiet times and can transition to deeper C-states. The idea of packing requests into a subset of active cores to extend idle periods on other cores is explored by works focusing on both C-states and DVFS management . These proposals are orthogonal to AW: while C6Awarm can provide most of the benefits of a deep idle state at lower latency, advanced and workload-aware sleep management techniques can bring extra power savings by enabling cores and/or system to enter traditional deeper C-states for a longer time . Memory power management techniques have also been proposed to reduce system energy consumption and are complementary to our work.
Cold-Start Latency . The performance effects of the alteration of the microarchitectural state between active periods of an application has been studied either through core migration or power gating . In Lukewarm, Schall et al. noticed that the microarchitectural state of the core changes between invocations of the same function increasing the CPI. They identified the L1I cache as the main contributor and proposed an instruction prefetcher to speed up the warm-up time. Another study investigated various factors (i.e., migration frequency) impacting the warm-up time of a recently migrated thread/process. According to their findings, for the warm-up time to reduce, the core must maintain the predictor state of the recently migrated thread/process, caches should be coherent between active and inactive cores, and migration should occur at most every 160K cycles. AW agrees with prior works indicating that cold-start latency affects performance in some scenarios. Additionally, it introduces a solution integrated into the C-state architecture that reduces cold-start latency with minimal impact on power, performance, and area.