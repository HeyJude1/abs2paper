9 Conclusion
In this article, we presented LO-SpMM , a framework designed to efficiently generate highperformance SpMM implementations for sparse DNNs on GPUs. LO-SpMM employs a hierarchical 2-dimensional tiling strategy to define the search space for optimal tile sizes, and utilizes a set of constraints and a rank model to effectively prune the search space. Based on the architecture of GPUs and the structure of SpMM implementations, LO-SpMM creates proxies for efficiently evaluating code variants. It considerably diminishes the evaluation cost, accelerating the overall process of producing the optimal SpMM implementation. Furthermore, by reordering the sparse matrix involved in SpMM, LO-SpMM improves the performance of generated SpMM implementations. Compared with the state-of-the-art tensor compilers, our approach can reduce the search time by 281Ã—