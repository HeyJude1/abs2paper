4 Sparse Matrix Reordering
Unstructured pruning on a DNN leads to a non-uniform distribution of nonzero elements within its weight matrices. This distribution is ill-suited to GPUs, resulting in imbalanced computational loads across different tiles and increased memory access overhead. Reordering the nonzero elements in the sparse matrix can yield a distribution better optimized for SpMM kernel performance.
In this section, we introduce the motivation for our reordering algorithm, along with the problem formulation and the corresponding algorithm for sparse matrix reordering. The effectiveness of the algorithm is demonstrated through an illustrative example.
4.1 Motivation
The memory access overhead has an important impact on the performance of the kernel. For example, assume an SpMM kernel with dimensions (M, K, N ) = (128, 2048, 128) executed on an RTX 2080Ti. To avoid the influence of other factors on the performance, this kernel is launched within a single thread block by setting the tile size to (128, 128). We evaluate the performance of SpMM with different numbers of non-empty columns (nnc) while fixing the number of non-zero elements (nnz) to 2,048, 3,072, and 4,096, respectively. It is noteworthy that there is a positive correlation between nnc and memory access load because nnc reflects the frequency of accesses to the dense matrix B per thread. As illustrated in Figure , the runtime escalates with an increase in memory access overhead for a fixed nnz. The analysis reveals a performance divergence of up to 10.99× across different memory access overhead under identical computational demands. Since the SpMM kernel is memory-bound, variations in nnz within a tile in this example have negligible impact on the performance of the SpMM kernel. Row reordering of the sparse matrix can reduce memory access overhead while maintaining load balancing, as illustrated in Figure . In this example, each thread computes 4 × 1 output elements, and each thread block computes 4 × 4 output elements. As shown in Figure (a), the sparse matrix A is partitioned into two A tile , with rows 0 − 3 assigned to the first A tile and rows 4 − 7 assigned to the second A tile . The nnc in each A tile is 8, resulting in 8 memory accesses per thread to fetch the corresponding elements of the dense matrix B into registers. To reduce memory accesses per  tile, the sparse matrix can be reordered by grouping rows with similar distributions of non-empty columns within each A tile . This approach reduces the nnc in each A tile , thereby decreasing the number of memory accesses per thread. Figure (b) demonstrates this optimization, which assigns rows 0 − 1 and 4 − 5 to the first A tile , and rows 2 − 3 and 6 − 7 to the second A tile . It reduces the nnc in each A tile to 5. Consequently, each thread performs only 5 memory accesses.
4.2 Problem Formulation and Algorithm
Given a tile size (M1, N 1), sparse matrix reordering solves a constrained optimization problem. Its objective is to reduce the maximum number of memory accesses in all A tile while maintaining load balancing among all A tile . This objective can be formulated as follows: arg min
SA t il e max(nnc(SA tile )), (2)
subject to max(size(SA tile )) ≤ M1, (3)
nnz imbalance o f SA tile < α, (4)
where SA tile is a set of A tile . The size of A tile is limited by M1 so that all threads are constrained to have a close number of registers and write operators.
Regarding each row as a node and each column as a hyperedge, this problem can be transformed into a constrained hypergraph partitioning problem. The goal of this problem is to minimize the maximum number of hyperedges across all subgraphs while ensuring that the total number of nodes across all hyperedges is similar in each subgraph. This is an NP-hard problem. Therefore, we propose Algorithm 1 to solve this problem approximately. First, we count the number of nonzero elements in the whole sparse matrix and in each row, denoted by nnz_matrix, and nnzs_row, respectively (lines 1-2). Then we sort rows in the sparse matrix by nnzs_row and remove empty rows (lines 3-4). The sparse matrix rows are processed in ascending nnzs_row order. For each row, we merge it with each A tile and sort the TSA tile by the nnc in A tile (lines 9-10). We start with the A tile which has the smallest nnc and is smaller than M1 in size. If the nnz in A tile does not exceed the nnz limitation (T H nnz ), this row is assigned to this A tile . Otherwise, we choose the next A tile to judge. If the nnz of all unfilled A tile is larger than the limitation, then we assign this row to the A tile with the smallest nnc (lines 12-22). In the reordering process, the nnz in each A tile is limited to make nnz among different A tile close, so as to achieve computational load balancing.
73:10 J. Lin et al.
4.3 Effectiveness of Sparse Matrix Reordering
To evaluate the effectiveness of Algorithm 1, we constructed a comparative analysis of the performance of SpMM implementations under three scenarios: without sparse matrix reordering, using a hypergraph partitioning method, and using our proposed method. In the hypergraph partitioning method, rows and columns are treated as nodes and hyperedges, respectively, with node weights set to the nnz in the row to ensure computation load balancing. Then we use Kahypar to optimize the connectivity objective. Assume an SpMM kernel is of shape (M, N , K) = (1,024, 1,024, 1,024) and sparsity 98%. It is divided into 32 blocks by row, and each block has 32 rows. The similarity R between two blocks is denoted by the ratio of identical nonzero element positions in the two blocks. The R in paired blocks (block i and block i+16 , i ∈ {0, 1, . . . , 15}) varies from 0 to 0.9 to show the effect of similarity on these methods. Meanwhile, to show the impact of load balancing, the nnz ratio in adjacent blocks (block i and block i+1 , i ∈ {0, 2, . . . , 30}) varies from 1 to 3.
As shown in Figure , with balanced load, as R increases, the runtime of the SpMM implementation tends to decrease with sparse matrix reordering and remains the same runtime without sparse matrix reordering. As the similarity of the sparse matrix increases, the memory access similarity of each block becomes higher after reordering, enabling fewer memory accesses per block. Moreover, the hypergraph partitioning method produces tiles with variable numbers of non-empty rows and columns when the nnz distribution per block is uneven, causing imbalanced memory access loads among thread blocks. In contrast, our method achieves more effective balance in memory access loads.