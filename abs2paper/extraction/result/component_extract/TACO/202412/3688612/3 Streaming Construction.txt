3 Streaming Construction
To achieve streaming memory accesses, we propose a novel preprocessing scheme to reconstruct the input dense and sparse matrices.
3.1 Streaming Construction for the Dense Matrix
Figure (a) shows the limitations of the conventional access pattern. We assume that each fiber of A contains two non-zeros, meaning that each scalar-vector intersection takes two clock cycles with pipelined float point units (FPUs). The matrix B is shown in transposed form and accessed by two 128-bit (4 floating-point elements) memory channels. During cycle 1, four elements are transferred to the PE-0 and PE-4 using channel-1 and channel-2, respectively. In the next cycle, the 2nd and 6th columns of B are traversed, presenting a poor spatial locality. Moreover, this pattern limits PE utilization because half of the PEs remain idle while the other half is overloaded during cycle 2. Increasing bandwidth can alleviate this issue but may lead to lower bandwidth utilization.
To this end, we propose two optimization strategies to reconstruct dense matrices to achieve more efficient memory accesses. Strategy 1: Row-major traversal and matrix partitioning: We first adopt the row-major storage for B, allowing the architecture to traverse and distribute elements to the PEs. We then partition each B row into segments with a length of #PE (the number of PEs) and store each block with a dimension of K × #PE in consecutive address spaces. Doing so can ensure a better spatial locality when performing computations on the blocks of B. In Figure (b), during cycles 1 and 2, the elements in the first row are evenly distributed to all PEs with a single memory channel. This access pattern enables streaming access to blocks of B as all rows are sequentially traversed and alleviates the idle PE issue by feeding each PE with at most one element in one clock cycle. In implementation, we also adopt this strategy when writing the matrix C, which means C will be stored in the same form as B. This improves the spatial locality in the writing phase, and C can be directly applied as an operand in consecutive SpMMs. More details will be introduced in Section 4.1.4. Strategy 2: c-cycle delayed feeding: In the column-wise approach, each element of B participates in a scalar-vector product A[∶, rid] ⋅ B[rid, i]. Thus, the minimum required cycle is equal to the number of non-zeros in A[∶, rid] (assuming each PE employs one multiplier). Figure shows that each scalar-vector product takes two cycles, enabling feeding one B element to each PE every two cycles while maintaining high PE utilization. Therefore, we introduce a delay parameter, c, and propose a c-cycle delayed feeding strategy to allow for feeding each PE with one B[rid, i] every c + 1 cycles. Figure presents the 1-cycle delayed strategy, where each PE is fed with one element per two cycles. This strategy significantly reduces the bandwidth budget for accessing B and achieves high bandwidth utilization. Note that it is an aggressive optimization method because a larger c value enables a smaller bandwidth requirement but increases the risk of performance degradation. Further analysis will be detailed in Section 4.2.
3.2 Streaming Construction for the Sparse Matrix
CSC and CSR are commonly adopted for storing sparse matrices. Figure (a) shows that both formats use idx and val arrays to hold the positions and values of non-zeros, respectively, and use a pointer array, ptr, to indicate the start address of each column/row. We argue that the traditional processing dataflow has three issues. (1) It adopts burst transfer to access A fibers without delay, but this method is less efficient than streaming access. (2) It requires additional control logic to separate the A fibers and complete the computation of a C row; (3) It can incur RAW conflicts. Figure (a) presents a sparse A as an example. The first fiber will be multiplied with B[0, i] to 79:10 X. Lu et al. produce a partial column containing two non-zeros of a ⋅ B[0, i] and b ⋅ B[0, i]. The two partial results will be accumulated according to their row-ids, i.e., 0 and 3, which are determined by a and b. Similarly, multiplying B[2, i] with A[∶, 2] produces partial elements with row-ids of 0, 1, and 3. Since FPUs require multiple clock cycles for floating-point additions, two accumulation operations with the same row-id may incur an RAW conflict. Assuming a RAW dependence distance of d, the distance between two A non-zeros with the same row-id must not be less than d.
The streaming construction scheme tackles these challenges by incorporating a novel storage format, which introduces three control elements. control element 1 -Rest: The proposed format discards the ptr array and instead inserts a Rest element with row-id −1 into the idx array (correspondingly insert 0 into the val array) at the end of a fiber. In Figure (b), we insert four Rest elements after the element-b, -e and -g. Continuous occurrences of two Rest indicate a fiber without non-zeros. In this case, the accelerator can access idx and val in a streaming fashion, and identify the end of each fiber from the streaming data without additional control logic. control element 2 -Padding: The RAW conflicts occur when the distance between two nonzeros with the same row-id is less than d. We insert Padding elements between the conflicting non-zeros to increase the distance. Assuming d = 5, streaming construction traverses the idx array and checks whether each element conflicts with its following five elements, then inserts several Padding elements (row-id −2 and value 0) before the conflicting element once a conflict is detected (lines 21 to 23 in Algorithm 1). Figure (b) shows streaming construction first detects a conflict between element-a and element-c and then inserts a Padding before element-c. Similarly, we insert a Padding before element-f to avoid RAW conflicts with element-c. control element 3 -Blocking: As discussed in Section 2.2.4, the column-wise approach needs to hold the partial sums with size of K on-chip. However, practical applications may involve largescale sparse matrices, leading to a large on-chip memory requirement. Therefore, we introduce Block with row-id −3 and value 0 to partitioned multiplicand A into several sub-matrices, tightening the on-chip memory budget.
Algorithm 1 provides a detailed implementation of streaming construction for sparse matrices. We prioritize the insertion of Rest (line 3) and Block (line 8) elements, as both can increase the distance between non-zeros, reducing the number of Padding elements inserted in line 16.