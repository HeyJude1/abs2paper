1 Introduction
Graph-based services provide an efficient solution for managing the continually growing largescale applications in both industry and academia , for which the quality of service (QoS) is essential. A graph encompasses a series of properties used to describe throughput, response time, and other relevant metrics.
As the graph scale (i.e., the number of vertices and edges) explosively grows, large-scale graphs need distributed machines to store and handle. For instance, the Sogou graph contains 271.8 billion vertices and 12.3 trillion edges that need 38,656 nodes during testing ; the 155.25K-node Fugaku supercomputer conducts breadth-first search (BFS) on a Kronecker graph at scale=42 (having 4.4 trillion vertices and 70.4 trillion edges ). No single machine can accommodate and process such big graphs. As such, many real-world and mimic graphs need distributed machines to store and handle them.
While graphs show promise as applications on distributed systems at scale ] and provide high QoS for many supercomputing users , current graph processing systems often prioritize one aspect of QoS: high throughput, which refers to the processing speed of graph algorithms, also known as graph operators. However, such criteria do not always address the bottleneck factors that affect the performance of service-oriented graph applications. This is because the complete graph-based service comprises both the graph operator and the graph constructor. Indeed, the graph construction time is usually orders of magnitude higher than the processing time on graph operators. That is primarily because all state-of-the-art graph engines compete in the throughput of graph algorithms and take the processing speed of the graph operators as the sole criterion for graph applications. While this assertion might hold for standard graph processing on small-sized high-performance computing (HPC) systems, typically involving at most tens of computing nodes, it does not necessarily apply to distributed graph processing at scale.
In large-scale graph processing, graph construction is often a must, as shown in Figure . Graph processing typically involves four stages: (i) loading the graph, during which real-world graphs or synthetic graphs are handled by a graph constructor; (ii) graph preprocessing; (iii) graph construction, which mainly includes graph partition and graph storage; and (iv) graph application. During the preprocessing stage, various tasks are performed, such as counting degrees and sorting graphs . For the graph construction stage, vertices and edges are distributed into many computing nodes by using an advanced graph partitioning algorithm (known as a partitioner) such as XTree and stored based on a specified format such as the compressed sparse row (CSR) or its variants . Finally, the constructed graphs are passed into graph processing algorithms such as BFS , single-source shortest path (SSSP) , connected component (CC) , PageRank (PR) , and community detection with label propagation (CDLP) . To provide user-friendly graphic services, we take QoS as the total cost (i.e., Θ) of four graph processing stages for distributed graph applications. Θ(QoS) is a lower-is-better metric for large-scale graph applications on HPC systems. Θ(QoS) = τ g + τ c + τ pre + τ loadinд Herein, τ g represents the processing time of graph operators, which determines the throughput. τ c represents the processing time of graph construction that can affect the throughput of the graph operators. τ pre and τ loadinд are the preprocessing time and loading time of the graph, respectively. Since τ pre can be parallelled in advance and τ loadinд can be processed offline, we can approximate Θ(QoS) as follows.
Θ(QoS) ≈ τ g + τ c
(2)
GraphService: Topology-aware Constructor for Large-scale Graph Applications 2:3 Fig. . A typical graph processing pipeline.
According to Equation , when processing large-scale graphs on HPC systems, the QoS of distributed graph applications encompasses two aspects, not just throughput. Further, τ c is the bottleneck of the Θ(QoS) because it is often 3 ∼ 5 orders of magnitude higher than τ g . In detail, communication costs within τ c exceed 80% due to significant variability among different computing nodes . This trend is expected to become even more pronounced with the increase of computing nodes.
The success of large-scale graph processing systems heavily relies on efficient partitioning algorithms and communication optimization techniques . As such, various graph partitioning strategies have been proposed . Indeed, all graph processing systems utilize some form of graph partitioning to take advantage of the sparsity of the graph data to distribute vertices and edges across computing nodes . However, current advancements in large-scale graph engines have focused on achieving excellent throughput, often at the cost of longer construction times . A key reason is that these engines assume consistent communication overhead between any two nodes. While this assumption may be true for small-sized HPC systems , it is not the case for processing big graphs at scale. Recent approaches utilize fine-grained partitioning techniques to exploit graph operators and leverage graph-specific attributes such as vertex distribution to mitigate communication overhead. While important, they only consider the graph-based topologies at best, such as sparsity, and ignore the communication hierarchy of the target HPC system, which severely hampers the graph construction. Although GraphCube takes both the sparsity of the graph and the communication hierarchies into account, it is basically exploited to expedite graph traversal. In contrast, GraphService dedicates to leveraging hierarchical communication domains (in terms of a group of computing nodes attached to the same routing cell ) to accelerate graph construction before graph operations (e.g., traversal) ingress. As we will show in this article, state-of-the-art graph processing systems, such as Fugaku and the Wuhan supercomputer , struggle with rapid graph construction.
To tackle this problem, we introduce GraphService, which is specifically designed to optimize graph construction in order to minimize the overall online processing time rather than solely concentrating on graph operators. The key idea of GraphService is to (i) develop a hierarchy-aware partitioner that leverages the communication topology of target HPC systems to minimize communication costs and (ii) provide a space-time-efficient graph compression by grouping identicaldegree vertices, enabling batch memory access for fast graph construction based on graph topology, where many graph vertices have the same degree .
We evaluate GraphService by applying it to representative graph operations across three different HPC systems with varying scales, using up to 79,024 nodes and over 1.2 million processor cores.  We show that GraphService consistently outperforms state-of-the-art graph partitioning methods, CSR-like formats, and graph systems on different graph scales and hardware setups. Specifically, GraphService achieves 162,494 and 23,021 giga-traversed edges per second (GTEPS), respectively, for BFS and SSSP according to the Graph500 specification . These results can be translated to 1.17× and 1.50× improvements, with three orders of magnitude construction time reduction for BFS and SSSP, respectively, compared with the top-ranked systems on the latest Graph500 ranking (November 2023). We also test GraphService on real-world graphs, for which it outperforms three state-of-the-art graph processing engines, Gemini , Gluon , and Graph-Scope , with a speedup of up to 18.9×.
Conference extension.
A preliminary version of this article "GraphCube: Interconnection Hierarchy-aware Graph Processing" by Gan et al. appeared at the 29th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming (PPoPP), 2024 . This extended version makes the following new contributions to the conference paper, providing new insights based on the original paper.
-We extend our approach to support large-scale graph construction, demonstrating the generality and performance advantages over prior approaches (Section 5.2). -We explore a space-time-efficient graph compression to store and index identical-degree vertices, which not only allows for batching and coalescing memory accesses for further boosting graph construction but also reduces memory footprint (Section 5.5). -We conduct extensive experiments to demonstrate the effectiveness and efficiency of Graph-Service. More specially, GraphService achieved the top position in the Graph500 ranking, utilizing up to 77.2K nodes with 17% higher throughput and more than 1,218× reduction in construction time.