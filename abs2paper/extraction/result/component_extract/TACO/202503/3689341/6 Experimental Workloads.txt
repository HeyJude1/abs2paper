6 Experimental Workloads
Our main evaluation is performed on the BFS algorithm defined in the Graph500 benchmark . Graph500 is the de facto standard for assessing a computer system's capability for graph processing . It provides a graph generator to generate synthetic graphs that mimic real-world graph structures. This tool takes two parameters, a graph factor, and an edдe_f actor. Given a graph size m and an edдe_f actor n, it generates a graph (i.e., Kron −m) of 2 m vertices and n × 2 m edges. Unless stated otherwise, we use the Graph500 default edдe_f actor of 16. For our evaluation, we vary the graph factor between 26 and 41 to generate graphs of different scales for testing our approach on various hardware setups. Table lists the synthetic graphs and real-world graphs used in our evaluation.
2:16 X. Gan In addition to the synthetic graph data generated by Graph500, we also evaluate GraphService on two public real-world graphs , including clueweb12 (with 987 million vertices and 42.6 billion edges) , and twitter-2010 (with 41.7 million vertices and 1.47 billion edges) . We also assess other graph processing operations on these datasets, including SSSP, PR, CC, BC, and TC.
6.2 Evaluation Platforms
To evaluate the portability of GraphService, we apply it to three cutting-edge systems with different CPU architectures using 512 nodes to 79,024 nodes. Table lists the three HPC systems used in our testing and the maximum number of computing nodes. Each node on the WuzhenLight has two HG2 32-core CPUs at 2.5 GHz that are compatible with the AMD x64 instruction set. Each node on Tianhe-Exa has a Phytium 16-core CPU at 2.0 GHz. The last one is configured with a 512-node Intel Xeon CPU at 2.93 GHz. These three systems run a customized Linux operating system with Linux kernel v9.3.0. We use MPICH 10.2.0 for the MPI and libgomp 4.5 for OpenMP and compile the benchmark using GCC 10.2.0 with "-O3" as the compiler option.
6.3 Competing Baselines
We compare GraphService to five representative graph partitioners: 2D decomposition , LDG , Par-METIS (the parallel version of METIS ), CLUGP , and TopoX for validating the communication hierarchy-aware partitioner. Moreover, we compare GraphService to six state-of-the-art sparse storage formats: native CSR, DCSR , COO (Coordinate list) , CSCSR (Coarse index + Skip list) , BCSR (Bitmap-based sparse matrix representation) , and CSR5 . We also compare GraphService against Gemini and Graph-Scope , two state-of-the-art graph processing engines, using the engineer-tuned algorithm implementations provided by these frameworks.
6.4 Benchmarking Graph500
We deployed the full implementation of GraphService to benchmark Graph500 BFS and SSSP on Tianhe-Exa. In our experiments, we used 79,024 computing nodes (1,264,384 cores) for BFS and 8,192 nodes (131,072 cores) for SSSP. Our implementation and evaluation fully comply with the Graph500 specification.
The latest Graph500 ranking, published in November 2023, places Fugaku and Wuhan Supercomputer as the top performers for BFS and SSSP, respectively. However, GraphService on Tianhe-Exa successfully outperforms these top-ranking systems for both benchmarks with three orders of magnitude lower construction time, as listed in Table . This notable improvement can be attributed to the communication hierarchy-aware partitioner and space-time-efficient graph compression techniques integrated into GraphService, which significantly enhances the performance of BFS and SSSP.
6.5 Compare with Baseline Partitioners
Figure reports the time spent on constructing the graph. Generally, as the size of the graph and the number of computing nodes increases, the construction time also grows. However, we observe that GraphService has the lowest overhead compared with other baselines. In contrast, LDG, which GraphService: Topology-aware Constructor for Large-scale Graph Applications 2:17  Fig. . BFS throughput given by different partitioners (higher is better).
requires significant refactoring of the input graph, incurs 4, 971.83× longer construction time with the 4,096-node available on Tianhe-Exa than that of GraphService. Note that (i) ParMETIS is a general partitioner without taking the structure of the graph into account, resulting in poor performance in processing large-scale graphs. (ii) More importantly, communication time will become the main bottleneck of the graph processing but existing partitioners (such as ParMETIS) fail to exploit communication hierarchies at large scales, which suggests that developing a topology-aware GraphService is crucial to scale graph processing. Figure compares the throughput of GraphService to five graph partitioning methods. The experiment used up to 4,096 Tianhe-Exa nodes to execute BFS. Some methods led to a runtime error (marked as X). GraphService outperforms all baselines, particularly as the number of computing nodes increases. For instance, when processing a graph scale of 38 using 4,096 Tianhe-Exa nodes, GraphService delivers 33,490.17 GTEPS, 9.7× and 28.7× improvements over TopoX and CLUGP, respectively. We also obtain similar results on SSSP, PR, CC, and CDLP, where GraphService respectively gives 27.2×, 29.1×, 25.6×, and 19.7× throughput improvements over the bestperforming baseline when using 4,096 Tianhe-Exa nodes. This is because GraphService significantly enhances graph distribution, making subsequent communication during graph computation more regular and expediting graph tasks. Note that, while GraphService is motivated by Fat-tree, the underlying methodologies of our work have been generalized across different interconnect topologies, such as 3-D Torus, and Dragonfly. Both are respectively equipped in WuzhenLight and Intel Cluster, and evaluated using GraphService.  × 100%, M(X) represents the memory cost of format X (i.e., CSR or GraphService).
6.6 Tuning Thr for Graph Compression
In this subsection, we will take the real-world graphs, including clubweb12 and twitter2010, to examine the impact of the hyperparameter Thr on the performance of GraphService. In addition, by digging deeper, we demonstrate how to further fine-tune the Thr for fast graph The selection policy for Thr should be highly based on the graph's vertex distribution. As we show in Figure , low-degree vertices account for a high fraction in the real-world graphs, whereas DCSR-mentioned hypersparse graphs are uncommon. Thus, our insight is to make Thr cover most of the low-degree vertices. For example, vertices with deдree ∈ hold more than 78% for the provided real-world graphs (see Figure ). We highly recommend users set up their own Thr range and evaluate the sensibility of Thr across different scales of graphs according to the graph degrees' distribution as shown in Figure .
We evaluate the GraphService's performance by carefully tuning the Thr ∈ {10, 15, 20, 25}. We also list the results of Thr ≤ 9 (see Figure ) to prove that based on the degree distribution in Figure , every increase in Thr brings obvious benefits, and the overall yield is linear. On the other hand, Figure shows that when Thr > 9, further changes in Thr have little effect on its performance with the same graph. The largest performance gap would be around 5% when we conduct different Thr on clueweb12 and twitter2010. So far, we may draw the following conclusions.
(i) Majorities of the graphs have a large scale of N-degree vertices, such that N ≤ 10. In this case, Thr = 9 gains significant benefits. It is strongly recommended that, prior to the meticulous adjustment of the Thr, researchers should refer to the graph's degree distribution. (ii) Although a larger Thr may give a better GraphService performance, GraphService is overall Thr-oblivious when Thr > 10.
6.7 Preprocessing Overhead
Owing to requiring a sorted graph as input, GraphService includes a built-in sorting module configured to accommodate various types of input graphs without the need for manual sorting beforehand. Next, GraphService performs a further reindexing of each vertex by incorporating the RST and COL array, which incurs preprocessing overhead. This preprocessing is a one-off cost and employed by many famous graph systems . Experiments show that the overhead of GraphService preprocessing will get slightly higher but still acceptable when the graph gets bigger (2.07 s while scaling to 512 nodes). We have noticed that many great works of vertex sorting in graph-parallel processing systems have been provided, such as . GraphService is developed for better servicing graph applications and can be integrated seamlessly with existing graph preprocessing approaches, potentially gaining additional benefits from them.
6.8 Compare with Other Sparse Storage Formats
Figure (a) reports the memory footprint comparison across different sparse formats for BFS. GraphService outperforms all the other CSR-like formats, saving more than 90% memory space over most of the CSRs, especially up to 99.8% of space against the CSCSR. We also evaluate GraphService on a real-world social graph clueweb12 and report both the memory usage and runtime of BFS in Figure . Figure shows that GraphService has the smallest memory cost over other storage formats (saving average memory). In Figure , GraphService also shows the fastest runtime against others (yielding average runtime speedup).
6.9 Scalability
In this section, we evaluate the scalability of GraphService by applying it to BFS running with different numbers of nodes on Tianhe-Exa , WuzhenLight [4], and Intel cluster listed in Table . Figure reports how the normalized GTEPS changes as we increase the number of computing nodes, with one single node serving as the normalization baseline. We observe a consistent increase in GTEPS for GraphService as the number of computing nodes increases, suggesting that GraphService-based BFS exhibits good scalability.
6.10 GraphService for Real-World Graphs
We conduct experiments with GraphService on large real-world graphs using 64 Tianhe-Exa nodes across four communication domains. Figure compares GraphService with Gemini and GraphScope, both of which offer engineer-optimized implementations for the test algorithms. Gemini could not execute some test cases (marked as X) and does not support CDLP. GraphService's partitioning approach leads to shorter preprocessing times than Gemini and GraphScope, 2:20 X. Gan  which need graph repartitioning for load balancing . GraphService consistently outperforms Gemini and GraphScope in all test cases during the graph computation stage, achieving a speedup of up to 18.92× over GraphScope.