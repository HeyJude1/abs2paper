5 Methodology
5.1 Overview of GraphService
GraphService is designed to build an ultra-fast graph constructor before the kernel operators ingress for large-scale distributed graph-based applications. This is accomplished by orchestrating data layout based on a communication hierarchy-aware partitioner (Section 5.2), with the aim of minimizing communication latency. To further advance graph construction, a space-time-efficient graph compression is built in GraphService by grouping identical-degree vertices (Section 5.5), aiming to batch memory access along with memory reduction. Implementation. We implement GraphService as a library in around 10K lines of C/C++ code tailored for ARM and x86 architectures. It provides application programming interfaces (APIs) for common graph operations, including those evaluated in this work.
5.2 Hierarchy-Aware Partitioner
Due to the significantly faster communication within lower-level domains compared with higherlevel ones, GraphService explicitly accounts for variations in communication latencies across different communication domains. It ensures that the graph's locality adapts to the hierarchical communication domains of target HPC systems. Our key idea is to assign high-degree vertices and their clustered vertices to the same communication domain. That is because there are frequent communications among high-degree vertices, and placing high-degree vertices within the same domain can significantly improve locality and advance performance.
5.3 Vertex Clustering
Like most graph partitioning methods , we begin by extracting the spatial locality of subgraphs from the input graph. This can be achieved by multiple methods, such as XTree , core subgraph , and vertex clustering. In this work, we opt for vertex clustering due to its low time and space complexity, but our partitioning algorithm (detailed in Section 5.4) can work with other methods as well. Vertex clustering is based on an observation that in real-world graphs, only a small number of vertices have a high number of edges. These high-degree vertices and their reachable neighbors will likely be frequently accessed together. Our method differs from previous works in that we strive to position vertices in the same cluster nearby within the communication domains, thereby minimizing communication overhead.
In the graph preprocessing phase, we sort graph vertices by edge degree and group them into a "vertex cluster" using Algorithm 1. Each cluster is centered around a designated "center vertex", 2:12 X. Gan v 0 , with members consisting of vertices reachable from v 0 within a given number of hops. The iterative clustering process starts by selecting the highest-degree unvisited vertex as v 0 and adding its unvisited neighbors to the C cluster. We then recursively add unvisited vertices at the next level to C until the distance threshold, h, is less than 1 (line 2). After generating clusters for a given v 0 , we repeat the process and move on to the next unvisited vertex with the highest edge degree. We continue until all vertices have been visited at least once, except for isolated ones with no neighbor.
We generate up to three clusters for each unvisited center vertex, v 0 , with distance thresholds of 1-hop, 2-hop, and 3-hop, though users can adjust this threshold. Each cluster contains vertices at a specific distance from v 0 , with smaller thresholds resulting in stronger vertex locality around v 0 . Because only a small fraction of vertices have a high edge degree and we only add unvisited vertices to a new cluster, we generate a small number of vertex clusters, typically less than 15.
Essentially, we use the distance threshold, h, to determine the proximity of adjacent vertices to the center vertex, v 0 . We start by considering vertices at a distance of 1 from v 0 , and form a neighboring cluster consisting of these vertices. We then consider vertices at a distance of 2 from v 0 to create a new cluster. We continue this process, forming clusters for vertices at increasing distances from v 0 until all vertices have been assigned to a cluster. Once we have formed the vertex clusters, we assign them to communication domains based on the center vertex's edge degree and the aggregated edge degree of the cluster by starting a cluster whose center vertex has the highest degree.
5.4 Topology-Aware Graph Partitioning
Algorithm 2 outlines partitioning and distributing graph vertices to computing nodes. The algorithm operates on a list of allocated computing nodes, denoted by N, which contains the node IDs. The distribution algorithm considers the locality of graph and communication differences across communication hierarchies.
Our partitioning algorithm (Algorithm 2) first builds a communication hierarchy for the target hierarchical systems, grouping computing nodes into communication domains according to the interconnection hierarchy of the target HPC systems and getting the total levels of communication hierarchy (lines 1-5). Next, we remove isolated vertices from the vertex list (V) that lack connections to other vertices, storing them in a separate list Ṽ. The remaining vertices in V are distributed among computing nodes using the Partitioning function (lines 9-12). The Partitioning function selects the vertex in V with the highest degree and utilizes the given vertex clusters (explained GraphService: Topology-aware Constructor for Large-scale Graph Applications 2:13   in Section 5.3) to group nearby vertices. Vertices within a vertex cluster C are assigned to computing nodes recursively to adapt to the target communication hierarchies. This method prioritizes node placement within the same communication domain or domains at the same level. To partition the graph based on vertex distance, we set a threshold, denoted as h (see Section 5.3). We then generate a list of h clusters,
C v = C 1 v , C 2 v , . . . , C h v ,
where each cluster C i v corresponds to a distance of i (1 ≤ i ≤ h) from the highest-degree vertex v that has not been processed yet (lines 25-27). When distributing vertices in each cluster to computing nodes, GraphService recursively starts from the lowest available level of the communication hierarchy and moves to a higher level only if the current level's resources cannot hold all vertices in C.
5.5 Topology-Aware Graph Compression
GraphService builds upon the classical CSR format but employs a folding method to group vertices with the same degree into a single starting offset in the RST array. GraphService will classify the initial RST array into two parts with a key parameter Thr, which is a threshold of vertex degree.  Vertices located before and after Thr will have specified indexing methods separately. While simple, this folding scheme is effective for graph processing by batching identical-degree vertices, thereby coalescing memory accesses and further enhancing graph construction speed in large-scale graphs.
5.6 GraphService Sparse Format
To facilitate GraphService, we tailor CSR to enhance large-scale graph storage, which introduces two additional arrays, RST_OFFSET and COL_OFFSET, and a hyperparameter, denoted as Thr. Thr is a threshold that determines whether a vertex is low degree and should be folded. Vertices in RST are classified into two parts by Thr; thus, only a small number of vertices with degrees exceeding Thr are stored and indexed similarly to standard CSR. Otherwise, vertices with degrees no more than Thr are expressed in RST_OFFSET and COL_OFFSET. The RST_OFFSET array stores the minimal IDs of vertices with edge degrees between 1 to Thr while the COL_OFFSET array stores the COL offset values with respect to the vertices in RST_OFFSET. In this way, the low-degree vertices can be traced through the RST_OFFSET and COL_OFFSET arrays. For high-degree vertices whose edge degrees are great than Thr, we store them in the standard CSR RST and COL arrays. Note that we opt not to compress high-degree vertices in GraphService. This decision stems from the observation that high-degree vertices are typically relatively rare in real-world graphs and are often accessed frequently during graph processing . Therefore, compressing them may incur additional runtime overhead, which could outweigh the benefits of compression.
5.7 Graph Storage
We use Figure to illustrate how GraphService represents a graph adjacency matrix for the example given earlier in Figure . For illustration, we set the edge degree threshold parameter, Thr, to 2. This means that vertices with edge degrees greater than 2 are considered high-degree vertices and will be stored in standard CSR, whereas vertices with degrees equal to or less than 2 are considered low-degree vertices and will be stored in the RST_OFFSET and COL_OFFSET arrays by referring to COL.
Algorithm 3 outlines how GraphService encodes high-degree and low-degree vertices. Specifically, the RST_OFFSET array stores the minimal IDs of N -degree vertices for N ∈ [1,Thr ], with the edge degree ordered in an ascending manner. For example, in Figure , RST_OFFSET[0] records the minimal ID of vertices with degree = 1 among vertices with ID = 6 and ID = 7, storing only one vertex with ID = 6 for all 1-degree vertices. Similarly, RST_OFFSET records the minimal ID of vertices with degree = 2 (i.e., degree = Thr) among vertices with ID = 4 and ID = 5, storing only one vertex with ID = 4 for all 2-degree vertices. For others in the RST_OFFSET array, the same rule applies. Correspondingly, COL_OFFSET[0] records the starting offset in COL for the vertex with minimal ID among 1-degree vertices (i.e., the vertex with ID = 6), whereas COL_OFFSET records the starting offset in COL for the vertex with minimal ID among 2-degree vertices and, thus, a GraphService: Topology-aware Constructor for Large-scale Graph Applications 2:15
1 for v c ∈ RST in parallel do 2 degree = RST [v c +1] -RST [v c ] 3 if 0 < degree ≤ Thr then 4 if v c ≤ RST_OFFSET[deдree-1] then 5 RST_OFFSET[deдree-1]=v c 6 COL_OFFSET[deдree-1]=RST[v c ] 7
successive adjacent vertex set {1, 2} for the vertex with ID = 4, and {0, 3} for the next 2-degree vertex with ID = 5, until all 2-degree vertices would be directly accessed without repeated calculations. In contrast, high-degree vertices with degrees greater than Thr are stored in a standard CSR. Overall, this approach optimizes the storage of low-degree vertices while still allowing highdegree vertices to be stored using the standard CSR approach. To this end, GraphService not only saves space but also enables batch memory access since it merely needs one entry for many identical-degree vertices that are continuously stored in a sorted graph.
6 Experimental Evaluation