7 Related Work DVFS on Mobile Systems. Several related studies propose ML-based Dynamic Voltage
Frequency Scaling (DVFS) on mobile systems . The study in predicts the CPU loads and employs Q-learning to adjust CPU frequency to minimize energy consumption. ML-Gov leverages an offline linear regression model to estimate CPU/GPU frequencies that maximize energy savings with minimal FPS degradation. AHDL classifies the TOP-APP into several types (e.g., computing intensive, memory intensive, etc.) and allocates computing resources based on predefined rules. Yet, the studies in only focus on managing CPU frequency and fail to manage GPU frequency, leading to sub-optimal performance and higher power consumption. Moreover, the studies in rely on limited features for scheduling, such as CPU load (the work in ) or predicted application types (AHDL ). They do not consider other critical OS runtime features like cache misses, IPC, and so forth. Therefore, they cannot comprehensively detect system performance issues and schedule the frequency accurately. The studies in has only one optimization goal, i.e., energy consumption. This might result in frame drops in mobile systems due to frequency under-provision. In terms of generalization, these studies cannot be easily generalized across new platforms because they use offline ML models (e.g., tree-based piecewise linear models in ML-Gov , k-NN-based power predictor in work , and CNN-based application classifier in AHDL ). When deployed on new platforms, they require offline data collection and model retraining.
By contrast, MobiRL learns from more critical OS runtime features, so it can identify performance issues and make accurate frequency scheduling decisions accordingly. It manages  both CPU and GPU frequency to achieve better UI responsiveness and lower power consumption simultaneously. Moreover, MobiRL does not require offline data collection; it uses reinforcement learning to autonomously explore the scheduling exploration space and learn to optimize UI responsiveness and power consumption. And using transfer learning can reduce MobiRL's training overhead when deployed on new platforms. In Section 5.5, we qualitatively and quantitatively compare MobiRL to the prior work that employs Q-learning for CPU scheduling. MobiRL significantly reduces the frame drop rate and power consumption compared with . DVFS on Data Center Servers. DVFS on data center servers is a well-studied approach . Table summarizes several typical DVFS studies on data center servers and shows their differences from DVFS on mobile devices. Generally, mobile systems often use the big.LITTLE heterogeneous computing architecture, which provides power-saving little cores and high-performance, powerhungry big cores. DVFS mechanisms on mobile devices focus on effectively leveraging this specific computing architecture to achieve better performance and lower power consumption. And, though some studies are also conducted on data center servers with heterogeneous processors, we find that some of their scheduling behaviors are coarse grained (e.g., longer scheduling time intervals, tasklevel partitioning/scheduling , etc.) than our approach on mobile systems. Besides, mobile systems are prone to be more energy efficient. On mobile systems, power is a problem that is often on top of others. By contrast, though some studies on data center servers also try to reduce the power and improve the QoS , their platforms, environments, applications, and use cases differ from mobiles. So, the solutions are also different at the root.
ML/AI for Systems. Using ML/AI is a promising approach for system optimizations. Many studies try to make OS intelligent using ML/AI technologies, e.g., resource scheduling for cloud services , load balancing , parameter tuning for OS/system software , VM failure mitigation , and so forth. Generally, these studies fall into three categories. The first category is statistical learning . The second category is deep learning . Deep learning models are data driven. They require sufficient training data for accurate prediction and generalization. The third is reinforcement learning . They can learn online from historical scheduling decisions and the feedback from the environment, making them resilient to changes in the environment and the workloads.