5 Evaluations
We compare MobiRL with the most related work in : (1) Hyper Boost . Hyper Boost is the state-of-the-art industrial frequency scheduler on the newly released mobile device (Table ). Hyper Boost raises the frequency when users launch an application or swipe the screen. Besides that, Hyper Boost can boost the frequency for dozens of applications by recognizing critical scenarios and notifying the mobile system through Hyper Boost SDK interfaces . Details are in Section 5.4. (2) Q-Learning approach . The work in employs a reinforcement learning algorithm for CPU frequency scheduling. We denote this approach as Q-Learning. It selects the appropriate CPU frequency using Q-Learning based on estimated CPU loads to minimize . The CPUFreq subsystem provides several default frequency scaling governors that adjust the CPU frequency within the frequency limits. They are frequency scaling algorithms that are widely used in mobile systems. We compare MobiRL with four representative governors including performance, powersave, schedutil, and conservative to illustrate MobiRL's effectiveness over existing frequency scheduling mechanisms in mobile systems. The performance governor adjusts the frequency to the upper frequency limits for higher performance. The powersave governor adjusts the frequency to the lower frequency limits to save power. Both the schedutil and conservative governors make frequency scaling decisions based on the estimated CPU utilization. The schedutil governor is more flexible due to its shorter scheduling time interval and larger-frequency scheduling steps. The experimental results are in Section 5.6.
5.1 Methodology
The following metrics are used in evaluations.
Frame Drop Rate. The frame drop rate refers to the percentage of frames that should be rendered but are not rendered during real-time rendering due to frequency under-provision. It is measured using the gfxinfo tool in Android.
Power Consumption. Power consumption is calculated by multiplying the voltage by the current. In MobiRL, adb is used for communication between the server and the mobile device. To eliminate the impact of charging current on power measurement, we establish the adb connection using WiFi instead of the USB cable.
For all experiments, we set the FPS to 60; i.e., the allowed frame rendering time is (1 s/60) -1 ms = 15.7 ms. The system monitor collects the mobile system's status each time 10 frames are rendered; i.e., the sampling rate is six times per second. Each time MobiRL receives the collected data, it makes a frequency scheduling decision. Therefore, the frequency of MobiRL decision-making is also six times per second. In the experiment, we ensure that the initial device temperature is below 35 • C for each trial to avoid forced throttling of the mobile device due to high temperatures.
5.2 Benchmarks
We evaluate MobiRL using some representative applications, including video playing, social media, photo taking, and so forth. They exhibit different computing/memory patterns. They are TikTok , Weibo , Taobao , Camera , and Browser . In addition, we also evaluate cases where the system load varies by running various background applications before launching the TOP-APP.
5.3 MobiRL Training and Convergence
We show that MobiRL's DDPG model can converge faster using transfer learning in Figure . We first train the model at FPS 60 (i.e., each frame should be rendered in 1 s/60 = 16.7 ms) using the benchmark applications in Section 5.2. The black curve (the lower curve) in Figure shows the model's episode reward during the online training. Each episode has 200 training steps (Table ). The episode reward is the sum of the reward value in each training step of an episode. A higher episode reward indicates that the model can achieve lower frame drop rates and power consumption during this episode. Then, we change the FPS to 120 (i.e., each frame should be rendered in 1 s/120 = 8.3 ms). In this case, the previous model trained at 60 FPS does not work well and needs to be retrained because the user demand changes. We retrain the model at FPS 120 using transfer learning based on the pre-trained model at FPS 60. The blue curve (the upper curve) shows the model's episode reward.
5.3.1 Model Training at 60
Frames per Second. The black curve (the lower curve) in Figure shows that MobiRL's DDPG model learns to maximize the episode reward over time. The model quickly converges in 100 episodes; i.e., the episode reward stabilizes and consistently remains at a high level. At the beginning of the learning process (from episode 0 to 15), MobiRL's DDPG model learns to schedule frequency by exploring the search space, leading to fluctuations in UI smoothness and power consumption. After that, we observe a rapid increase in episode reward from episode 15 to 100. During this period, DDPG learns to improve the model's decision-making, achieving a higher reward by optimizing UI smoothness and power consumption. Additionally, we observe that UI smoothness and power consumption optimize during the training process. For each 10 training episodes, we save the checkpoint of model parameters. To evaluate the model trained for a specific number of episodes, we load the saved parameters and compare it with Hyper Boost in terms of frame drop rate and power consumption when handling the same workload. The starting policy is no better than Hyper Boost. But after episode 100, MobiRL outperforms Hyper Boost. We evaluate MobiRL with parameters at episode 390. MobiRL outperforms Hyper Boost by 5.8% and 32.3% in terms of frame drop rate and power consumption, respectively.
5.3.2 Transfer Learning with a Low Retraining Cost at 120
Frames per Second. The blue curve (the upper curve) in Figure shows that transfer learning can reduce the retraining cost and make the model converge faster. We first copy the network parameters of the pre-trained model to the new model at FPS 120 and then conduct online training. The episode reward of the model trained using transfer learning increases quickly in the first 50 episodes and consistently remains high; i.e., the model converges in around 50 episodes. Moreover, the model trained using transfer learning achieves 23.6% higher episode reward upon convergence compared with the case when transfer learning is not used; i.e., the model trained using transfer learning can achieve a lower frame drop rate and power consumption in practice. Training the model for 50 episodes takes around 30 minutes. This indicates that MobiRL's DDPG model has a low retraining cost by using transfer learning, making MobiRL easier to generalize across new cases or platforms.
5.4 Effectiveness of MobiRL Compared with the Industrial Scheduler
We first evaluate MobiRL against the state-of-the-art industrial frequency scheduler Hyper Boost that is widely deployed on modern mobile devices. We show the effectiveness of MobiRL as follows.
5.4.1 Performance Distribution.
MobiRL exhibits better UI smoothness and lower power consumption (Figure ). Using ML, MobiRL can schedule the frequency accurately to quickly satisfy user demands. We construct 58 workloads by varying the TOP-APP, the time interval for swipe actions, and the number of background applications. For instance, in workload 1, the TOP-APP is TikTok, the interval for swipe actions is 5 seconds, and three background applications are launched. For each workload, we use MobiRL and Hyper Boost, respectively. We collect the frame drop rate and power during the 120-second period after the scheduling begins. Figure shows the distributions of the scheduling results of these 58 workloads for MobiRL and Hyper Boost, respectively. The x-axis shows the frame drop rate; the y-axis denotes the power. Generally, MobiRL can achieve a lower frame drop rate with lower power consumption for these workloads. On average, MobiRL has a frame drop rate of 2.2% and a power consumption of 275.8 mW, while Hyper Boost has a frame drop rate of 6.3% and a power consumption of 482.1 mW. MobiRL reduces the frame drop rate and power by 4.1% and 42.8% for these workloads, respectively. We also record the frame rendering time of the cases in Figure . Compared with Hyper Boost, MobiRL reduces the average frame rendering time and frame rendering time of the 50th, 90th, 95th, and 99th percentiles by 21.2%, 21.0%, 23.1%, 20.8%, and 16.8%, respectively.  better mainly because it has the learning ability and can dynamically adjust the frequency to satisfy user demands. By contrast, Hyper Boost cannot promptly handle some high-load cases that are not directly triggered by the user's action, which often leads to frequency under/overprovision when handling dynamically changing loads, leading to worse UI smoothness and increased power consumption.
5.4.2 Performance for Varying Applications.
We study how MobiRL performs for each application in Figure . Figures ) and 8(b) show each application's frame drop rate and power consumption, respectively. Each application's results are based on the average of five experimental results. MobiRL can optimize the frame drop rate and power consumption for all applications. Specifically, for TikTok, Taobao, Weibo, Browser, and Camera, MobiRL can reduce the frame drop rate by 7.0%, 3.1%, 2.5%, 1.6%, and 0.1%, respectively. MobiRL can also save power consumption by 54.6%, 15.2%, 23.5%, 50.4%, and 9.6%, respectively. We observe the most significant optimization in frame drop rate and power consumption for TikTok, a video-playing application. For Camera, it achieves a frame drop rate of 0.1% when using Hyper Boost for scheduling. Using MobiRL for scheduling can further reduce its power consumption by 9.6%.
5.4.3 Performance for Varying TOP-APP Loads.
We test how MobiRL performs for varying loads of TOP-APP in Figure . We control the load of the TOP-APP by changing the time intervals between swipe actions. The shorter the time interval, the higher the load. We use TikTok as the TOP-APP in Figure . We observe that MobiRL consistently outperforms Hyper Boost in every time interval setting. For time intervals ranging from 1 s to 5 s, MobiRL outperforms Hyper Boost by 5.7%, 5.0%, 4.8%, 5.6%, and 3.4% in terms of frame drop rate, and saves power by 30.0%, 25.2%, 41.6%, 47.9%, and 48.0%, respectively. Note that our ML model is only trained on TikTok with a 5-second swipe action interval. However, MobiRL can perform well under other interval settings, indicating that MobiRL performs well in generalization across varying TOP-APP loads. Interactive applications may have user inputs at random time intervals, i.e., varying TOP-APP loads. MobiRL also works well for them.
5.4.4 Performance for Varying Background Loads.
In Figure , we test how MobiRL performs with varying background loads by launching a variable number of background applications. Tik-Tok is used as the TOP-APP (active app on the screen). The interval of swipe action is set to 5 s. When 0, 3, 6, 9, and 12 background applications are launched, MobiRL outperforms Hyper Boost by   3.4%, 7.8%, 7.3%, 8.0%, and 2.7% in terms of frame drop rate, respectively. MobiRL can save power by 48%, 14.2%, and 6.0% when 0, 3, and 9 background applications are launched, respectively. When the system has a high load, MobiRL prioritizes UI smoothness. When 6 and 12 background applications are launched, MobiRL only incurs 6.3% and 8.3% higher power consumption, respectively.
5.4.5 Performance for Unseen Applications.
We study how MobiRL performs for applications that are not used to train MobiRL's DDPG model in Figure . We evaluate MobiRL using Watermelon video [41], TopBuzz , JingDong , and Vipshop . For these unseen applications, MobiRL outperforms Hyper Boost by 5.0%, 1.4%, 3.3%, and 14.0% in terms of frame drop rate and saves power by 50.8%, 18.4%, 78.4%, and 14.6%, respectively. Furthermore, we evaluate MobiRL using a VR application (Hall VR ). This application is resource intensive. It constantly processes motion sensor data and renders the scene in real time, requiring lots of computing/memory resources. It is also performance intensive and needs to respond to users promptly. For this application, MobiRL outperforms Hyper Boost by 2.5% in terms of frame drop rate and 32.4% in terms of power consumption. MobiRL achieves a lower frame drop rate and power consumption in these unseen cases, showing that MobiRL is generalizable and performs stably in various cases.
5.4.6 MobiRL's Performance During Runtime. We further show how MobiRL performs in detail.
In Figure , we use TikTok as the TOP-APP and do not launch any background applications. We use adb to simulate swipe actions with a 5-second time interval. Figures ) and 12(b) illustrate the frame rendering time and power consumption during the scheduling process, respectively. Figures ) through 12(f) show how MobiRL schedules the CPU/GPU frequency limits for achieving ideal UI smoothness and power consumption. It schedules threads according to the CPU resources required by tasks. Android OS schedules TikTok threads on CPU clusters 0 and 1 for power efficiency for these two cases.
MobiRL can achieve higher UI smoothness and low power consumption simultaneously. As shown in Figure , during the 100-second frequency scheduling period using MobiRL and Hyper Boost, MobiRL has a lower frame drop rate (more smooth UI)-the frame drop rates of the TOP-APP scheduled by MobiRL and Hyper Boost are 1.3% and 6.3%, respectively. In Figure , the average power consumption for MobiRL is 372.4 mW, whereas Hyper Boost has an average power consumption of 561.2 mW. MobiRL saves 33.6% power compared with Hyper Boost.
MobiRL can quickly schedule CPU/GPU frequency limits to achieve the frequency limit configuration that can maximize the long-term rewards within seconds. MobiRL schedules frequency starting from time point 0. As shown at the beginning of Figures ) and 12(f), MobiRL promptly conducts four consecutive frequency scaling actions within 1.5 seconds to raise the lower frequency limits of CPU cluster 1 and the GPU. Finally, the lower frequency limit of CPU cluster 1 is raised from 960 MHz to 1,670.4 MHz, and the lower frequency limit of GPU is raised from 315 MHz to 676 MHz. A higher CPU or GPU frequency increases power consumption but does not further reduce the frame drop rate. By monitoring the mobile system status, MobiRL raises the lower frequency limits to values that can minimize potential frame drops while avoiding high power consumption. MobiRL has fast responsiveness. In MobiRL, the system monitor collects data when 10 frames are rendered (Section 4.3). Thus, when FPS is 60, the theoretically minimum scheduling interval of MobiRL is 1 s/60 ×10 = 167 ms. MobiRL can reduce power consumption by scaling down the frequency limits while ensuring UI smoothness. As shown in Figures ) through 12(e), MobiRL scales down the upper frequency limits of CPU clusters 0 and 1 and the lower frequency limit of CPU cluster 2 for lower power consumption.
Moreover, during MobiRL's scheduling process, there are no frequent changes in the frequency limits. This is because MobiRL tends to optimize UI smoothness and power consumption by selecting a configuration of frequency limits that yields the highest long-term rewards rather than making real-time frequency adjustments.
12:20 X. Dou et al.
5.5 MobiRL vs. Other ML-based Scheduler for Mobile
In this section, we compare MobiRL with a recent study using Q-Learning for CPU frequency scheduling based on estimated CPU loads. We denote this work as Q-Learning. Q-Learning takes the estimated CPU loads and current CPU frequency as inputs and outputs the CPU frequency that meets the CPU loads with relatively lower power consumption. During online training, Q-Learning learns to adjust CPU frequency to reduce power consumption, aiming to minimize a cost function defined as the device's power consumption. We evaluate MobiRL and Q-learning as follows.
First, we evaluate MobiRL and Q-Learning using workloads that have different TOP-APPs, including Taobao, Weibo, Browser, and Camera. There are no background applications in these workloads. The time interval between swipe/tap actions is set to 1 s for these TOP-APPs. The experimental results are in Figure . Compared with Q-Learning, MobiRL can achieve a lower frame drop rate and power consumption simultaneously for these TOP-APPs. MobiRL achieves a 2.5%, 2.1%, 1.7%, and 0.1% lower frame drop rate and 32.6%, 19.4%, 20.3%, and 3.0% lower power consumption for Taobao, Weibo, Browser, and Camera, respectively. The underlying reason is that MobiRL holistically schedules both the CPU and GPU frequency, achieving better scheduling results than Q-Learning, which only schedules the CPU frequency.
Second, we evaluate MobiRL and Q-Learning using workloads with varying TOP-APP loads. We use TiKTok as the TOP-APP and control its load by changing the swipe time interval. A shorter swipe time interval indicates a higher load. There are no background applications in these workloads. The experimental results are illustrated in Figure . Our design outperforms the Q-Learning approach in general. Moreover, we show that the Q-Learning approach may outperform our design in one aspect but cannot simultaneously have better solutions on both power and frame drop rate (i.e., UI smoothness). For example, in Figure , when the swipe time interval is 3 s, Q-Learning achieves 1.0% lower power consumption but incurs a 3.7% higher frame drop rate than MobiRL. The underlying reason is that Q-Learning uses the mobile device's power consumption as the reward; thus, it optimizes only the power consumption and does not consider the UI smoothness. It tries to achieve a lower power consumption by scaling down the frequency, which can lead to frequency under-provision and incur slow UI responsiveness. By contrast, MobiRL optimizes the UI smoothness and power consumption simultaneously because it considers both the frame drop rate and power consumption in its reward function.
Third, we evaluate MobiRL and the Q-Learning approach using workloads with varying background loads. We launch TikTok as the TOP-APP and launch a varying number of background applications. The interval of the swipe action is set to 5 s. The experimental results are in Figure . We show that MobiRL can satisfy the loads with lower power consumption, especially when the background load is heavy. For example, in Figure , when there are nine background applications in the workload, MobiRL has 3.1% lower frame drop rate and 47.1% lower power consumption. Besides, in the cases where there are 12 background applications, MobiRL also provides significant benefits. The underlying reason is that MobiRL has more input features, so it   can identify performance issues and make accurate frequency scheduling decisions accordingly, outperforming the other approach. As shown in Table , MobiRL's input features include the task load of the TOP-APP and the CPU cluster ID that the TOP-APP is running on. With these two features, MobiRL can satisfy the TOP-APP's load by accurately scheduling the frequency of the CPU cluster that the TOP-APP is running on using the minimum power consumption. By contrast, the Q-Learning approach relies on the estimated CPU loads for scheduling. It schedules frequency for all applications, even those that are not important for improving the UI responsiveness, leading to higher power consumption, especially when the background load is heavy.
5.6 MobiRL vs. Default Frequency Scaling Governors in CPUFreq Subsystem
The Android OS uses the CPUFreq subsystem to support CPU performance scaling . It provides several default frequency scheduling governors that scale frequency within the frequency limits, e.g., performance, powersave, schedutil, and conservative. They have straightforward scheduling policies and are widely used on mobile systems. We compare MobiRL with them to show MobiRL's effectiveness over default mechanisms. In our experiments, we use TikTok as the TOP-APP and set the swipe time interval to 1 s. There are no background applications in the workload. The experimental results are in Figure .
The performance governor adjusts the frequency to the upper frequency limits for higher performance. As illustrated in Figure , compared with our approach, it further reduces the frame drop by 0.6% but incurs a 2.3× higher power consumption. The powersave governor adjusts the frequency to the lower frequency limits to save power. It saves power consumption by 59.8% compared with MobiRL but incurs a 28.2% higher frame drop rate. Both performance and powersave cannot optimize the frame drop rate and power consumption simultaneously. The schedutil governor scales CPU frequency dynamically based on the estimated CPU utilization. More specifically, it adjusts the CPU frequency dynamically to control the estimated CPU utilization close to 80%. If the estimated CPU utilization is above 80%, it dynamically scales up the CPU frequency if possible; otherwise, if utilization is below 80%, it scales down the CPU frequency. The conservative governor also schedules based on the estimated CPU utilization, but it has a larger scheduling time interval and smaller frequency scheduling steps. Compared with  schedutil and conservative, MobiRL achieves a 3.9% and 5.5% lower frame drop rate, respectively, and achieves a 35.5% and 36.7% lower power consumption, respectively. The schedutil performs better than conservative because it is more flexible and works better on mobile devices with dynamically changing loads. In general, MobiRL can optimize the frame drop rate and power consumption simultaneously and outperforms these governors in the CPUFreq subsystem.
5.7 CPU Frequency Usage: Why MobiRL Works Effectively
We analyze the usage of CPU frequency to study why MobiRL can optimize the UI smoothness and power consumption simultaneously. Figure shows the CPU frequency usage for 50 workloads where MobiRL outperforms Hyper Boost. Each workload is run for 1 minute. The total time for the plots is 50 minutes. Figures ) through 17(c) show the frequency usage for CPU clusters 0, 1, and 2, respectively. The x-axis represents each CPU cluster's predefined discrete frequency values; the y-axis represents the proportion of time during the entire scheduling process that the CPU cluster stays at a specific frequency. As shown in Figure , when MobiRL is used for scheduling, CPU cluster 0 stays at 1,804.8 MHz (the highest frequency value) for 96.7% of the entire scheduling process. By contrast, with Hyper Boost, CPU cluster 0 stays at 1,804.8 MHz for only 39.7% of the scheduling process. We learn from Figure (Section 2.2) that the cores in CPU cluster 0 are power-saving ones. The high usage of CPU cluster 0's highest-frequency value means that MobiRL makes good use of the power-saving cores in CPU cluster 0. Therefore, MobiRL can optimize the UI smoothness and power consumption simultaneously.
5.8 Overhead
MobiRL has a low overhead. The time required for getting model input features is 2.4 ms. The Actor network runs on the CPU when MobiRL is deployed on the mobile system. It takes 6.7 ms on average to forward the input parameters to the model and obtain the output. The memory usage of MobiRL is 7 MB. In terms of CPU usage, the model prediction and frequency scheduling account for 10.5% utilization of a little core (Cortex-A55) on the experimental platform. As MobiRL does not send or receive network requests, it does not consume network bandwidth. As for storage overhead, the model consumes only 13 KB.
Moreover, we evaluate MobiRL's impact on background applications including Gmail, Google Maps, Amazon Shopping, and WeChat. They run in the background and are not on the screen. For MobiRL 12:23 each background application, we use TikTok as the TOP-APP and leverage simpleperf to measure the background application's IPC with and without using MobiRL, respectively. The experimental results show that for Gmail , Google Maps , Amazon Shopping , and WeChat , enabling MobiRL decreases their IPC by 2.9%, 3.6%, 3.3%, and 4.8%, respectively, which is negligible and does not impact the user experience in practice. Generalization. If mobile devices have new hardware that significantly differs from existing ones (e.g., a new processor with a different number of cores), the RL model needs to be retrained for accurate scheduling due to the hardware changes. Transfer learning can be used to retrain the model with a small training overhead. MobiRL is generalizable. Its model can be used on devices with similar hardware configurations. This is because the relationship between OS features, rendering time, and computational resources captured by MobiRL does not change drastically on these devices. Moreover, MobiRL can effectively schedule resources even for devices with different hardware through low-overhead transfer learning (Section 5.3).
One-for-all vs. One-for-each Category. Training a model for each category of applications may lead to a lower frame drop rate and lower power consumption compared to using a single model to handle all applications. For instance, using a model tailored to video playback applications (e.g., TikTok, YouTube, etc.) would result in higher accuracy and better scheduling results compared to scheduling in a one-for-all manner.