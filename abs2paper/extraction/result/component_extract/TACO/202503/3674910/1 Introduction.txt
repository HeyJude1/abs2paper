1 Introduction
Mobile devices (e.g., smartphones) that use the Android Operating System (OS) had a global market share close to 70% in 2022 . The Android OS kernel is derived from the Linux kernel 12:2 X. Dou et al.
with designs for human-machine interaction. Smartphone users are sensitive to the slow responsiveness of the user interface (UI) and the high power consumption. Therefore, the smoothness of the UI and power consumption are two critical optimization goals on mobile platforms.
Computing resources on mobile systems-CPU/GPU frequency and enabled CPU coresdirectly affect UI smoothness and power consumption. The existing mobile systems, e.g., the ARM big.LITTLE heterogeneous computing architecture, provide both power-saving little cores and high-performance, power-hungry big cores. System designers can have new mechanisms that effectively leverage this specific computing architecture to have better performance on the UI and power. For computing resource scheduling, the CPU performance scaling (CPUFreq) and device frequency scaling (devfreq) subsystems in the Linux kernel also provide frequency governors for dynamically adjusting CPU and GPU frequency. The Android Open Source Project (AOSP) provides the powerHint interface [4] that allows original equipment manufacturers (OEMs) to implement customized frequency scheduling/scaling (the two terms are used interchangeably for different cases) policies. OEMs also provide SDK interfaces that allow applications to tell the system to raise the frequency in response to burst inputs or changing loads. These mechanisms are deployed on mobile devices such as Samsung GameDev , OPPO Hyper Boost , and Huawei PerfGenius . Prior frequency scheduling mechanisms often use heuristic algorithms and empirical experiences. They schedule frequency according to predefined policies. Facing diverse changing loads generated by today's mobile users, existing approaches might not detect frequency over-provision (wasting power) or under-provision (cannot meet users' demands) due to their limited access to OS runtime features. We show a typical instance. The schedutil governor in the CPUFreq subsystem only relies on the CPU utilization estimated by per-entity load tracking for frequency scheduling. It cannot access other OS runtime features, such as cache misses, instructions per clock (IPC), and so forth. Thus, it lacks sufficient information to identify performance issues. As a result, mobile users often encounter application UIs becoming stuck (high frame loss rate) and high power consumption.
We summarize several challenges that need to be conquered in existing frequency scheduling mechanisms: to identify the performance issues and make accurate frequency scaling decisions accordingly to avoid frequency over-provision and under-provision, to handle some cases where the load is high and dynamically changing, and (3) to simultaneously schedule CPU and GPU frequency to avoid sub-optimal performance. To this end, this article proposes MobiRL, a reinforcement learning (RL)-based scheduling mechanism for intelligent scheduling/adjusting CPU/GPU frequency on mobile systems. MobiRL formulates the frequency scheduling as a classification problem and employs a customized Deep Deterministic Policy Gradient (DDPG) RL model to solve it. Using RL, MobiRL learns to adjust CPU/GPU frequency dynamically to achieve high UI smoothness (low frame loss rate) and low power consumption. When MobiRL performs scheduling, it captures the system status and uses the ML model to predict an action for adjusting CPU/GPU frequency. After conducting the action, MobiRL receives a reward from the mobile system and learns from it. MobiRL can provide precise and timely CPU/GPU frequency scheduling actions compared with prior work . Machine learning (ML) has already shown tremendous potential and advantages in many studies on OS and architecture . In this article, we leverage ML technologies to improve the scheduling performance of mobile systems. Using ML/AI technologies for mobile systems is a new topic, and there are not many published studies in this field. We are among the pioneers using ML/AI to improve (mobile) systems. We make the following contributions:
(1) We show that the existing heuristic-based CPU/GPU frequency scheduling mechanism used in off-the-shelf mobile devices cannot effectively handle high-load cases where the screen is not being touched. Moreover, this mechanism raises processors' frequency according to predefined policies, rather than adjusting frequency on demand. Thus, it cannot promptly satisfy users' diverse loads and often leads to frequency under-provision (UI stuck) or over-provision (energy wasting). We propose MobiRL, an intelligent frequency scheduling mechanism for mobile systems. Mo-biRL leverages a reinforcement learning model-DDPG customized for the mobile systemsand learns to dynamically schedule CPU/GPU frequencies according to system loads and user demands, optimizing the UI smoothness and power consumption at the same time. (3) To use ML on mobile optimizations, we formulate mobile frequency scheduling as a classification problem and further design a discrete frequency scheduling action space. This approach simplifies the decision-making process by reducing the complexity of the action space and speeding up the convergence of the ML model. Our approach reduces the deployment overheads on resource-constrained mobile systems. (4) We implement MobiRL on the latest real smartphone delivered by a well-known mobile corporation. The experimental results show that MobiRL outperforms the state-of-the-art industrial frequency scheduler, reducing the frame drop rate by 4.1% and reducing power consumption by 42.8%, respectively. Our approach has been adopted by industrial.