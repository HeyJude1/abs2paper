5 Evaluation
To evaluate our transformation, we extended the DaCe pipeline by adding the pointer disaggregation transformation explained in Section 2 and the specific transformations explained in Section 4. The approach described in Section 4.2 and Section 4.3 is implemented by adding a whitelist of additional dependencies in the data-centric IR (intermediate representation) used by DaCe.
As detailed and demonstrated in Section 2.5, while incremental performance enhancements are attainable across various compilers, the constrained scope of vectorization inhibits substantial performance gains. Consequently, we prioritize automatic parallelization compilers such as Polly and DaCe, which hold promise in uncovering novel opportunities facilitated by the transformations implemented. Specifically, we direct our attention to DaCe due to its inherent data-centric approach, which offers superior analysis of data dependencies.
We measured performance on a dual-socket 2×6 core (2×12 threads) Intel Xeon X5670 @ 2.93 GHz with 48 GB of RAM. We compare the DaCe data-centric framework (using GCC 12.1.1 as a backend compiler) against GCC and Polly (using Clang 15.0.6). We report the median of 10 runs with a confidence interval of 95%. OpenMP is used for parallel execution. Integrating the adjunct transformation into Polly did not reveal any additional SCoPs, and consequently, no further parallelization opportunities were identified. Hence, we provide the runtime results of Polly without the adjunct transformation. We specifically chose to compare with Polly due to its widespread availability as part of the LLVM/Clang suite, offering some level of automatic parallelization capabilities. Our evaluation was conducted on the Mantevo HPCCG benchmark and the OpenSSL PBKDF2 implementation, with the results presented below.
5.1 OpenSSL PBKDF2
The Password Based Key Derivation Function 2 (PBKDF2) is a derivation function that derives a cryptographically secure key from a password. PBKDF2 applies a Hash-based Message Authentication Code (HMAC) function multiple times to a provided password and salt. Based on the required length of the key, this process is repeated multiple times. A summary of the process is provided in Figure . We can notice that each single B i blocks can be computed independently of any other.
The implementation inside OpenSSL does not include parallel options. We applied our pipeline to the OpenSSL code to auto-parallelize the code. We compare the runtime against Polly and a manually parallel version that was written using the OpenSSL implementation as a starting point. Only the PBKDF2 algorithm was analyzed, all HMAC calls are treated as external calls and use the standard OpenSSL implementation. For completeness, we compare it with FastPBKDF2 , an implementation of the same algorithm that has been developed for parallelism from the ground up. We used SHA1 as the HMAC function, 5 • 10 6 iterations, and an output key size of 480 bytes (or 24 blocks), and we summarize our results in Figure .
We then varied the problem size, represented by the number of blocks. The results (Figure ) show a consistent trend across all experiments. Our approach was able to obtain comparable results to the manually parallelized version, providing at most a 10.7× improvement with 24 threads. Polly was not able to identify any parallel opportunities due to the challenges of analyzing  pointers. The FastPBKDF2 implementation is considerably faster than any OpenSSL equivalent, mainly due to the serial runtime of FastPBKDF2 version being three times faster: 27.7 s versus 84.5 s for OpenSSL. This reinforces the idea that tools can provide significant performance increases and find opportunities for parallelism, but nothing surpasses finding a better algorithm altogether.
5.2 Mantevo HPCCG
The Mantevo HPCCG benchmark computes the conjugate gradient on a sparse matrix. The sparse matrix is stored using the LIL format. We leverage the specific transformation explained in Section 4.1 to improve analyzability. The LIL transformation is applied once only to the input file for DaCe. We compare our pipeline against Polly with the same preprocessed input. The baseline is obtained using the original benchmark with OpenMP enabled.
We can see that Polly was not able to find parallel opportunities, as pointers are used to access the sparse matrix. Our approach was able to parallelize all five loops. The performance of our automatically parallelized code matches the hand-tuned version developers created across all experiments. At larger problem sizes, our approach even outperforms the reference implementation by up to 18%.
5.3 Lempel-Ziv-Oberhumer Compression Algorithm
In Section 2.5, we presented results from a benchmark on the LZO compression algorithm. Although automatic parallelization was not achieved, there was still a modest enhancement in singlethreaded performance. Achieving effective automatic parallelization would necessitate an algorithm redesign due to the presence of loop-carried dependencies. However, our method managed to achieve a 4% runtime enhancement without requiring any algorithm rewriting. Given the analogous pointer movement patterns observed in most compression algorithms, we anticipate similar, if not superior, outcomes by extending our pipeline to encompass them as well.