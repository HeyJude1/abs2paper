II. RELATED WORK
The process of discovering and designing Sparse Matrix Multiplication (SpGEMM) algorithms is significantly complex, with an extensive algorithm space. Establishing a more efficient algorithm from this wide space remains one of the fundamental open problems in computer science. Existing SpGEMM can generally be categorized into five types: ESC, Hash, Merge, Dense, and Tile-based methods.
The key steps in the ESC category involve storing intermediate results in temporary space (expansion), sorting intermediate results according to column indexes, and finally accumulating values per column index. Originating in CUSP , this algorithm was subsequently applied further in bhSPARSE and AC-SpGEMM . The sorting and accumulation process of this algorithm directly acts upon intermediate results, exhibiting commendable performance when the intermediate results are limited. However, this method requires substantial temporary space to store intermediate results. As the scale of intermediate results increases, sorting them comes with a high cost, leading to a dramatic decline in algorithm performance.
Hash accumulators can utilize hash features to substantially reduce random data access and effectively enhance hardware resource utilization . Due to the irregular sparsity characteristics of sparse matrix multiplication, the number of nonzero elements in the output rows often exhibits significant variability. Naively allocating the same storage space inevitably leads to resource wastage. Usually, the two-stage strategy is employed to calculate the number of non-zero elements in output matrix rows and allocate just-enough storage . The Hash method's primary time-consuming aspects involve the atomic accumulation operation of intermediate results and the subsequent sorting steps. As the number of non-zero elements in the result matrix increases, these operations become performance bottlenecks. Additionally, when the shared storage space of the GPU is insufficient, the hash table has to be stored in slower global storage , resulting in a more significant performance decrease.
Merging involves using sorted arrays to store intermediate results and implementing a merge algorithm for sorting the intermediate results. RMerge divides the input matrix into submatrices and utilizes a highly efficient merge algorithm for sorting results. As merge arrays are usually of equal length, they are unable to effectively address irregular sparsity characteristics, leading to low resource utilization.
Dense accumulators , are introduced for scenarios where matrix size is large, and the output matrix is dense. It applies for an array of the same length as the matrix column number, directly performing linear mapping and result accumulation based on the result column index. This method fundamentally eliminates atomic conflicts and high sorting costs in the Hash method, theoretically exhibiting superior performance for dense scenarios. However, high storage requirements also become the bottleneck of this method.
Tile-based methods extend from dense scenarios to sparse matrix scenarios. TileSpGEMM partitions and schedules tasks based on the tile as the basic unit, effectively enhancing hardware utilization. It has superior performance in scenarios with higher sparsity. However, this technique introduces a notable format conversion time cost and performs poorly in extremely sparse scenarios.
Current approaches for multi-GPU matrix multiplication primarily focus on dense matrices. SuperMatrix decomposes the matrix into tiles and enables general matrix multiplication on SMP multicores. MAGMA utilizes static scheduling to implement a multi-GPU linear algebra library. However, MAGMA faces limitations when dealing with heterogeneous systems. To overcome these limitations, StarPU introduces dynamic scheduling algorithms, including work stealing and priority scheduling, resulting in consistent superlinear parallelism. NVIDIA's cuBLAS-XT [21] is a commercial multi-GPU L3 BLAS library that also adopts a tile strategy. However, its performance is hindered by frequent communication. In order to address this issue, BLASX aims to overcome the insufficient communication and computation overlap in SuperMatrix and StarPU, as well as the frequent communication problem in cuBLAS-XT. BLASX achieves performance optimization through the implementation of optimization strategies such as algorithms-by-tiles, dynamic asynchronous runtime, and peer-to-peer (P2P) communication between GPUs. In the realm of sparse matrix multiplication, X. Liu et al. have extended cuSpAMM to multi-GPU platforms, creating a multi-GPU sparse approximate matrix multiplication (SpAMM) method. However, their task partitioning scheme naively divides the tasks equally based on the number of rows, resulting in a significant load imbalance for sparse matrices with irregular sparsity characteristics.