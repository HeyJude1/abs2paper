III. DELTASPARSE
DeltaSPARSE consists of seven distinct stages, as depicted in Figure1. Firstly, the computation of the upper bounds of non-zero elements per row in a lightweight output matrix C is performed. This serves as the basis for subsequent global task decomposition among GPUs. Following this, each GPU undergoes local task decomposition in the Multi-GPUs symbolic SpGEMM stage, employing a hybrid accumulation approach to determine the non-zero element counts per row in the partial result matrix C. The main GPU collects the individual computation results from each GPU, subsequently calculating the row offset array and the total number of nonzero elements in matrix C. This is followed by the execution of the global task decomposition stage in the numeric phase.
In the Multi-GPUs symbolic SpGEMM stage, each GPU allocates storage space for the local matrix C based on the partitioning results, performs the computation of the column index array and the values of non-zero elements in C, and finally aggregates the resulting matrix C.
A. Adaptive Hybrid Accumulator
Hash Accumulator The hash accumulator has been widely utilized in previous research. One of the key factors in enhancing the efficiency of the hash accumulator is the reduction of collision rates during the hashing process. Sparse rows leverage a hashmap for linear probing and accumulation of results at specific positions, thereby facilitating rapid indexing when the hashmap possesses ample unoccupied space. Moreover, this approach exhibits lower storage requirements in comparison to alternative methods. However, as the hashmap becomes increasingly populated, the likelihood of hash col-lisions escalates substantially, giving rise to elevated linear probing expenses.
During the symbolic stage, it is solely necessary to document the column indices of non-zero elements within the output matrix, necessitating the allocation of a 32-bit integer array in shared memory. In contrast, throughout the numeric stage, the task of recording the column indices of non-zero elements and reducing intermediate results at corresponding indices demands the allocation of arrays comprising both 32bit integer and 64-bit double types with lengths equivalent to the number of non-zero elements per row. Given the constraint of shared memory space on GPUs and the inherent inefficiency of global memory access, implementing an intermediate solution that allocates space in the global memory of the GPU would precipitate substantial performance degradation. To mitigate the collision rate, we have adopted a twofold approach: the allocation of a hashmap with ample space exceeding the basic requirements, and the detection of hash collisions during the symbolic stage. The pseudo-code for the hash accumulator, inclusive of collision detection, is presented in Algorithm 1. For rows exhibiting excessively high collision rates, we document and subsequently reprocess them utilizing a Dense accumulator.
During the numeric stage, the accumulation, compression, and sorting steps are primarily time-consuming due to hash linear probing in the accumulation step, and sorting often occupies much of the numeric runtime. Approaches represented by NSPARSE commonly utilize the count sort algorithm to orderly arrange the non-zero elements of the accumulator immediately following the accumulation step, all within the confines of the same kernel function. Although this algorithm obviates the need for atomic thread operations, its O(NNZ 2 c row ) time complexity causes the execution time to rise exponentially with the increasing number of non-zero elements per row in matrix C. DeltaSPARSE expedites the sorting step by introducing radix sort and selecting between count sort and radix sort based on the number of non-zero elements per row. Specifically, we obtain the threshold for the number of non-zero elements per row through experiments on the SuiteSparse dataset. For rows below the threshold, we continue using the count sort algorithm, i.e., counting the number of column indices smaller than the target element among the row's non-zero elements. For rows exceeding the threshold for non-zero elements, we write the disordered and compressed accumulated results into global memory and then employ radix sort for sorting.
Dense Accumulator For large and dense rows, the hash strategy suffers from severe performance degradation due to high memory requirements, high collision rates, and timeconsuming sorting processes. We introduce a dense accumulator to handle these rows, with an allocation of a linear array with a length equivalent to the output matrix's column count. This approach fundamentally eliminates the need for hash collisions and sorting operations since the array index directly serves as the element's column index. As storing an element's column index becomes unnecessary, more intermediate results can be stored within hardware limitations. In extreme cases where an array with the size of the column index range cannot be instantiated in shared memory, the intermediate results for different column index ranges must be processed through iterative loops. To minimize the number of iterations, we analyze different platforms and hardware conditions to establish the maximum column index range.
We employ a bitmap to record the column indices of nonzero elements during the symbolic stage, relying primarily on atomic operations in shared memory. The introduction of a bitmap greatly reduces memory requirements. In the numeric stage, we allocate a linear array to store the intermediate results in addition to declaring a bitmap array to depict nonzero element distribution. After each iteration, we apply the prefix sum algorithm to obtain and write partial results.
Adaptive Strategy
In the context of our study, the hashing strategy proves advantageous for matrices with small and sparse rows, whereas the dense strategy finds its utility in handling larger, denser matrices. The judicious selection of an appropriate accumulator, guided by the sparse characteristics of the rows, plays a pivotal role in optimizing performance, especially when dealing with irregularly sparse matrices. Through experimentation, we observed that among the myriad of influencing factors, the sparsity of matrix C's rows exerts the most significant influence on accumulator performance. Our empirical findings led us to establish a threshold of 7.60% sparsity as the criterion for strategy selection. Specifically, when the sparsity exceeds this threshold, opting for a dense accumulator is warranted, while a hash accumulator is the preferred choice for sparsity falling below this critical value.
B. Hierarchical Task Scheduling
In order to extend SpGEMM to a multi-GPU context while ensuring load balancing, maximization of hardware utilization, and minimization of algorithm execution time, it is essential to investigate the critical issue of designating appropriate computational tasks and allocating them across distinct levels of parallel hardware. However, devising task partitioning strategies is a complex endeavor owing to the irregular sparsity witnessed in sparse matrices and the inherent intricacies of the SpGEMM operator.
To address this challenge, we propose a hierarchical task partitioning strategy comprised of global and local task partitioning. The former manages the distribution of tasks among multiple GPUs, while the latter is responsible for the rescheduling of local tasks within an individual GPU. Global Task Scheduling Model In the context of dense matrix multiplication, the prevailing strategy entails an even distribution of rows among GPUs. This approach ensures optimal load balancing due to the uniform distribution of non-zero elements characteristic of dense matrices. However, sparse matrices exhibit substantial disparities in row lengths and positions, resulting in irregular sparsity. As depicted in Figure , the 'email-Enron' matrix demonstrates significant differences in row lengths-a trait inherent to irregular matrices frequently encountered within the SuiteSparse dataset. Additionally, the product matrix C displays analogous irregular sparsity, with a pronounced disparity between its maximum row length of 16,691 and minimum of a mere 510.
To establish a rational task partitioning methodology for matrices possessing these attributes, it is imperative to first devise a strategy for evaluating the costs linked to each subtask. Contrary to utilizing the sparsity of matrices A or B as a basis for partitioning, the sparsity of matrix C provides a more direct measure of the computational and memory access expenses. Consequently, the objective during the global task scheduling phase centers on evenly distributing the non-zero elements in matrix C among GPUs, thereby facilitating optimal partitioning and allocation of tasks.
1 upper ← 0; 2 foreach nonzero entry a ij in a i * do 3 upper ← upper + rpt B[j + 1] -rpt B[j];
In the symbolic phase, an upper limit on the quantity of non-zero elements per row is determined to estimate the row length and distribution of matrix C. This procedure is exemplified in Algorithm 2 and possesses a complexity of O(nnz). Notably, this process eschews the use of atomic operations, thereby yielding low computational expenses. Subsequently, during the numeric phase, the row-wise tallies of non-zero elements acquired from the symbolic phase are employed for the purpose of global task partitioning.
Algorithm 3 delineates the GPU rendition of the task partitioning algorithm. Although the complexity of this algorithm, O(np*m), is higher than that of algorithms premised on binary search, O(np*log(m)), where m indicates the number of rows in matrix C. However, it capitalizes on the thread resources provided by the GPU platform to yield a markedly superior execution efficiency when juxtaposed with the CPU variant of the binary search algorithm.
The symbolic and numeric phases receive as input the upper bound array of row non-zero element counts, denoted as upper, and the array of row non-zero element counts, denoted as nnz per row. Employing these inputs, the algorithm calculates the prefix sum in order to obtain the row pointer rpt c of matrix C. The ultimate output consists of the starting row index for each GPU task.
To efficiently manage multiple GPUs simultaneously, we assign a CPU thread to each GPU. After the partitioning is completed, each GPU in the symbolic phase allocates GPU memory to store the local row non-zero element counts of matrix C based on the assigned number of rows. Similarly, in the numeric phase, each GPU allocates GPU memory to store the local row pointers, column indices, and non-zero element values of matrix C based on the assigned number of rows and non-zero element counts Subsequent to the fulfillment of tasks by the individual GPUs, the results are consolidated onto a singular GPU. As no overlap occurs between the tasks carried out by distinct GPUs,
Local Task Scheduling Based on Decision Trees
The greatest challenge faced by the SpGEMM algorithm is irregular sparsity, as illustrated in Figure . When this problem is divided into two subtasks, the first subtask displays a maximum row length of 16,691 and an average row length of 2,235, while the second subtask presents row lengths of 6,125 and 510. Such considerable disparities in row lengths and distributions create challenges for achieving efficient parallelism and memory access on GPUs. In order to address the aforementioned issue, inspired by the binning strategy utilized by NSPARSE , we have developed a local task scheduling model based on decision trees, which facilitates secondary partitioning of GPU-local tasks within both the symbolic and numeric phases, as well as the allocation of storage and computational hardware resources. The primary objective of this approach is to enhance resource utilization and ensure optimal load balancing.
During the symbolic phase, rows are reorganized and par- titioned based upon the range of upper bounds for non-zero element counts. For rows with varying upper bounds, a hybrid accumulator is employed, which adaptively selects between a hash accumulator and a dense accumulator. In an effort to decrease collision rates within the hash accumulator, the size of the hash table is set to twice the upper bound of nonzero elements per group. Furthermore, the thread block size is configured to be half the size of the hash table, thereby promoting increased concurrent execution of thread blocks per streaming multiprocessor (SM) and enhancing hardware resource utilization and occupancy. Table delineates the partitioning range and parameter settings. It is important to highlight that, despite the fact that Dense accumulator necessitate the allocation of a larger quantity of shared storage space in comparison to hash accumulator, the storage cost during the symbolic phase remains considerably low due to the inherent lack of necessity to store the values of non-zero elements. Furthermore, Dense accumulator efficiently eradicates the significant expense associated with hash conflicts. Consequently, when encountering a scenario where the upper boundary of non-zero elements surpasses 1025, our preferred choice is to utilize Dense accumulator directly. During the numeric phase, we reorganize the partitions according to the range of non-zero elements derived from the symbolic phase, with the partition boundaries and parameter configurations presented in Table . Upon surpassing a Hash table size of 4096, the shared storage demands of the Hash accumulator begin to exceed the hardware constraints imposed by specific GPUs, causing the atomic operations and sorting procedures in global memory to result in a considerable decrease in performance. Consequently, we opt to employ Dense accumulator in these situations.
Local task partitioning does not consistently yield positive results. In two particular scenarios, task partitioning might offer limited advantages or potentially result in diminished performance:
• Low computational workload: In the case of matrices characterized by a limited number of rows and nonzero elements, the duration dedicated to partitioning may approach or even exceed the required computational time. • Low Degree of Irregularity: Low degree of irregularity signifies that there is a minimal difference in the lengths among various rows, indicating that they have similar resource requirements. To attain optimal performance across diverse tasks, we introduce an innovative lightweight decision tree analysis strategy. This approach is employed to discern the necessity of task partitioning implementation. The employment of a solitary threshold for strategical selection proves insufficient when aiming to identify the ideal strategy for matrices displaying diverse characteristics. Taking into consideration the contributing factors to partitioning performance, as well as the potential computational costs of supplementary analyses, this study ultimately identifies the sparsity of matrix C (sparsity c), the average number of non-zero elements per row in matrix C (row nnz avg), and the maximum number of non-zero elements per row in matrix C (row nnz max) as the pertinent features. It is important to note that, in the context of the symbolic phase, the upper limit of non-zero elements is utilized in lieu of the actual non-zero elements. In order to mitigate overfitting in the decision tree model, we imposed a maximum depth limit of 4 and allocated two-thirds of the dataset for training purposes, while the remaining portion was reserved for validation.