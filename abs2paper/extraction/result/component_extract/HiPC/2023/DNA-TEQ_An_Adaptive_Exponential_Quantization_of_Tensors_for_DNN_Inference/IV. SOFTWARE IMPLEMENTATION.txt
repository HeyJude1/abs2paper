IV. SOFTWARE IMPLEMENTATION
In this section, we propose a software implementation of DNA-TEQ using Intel SIMD extensions that leverage the vector processing capability of CPUs. Then, we discuss the scalability issues and limitations of SIMD when implementing DNA-TEQ compared to an optimized SIMD version of INT8.
To efficiently implement the popular INT8 DNN models, Intel introduced the Vector Neural Network Instructions (VNNI) as an extension of the AVX-512 set. One of the key instructions, VPDPBUSD, fuses three operations into a single one, accelerating the inner-loop multiply-accumulate of INT8 convolutions. This instruction can simultaneously perform 4 MAC operations for 16 different output neurons. Figure presents the pseudo-code of our best-effort to implement an FC layer with INT8 VNNI. Quantization and de-quantization functions are also implemented using SIMD intrinsics, although not shown in the code for the sake of simplicity.
Figure depicts the pseudo-code of the DNA-TEQ SIMD implementation of an FC layer. As described in Section III-C, DNA-TEQ performs the dot-product by counting the frequency of exponents for each term. Therefore, each layer requires a different amount of 8-bit counters per neuron (i.e. array counters) based on the numerical precision determined by our search algorithm. These array counters can be allocated in memory, and the Scatter-Gather instructions can read from or write to them based on the pointers. However, the major drawback of Scatter-Gather is that it produces a huge amount of data movements in the memory hierarchy, incurring in a significant latency per operation. To mitigate this issue, we allocate the array counters within SIMD registers. These registers are limited both in quantity (e.g. 32) and size (512 bits), reducing the amount of indexations (i.e. counting operations) that can be done in parallel, since we can only index one register at a time. For example, the level of parallelism is restricted to 2 and 4 different output neurons when the numerical precision is 5-bit and 4-bit, respectively. In the best case scenario, when the numerical precision is 3-bit, 8 output neurons can be computed concurrently. Intel also provides with the permutexvar instruction, which we use to shuffle the registers of the array counters using the corresponding exponents as indexes.
Table presents the execution times of FC layers for different configurations and schemes. DNA-TEQ can provide significant speedup over the baseline and, in particular, up to 5x when the size of the FC layer becomes bigger. This is   mainly due to the replacement of multiplications for counting operations and the reduction of data movements. DNA-TEQ operates within SIMD registers avoiding expensive load/store. However, we observe a slowdown when the precision starts to increase. This can be attributed to the number of counters required and the limited amount of SIMD registers and its size. In the worst case, when precision is higher than 6-bit, we can not allocate enough registers, and need to relay on additional transformations to perform the counting, incurring in more data movements. On the other hand, VNNI is highly optimized for the INT8 representation, providing a substantial degree of parallelism. Consequently, dedicated hardware is required to exploit all the advantages offered by DNA-TEQ.
D W Z D W Z W s Z W s Z s W Z s W Z s W Z s W Z s W Z s W Z s W Z s W Z D W Z D W Z D W Z D W D D D D D Z s W Z s W D Z D W Z D W Z D W Z D W Z D W Z D W Z D W Z D W Z D W Z D W Z D W Z D W Z D W Z D W Z D W sĂƵůƚ Z W Z W &^D ĚĚƌ