IV. IMPLEMENTATION
The system was implemented in Python. As machinelearning framework, we used PyTorch . An MLP of nine linear layers was used, with a maximum width of 2,000. Normalization and dropout layers were used to enhance performance. (Leaky) ReLU functions were used as activation layers, except for the last layer, where a sigmoid function was used (which was observed to improve performance). The full architecture is summarized in Figure . The length d of the output vector (which corresponds to the length of vector θ) is 700. As loss function L, we used the Mean-Squared Error (MSE) loss function. The data set (X, Y ) used for training consists of a maximum of random 3000 samples from D; for t ≤ 3000, (X, Y ) = D. The minibatch size was initialized at 1, and slowly increased as D increased, to a maximum of 16.
The MLP was retrained after 50 episodes, and then at intervals of 500 episodes. Of the dataset, 85% was used as a training set, and the remaining 15% as a validation set. Backpropagation is performed using the Adam optimizer . Training is done for 500 episodes, the weights of the episode with the lowest validation loss are retained. As for the reward function: as LinUCB strives to maximize the reward value, and our goal is to minimize either costs or execution time, we defined the reward function r(x) = 1 x , with x the costs in dollars, or the execution time in seconds. The parameter set was scaled using StandardScaler, the rewards were scaled using PowerTransformer, both from the sklearn.preprocessing library for Python.