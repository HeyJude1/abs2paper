III. IMPLEMENTATION
A. Static Hybrid Implementation
The HEaaN library in its default GPU implementation performs all GPU memory allocations using the stream-ordered cudaMallocAsync. This causes memory allocations to be limited to the maximum GPU size. We initially implement CUDA UM by replacing all host and GPU memory allocation with cudaMallocManaged. This guarantees that OOM won't occur, as long as memory usage is bounded by host DRAM capacity, or even secondary storage capacity if swap memory is used, albeit with performance degradation. The performance degradation that we found from just replacing asynchronous memory allocation with managed memory was significant. After profiling several homomorphic operations using CUDA nsys , we noticed that there was a difference in both individual kernel latencies, and that the GPU was actually idle a significant portion of the time during operations.
The HEaaN library in its default GPU implementation performs all GPU memory allocations using the streamordered cudaMallocAsync. This causes memory allocations to be limited to the maximum GPU memory size. We initially implement CUDA UM by replacing all host and GPU memory allocation with cudaMallocManaged. This guarantees that OOM won't occur, as long as memory usage is bounded by host DRAM capacity, or even secondary storage capacity if swap memory is used, albeit with performance degradation. The performance degradation that we found from just replacing asynchronous memory allocation with managed memory was significant. After profiling several homomorphic operations using CUDA nsys , we noticed that there was a difference in both individual kernel latencies, and that the GPU was actually idle a significant portion of the time during operations. Figures show the multiplication operation profiled on after using only asynchronous memory and managed memory allocation respectively. We notice almost a 5fold increase in operation latency, from 4.8 ms to 24 ms. This overhead occurs even if memory is not oversubscribed. After careful analysis, we realized that certain kernels were running alongside the cudaFree CUDA API. Because this causes a device-wide synchronization after each call, we determined that this was causing performance to degrade. Allocation of temporary variables in the middle of code would cause the destructor to be called when the code goes out of scope. This causes cudaFree to be implicitly called, and led to the significant delays due to the synchronization. We initially approached the situation by reusing the temporary buffers after each operation to avoid the buffers from being freed. However, this was only a temporary solution, as it led to error prone code dealing with double pointers, and was tedious to implement, with buffers still being allocated in the first iteration of each operation causing delays. Even though each operation slightly This led us to think of the hybrid approach, where we would allocate temporary buffers with cudaMallocAsync and every other buffer with cudaMallocManaged. We added the secondary method of allocation to the general buffer allocator in the HEaaN library, and allocate all temporary buffers with an additional flag denoting that asynchronous allocation would be performed. By doing so, and also similarly applying other techniques for unified memory like prefetching and memory advising (cudaMemAdvise) constant values to be read only, or to forcefully reside in GPU memory buffers by setting the SetPreferredLocation flag, we were able to decrease operation latency to values that are close to when every buffer is completely allocated asynchronously. In addition to this, we were able to experience the OOM errors that occurred when only asynchronous memory allocation was performed and GPU memory was insufficient to cover all objects. Experimental results of the static hybrid implementation are shown in Figure . Parameters in CKKS are organized based on the amount of memory they consume. Refer to Table for details on the parameters. For bootstrapping in all parameter sizes, memory is oversubscribed because all GPU memory objects do not fit within the bounds of 2GB of VRAM. For other operations, GPU memory is oversubscribed in the FVx parameter and not for the other parameter sizes.
Combining asynchronous allocation with unified memory in a hybrid approach by statically allocating the temporary buffers with cudaMallocAsync leads to lower latencies than the baseline 100% unified memory approach. Techniques like memory advise are also statically applied to buffers with constant values required for calculations in the GPU. Latency for the addition operation is small enough to be negligible in both approaches. For other operations like multiplication, rotation, and conjugation, there is a significant range of fluctuation for the baseline unified case in each iteration, while the asynchronously allocated case has a more stable, yet lower latency. Although it is not shown here, the hybrid allocation of temporary buffers and and other memory objects does not reduce latency to the extent of fully asynchronous memory allocations. However by performing this experiment, we are able to see that it is possible to combine the usage of both memory allocation schemes.
B. Hybrid Memory Allocation Ratios
We performed an experiment using hybrid allocation on a test CUDA program in order to determine the optimal ratios of performing asynchronous allocation with unified memory allocation. Figure show the results of the program. Each sub-graph shows a different oversubscription ratio of how much of the total GPU memory available is allocated using managed memory and asynchronous allocation combined. The maximum amount that asynchronous allocation can use is 100% (technically around 95% because OOM occurs at levels above that due to a fixed amount of memory required by the CUDA driver) so we performed the experiment using eight different ratios: 0%, 25%, 50%, 75%, 80%, 85%, 90%, and 95% asynchronous allocation. For oversubscription values over 100%, the remainder memory would be allocated using cudaMallocManaged. We measured, the allocation latency, memory copy latency from host to device, and the kernel latencies doing two different operations: one is simple random addition, and the other is 8-point butterfly , which is a computation used in FFT (fast Fourier transformation) algorithms. In order to perform the kernel operations, we allocate pages in 4KB chunks and randomly mix the pointers pointing to each chunk in an array. We then execute either the addition or butterfly kernels.
We noticed that for both Figure , higher asynchronous allocation ratios increased the time for all operations. However, increasing oversubscription rates also significantly decreases performance of all operations. The meaning of 100% oversubscription rate is that data covers total available GPU memory once. Rates above 100% mean that data is insufficient Fig. . Comparison of allocating all objects with UM to the hybrid method of allocating temporary buffers with cudaMallocAsync statically, and all other objects with UM in a Geforce GTX 1660 Ti with 6GB of VRAM, latency in milliseconds to be contained fully in the GPU. When oversubscription rate is 200%, meaning that data is two times the size of total GPU memory, we can see that operational latencies are almost one magnitude of order slower than when data can be fully subscribed. This is due to page faults caused by using CUDA Unified Memory. Nevertheless, maintaining a higher asynchronous allocation mode, despite oversubscription ratios gives the greatest performance for all operations. Therefore, we apply this knowledge in the dynamic allocation scheme.
C. Profiling Allocation Scheme
Manually inserting explicit allocation commands like allocate_async() can be cumbersome to apply to all GPU objects in frequently maintained code bases like the HEaaN library. Due to the HEaaN library design, the majority of allocated objects except temporary buffers are implicitly allocated using the general memory buffer allocator. This requires the programmer to statically create exceptions for every single GPU buffer in the library code, depending on where the object is automatically freed once it goes out of scope. Not only is it cumbersome and bug-prone to alter the code for all of these cases, but statically modifying the allocation method for each and every object can also cause diverse run-time performances depending on the specific GPU hardware used. As a result, this results in modifying the library code base in a very invasive manner. During the lifetime of any large-scale user workload running the HEaaN library, there are also a large number of user-determined objects that can be created like additional ciphertexts. This adds disadvantages in the static method because the user who uses the library must be aware of which allocation method they have to use. Therefore, instead of the static method, we prefer a minimally invasive dynamic method where the programmer or user does not have to directly care about which allocation method to use for every single GPU object.
Profiling homomorphic workloads in runtime can give us important details about whether or not an object should be allocated asynchronously. Our idea is based on the fact that GPU objects with shorter lifetimes should be allocated asynchronously, because managed memory allocation has the heavy overhead of device synchronization. Figure shows a step-by-step process of this method. In step 1, we run through the entire HE workload pass once with our profiler enabled. In this stage, we collect data such as GPU object ID, whether it is allocated or freed, the size of data, and the time stamp. Once we collect the data, we store it in a CSV file, and run a Python script to process the raw CSV format. In step 2, The Python script calculates the lifetime of each GPU object based on its timestamp and when it is allocated and freed using its ID as the identifier. We also determines a threshold async peak threshold to determine the maximum amount of data that we choose to allocate asynchronously on the GPU. We organize the GPU data based on the lifetime of all GPU objects in ascending order. Then we choose N, which is the upper limit of the lifetime (in seconds) of GPU objects that we wish to allocate asynchronously. Then, we store the data in order of the GPU id, denoting a 0 for managed memory allocation, and a 1 for asynchronous allocation. Then, in step 3, we use the profiled data to allocate each GPU object accordingly in all future passes. Because the order of the allocation of objects does not change in subsequent passes, we can use this profiling method as an "oracle" to determine the optimal choice of allocations for all future passes. Performing this method is good for workloads where repeated runs are necessary.
We perform this method using two different workloads. The lighter workload which uses less memory is the bootstrapping operation, which we use in CKKS often to decrease multiplication errors and was described earlier in Section II-D. This workload is called BM-bootstrap , and is a custommade workload that tests all the different CKKS bootstrapping operations across all parameter sizes. The heavier workload is HE-enabled pre-trained ResNet-20 , model using MNIST for inferences. Both workloads are large enough in that they do not fit in NVIDIA A40 GPU, which is equipped with 48 GB of VRAM. We created a scatterplot in Figure which shows an entire view and a zoomed in view of the lifetime of all GPU objects. We plot the allocated point in green, and the free point in red, with arrows in opposite directions as markers, as shown in the graph legend. For BM-bootstrap, allocation and free continuously occurs as the program is running until the end. Most objects are freed as soon as they are allocated. However, there are a few objects which are not freed until the end of the program, shown as the sparse red dots at the end of the graph. By zooming in the object IDs until range 1,000 in the second sub-plot, we can see that a few objects are never freed until the end of the program. This is also true in the case for ResNet, however the point in which certain objects are more variable than in the case of bootstrapping. This shows that different workloads have different timings for allocation and free, and different objects have different lifetimes.
Figure shows the lifetime of all objects for the BMbootstrap and ResNet-20 workloads. The first and third graph show number of occurrences of objects with lifetime below 1 second in log scale, because they constitute the majority of all objects. In both workloads, the majority of GPU objects have a lifetime below 1 second, constituting approximately 92% of all GPU objects for BM-bootstrap. The objects in this range and lower would thus be assigned a value of 1, meaning to be allocated asynchronously (0 to be allocated using managed memory), when we set N=1 as the lifetime threshold. Beyond the first second, the number of occurrences of different lifetimes are quite variable. The second and fourth sub-plots show these objects and their lifetimes. In the case of BM-bootstrap, changing the parameters as the workload is continuously running causes the lifetime of longer objects to change, explaining the intermittent spikes in the first sub-plot.
Figure shows the memory usage of asynchronously allocated and managed memory objects. The threshold value is the N value for the lifetime of objects that we set to be asynchronously allocated. The blue line shows the peak memory usage of asynchronously allocated objects at that point in time during the execution of the workload. The orange line shows the peak memory usage of managed memory. The red line shows the maximum available GPU memory of the device, which is an A40 GPU having 48GB of total memory available. This shows that until N=256, asynchronous allocations do not consume more memory than physically available, and once lifetime threshold becomes 512, we can see some potential for OOM errors to arise due to memory consuming more than physically available device GPU memory.
D. Dynamic Allocation Scheme
Profiling requires the workload to be run to completion initially in a single pass to know the lifetime of all the GPU objects. It is not truly dynamic in the sense that optimizations can only occur after the initial pass. If the workload takes a long time, and is not repeated more than once, using the profiling scheme may not provide any benefit at all. We introduce a dynamic scheme in this section, which does not require any prior knowledge of the allocated GPU objects, and Fig. . Allocation and free scatter plot of all GPU objects created during the lifetime of workload adjusts the allocation methods on-the-fly. We take advantage of the fact that objects with short lifetimes are repeatedly re-allocated as the program progresses. When the objects are re-allocated, we use our decision process to determine whether the object should be allocated asynchronously or under managed memory. Therefore we do not have to perform any modifications of existing pointer allocations by performing pointer switching or memory transfers. Figure shows an example of how we perform our decision making. Because there is no "oracle" to give us the deterministic outcome of the lifetime of every single object, we have to use heuristics in this approach. The information given to us during every memory allocation is only the size of the object to be allocated. Therefore we maintain a map where the key is the size of the buffer to be allocated and the value is the number of active allocations that have not been freed Fig. . Peak memory usage of GPU objects depending on time on an A40 GPU equipped with 48 GB VRAM yet, along with a ten-element active list. Every time an object has been freed, the total number of allocations is reduced by one. Every time an allocation is made, the total number of allocations increases by one. We also maintain an active list, that records the number of active allocations of that particular size currently residing on the GPU. Currently the size of the list is 10. Every time an allocation is made, the total number of allocations is pushed to the end of the list. Once the list is filled up, the first element is then replaced. When the list has not been filled up to ten elements yet, we allocate all objects using managed memory. Once the list is filled up, we measure the range of the queue by getting the maximum value and subtracting it with the minimum value. Then we compare the range with a preset value that we decide, and use it to determine whether or not the object should be asynchronously allocated, as shown in steps 3-5 of Figure .
We noticed a trend in that if objects have a short lifetime, there tends to be a repetitive tendency of allocation and frees happening within a short time span. In this case, the range of the list would be small, because active objects would continuously increase and decrease in a similar pattern. Objects that have longer lifetimes would actually increase the number of active objects, and thus increase the range of the active list. Therefore, we use a conditional branch to decide if the range is below a certain X value, to allocate all objects with that size in that manner, until the range of the active list changes again as more objects are added. This heuristic doesn't guarantee that all objects with short life times are asynchronously allocated, like in the previous section, but it does not require a profiling step, and also does not require static modifications to any of the HEaaN library code, in that only the allocator module is changed in an isolated manner.