I. INTRODUCTION
Fully Homomorphic Encryption (FHE) is a cryptographic scheme that enables computations to be performed directly on encrypted data, without the need for decryption. FHE holds immense potential for preserving privacy and security in various domains, such as cloud computing, machine learning, and data analysis. However, the practical deployment of FHE is impeded by its high computational and memory requirements, which can limit its ease of usage.
Graphics Processing Units (GPUs) have emerged as powerful accelerators for a wide range of computationally intensive tasks, including cryptographic operations. Leveraging This work is supported by CryptoLab. This work was also supported in part by the National Research Foundation of Korea(NRF) grant funded by the Korea government (MSIT) (No. NRF-2021R1A2C2003618). Prof. Yeom is the corresponding author of this paper.
the parallel processing capabilities of GPUs can potentially overcome the performance bottlenecks associated with FHE computations, particularly with bootstrapping . However, GPU memory is typically limited in comparison to host DRAM memory, and cannot be expanded easily. This is particularly true for cost-efficient retail GPUs used in most home or workspace environments. Server-based GPUs are quite expensive, and cannot be readily accessed in many environments. Therefore, efficient memory management plays a crucial role in optimizing the execution of FHE algorithms on retail GPUs.
In this paper, we investigate the use of a hybrid memory allocation strategy, combining cudaMallocAsync and cudaMallocManaged, on the HEaaN library . The cudaMallocAsync function allocates device memory asynchronously, which results in performance improvements compared to traditional GPU memory allocation. On the other hand, cudaMallocManaged provides a unified memory abstraction that allows for data swapping between the host and the device all managed by the CUDA driver, preventing OOM from occuring. Our research focuses on evaluating the performance characteristics and memory management tradeoffs of utilizing hybrid memory allocation techniques in FHE applications.
By benchmarking various FHE operations using our scheme, we aim to quantify the benefits of the hybrid cudaMallocAsync and cudaMallocManaged approach in terms of computational speed. Specifically, we assess the performance impacts of increased data movement and synchronization overheads resulting from using managed memory and on improved memory allocation performance by using asynchronous GPU memory allocation.
In summary, this paper aims to explore the advantages of utilizing hybrid memory allocation techniques for FHE on GPUs. We will present experimental results highlighting the performance gains achieved through the hybrid cudaMallocAsync and cudaMallocManaged approach, without resulting in traditional OOM problems. As far as we know, we have not seen any published work that adopted a method using GPU hybrid memory allocation combining both stream-ordered memory allocation and managed memory.