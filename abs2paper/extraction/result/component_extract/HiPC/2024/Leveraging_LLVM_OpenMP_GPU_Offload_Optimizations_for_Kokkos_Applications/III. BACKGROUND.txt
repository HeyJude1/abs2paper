III. BACKGROUND
Kokkos enables developers to write a common code base that can compile and run on multiple CPU and GPU architectures with minimal changes. Fig. shows its available backends and supported architectures. Execution patterns such as parallel_for and parallel_reduce are provided for parallel iteration over loop ranges or items in a view (Kokkos multidimensional array). The body of the loop is specified as a C++ lambda. The parallelism may be flat or hierarchical. This paper presents modifications to the implementation of the execution patterns in one backend and hence user code changes are not required to benefit from the optimizations described.
While OpenMP has been available since the late 1990's for CPUs, OpenMP GPU offload is a more recent development, both in the API specification and in compiler implementations. The widely used parallel for directive creates a team of threads that execute a loop in parallel. When used in a target construct along with teams distribute for GPU offload, it results in the creation of multiple teams spread across the blocks of a GPU, wherein, each team has multiple threads running in parallel. Fig. shows how OpenMP offload parallelism corresponds to parallelism in Kokkos and CUDA. However, the mapping does not indicate fully equivalent behavior. Firstly, below the thread level, the simd directive can enable vector parallelism, but this directive is commonly ignored by many compilers when generating GPU code. Secondly, simple block and thread indexing in grid languages like CUDA keeps overheads low, in comparison to the more heavyweight state required by OpenMP semantics. A major focus of the work described in this paper is the adaptation of the grid style expression of parallelism to OpenMP offload, as well as GPU scratch memory use and optimization of reduction operations.