VI. CONCLUSION
OpenMP is a widely used parallel programming model with support from open source and vendor compilers. However, adoption of OpenMP offload for GPUs has been more limited. Contributing factors include lack of support for advanced optimization techniques, e.g., use of dynamic memory shared among a team of threads, and heavyweight runtime library requirements compared to the simple multi-dimensional grid model of CUDA and HIP.
In this paper we have discussed two extensions to the LLVM/OpenMP ecosystem for GPUs, 1) the ability to request dynamic shared memory within a team and 2) the option to write SIMT style code in OpenMP. Together the extensions bridge key feature gaps between native frameworks such as CUDA/HIP and OpenMP. We have also shown how the extensions can be combined with additional performance tuning extensions in LLVM/OpenMP such as shuffle instructions to further optimize reductions on GPUs. The result is that users can leverage OpenMP's wider portability compared to vendor supported frameworks without major performance penalties.
We have demonstrated the use of new extensions in performance portable frameworks through the exemplar of Kokkos, in which we have extended the OpenMPTarget backend to use LLVM/OpenMP extensions when offloading Kokkos execution patterns to GPUs. Using these extensions, the performance of representative programs is now competitive with the native (CUDA/HIP) backends of Kokkos on NVIDIA and AMD GPUs. Our demonstration of these extensions provides motivation for the OpenMP Language Committee to consider adoption of them in the API for eventual availability in other OpenMP implementations beyond LLVM. Moreover, our evaluation of Kokkos with LLVM/OpenMP extensions provides evidence of viability for OpenMP GPU offload in large C++ based projects for performance portability.