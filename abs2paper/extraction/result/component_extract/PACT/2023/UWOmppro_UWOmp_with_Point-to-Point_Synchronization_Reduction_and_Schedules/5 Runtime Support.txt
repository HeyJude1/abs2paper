5 Runtime Support
We now describe the extensions to the OpenMP runtime that we made to support the key operations supported by the language extensions defined in UWOmp ğ‘ğ‘Ÿğ‘œ : signalling, waiting, performing reduction and supporting the different scheduling policies of OpenMP. We will start by describing our novel design of the communication sub-system between the activities of each parallel-for-loop that forms the basis for these key operations.
5.1 Shared Postbox System for Communication
We present a postbox based system for communication between the activities of a parallel-for-loop. We discuss the design of three types of postboxes: signal-only, data-messages-only, or mixed signals and data-messages (mixed-mode). 5.1.1 Design of the Postbox.Each activity ğ‘‹ ğ‘– of a parallel-for-loop, may receive one or more signals/data-messages from other activities. To avoid contention among the communicating activities, we associate a postbox with each activity ğ‘‹ ğ‘– . Thus, the postbox ğ‘ƒ is an array of ğ‘ elements (where ğ‘ is the total number of activities), such that each element ğ‘ƒ ğ‘– represents the postbox of ğ‘‹ ğ‘– .
We observed that for most of the parallel-for-loops using pointto-point synchronization, the number of activities that an activity communicates with, in a phase, is small. Based upon this observation, for such loops we set each postbox ğ‘ƒ ğ‘– to be a hashmap (of initial-size set to a constant ğ‘˜, with load factor set to a constant  ğ‘€%). Note that there are two straightforward alternatives to our proposed scheme: (i) each post-box entry ğ‘ƒ ğ‘– , is an array of ğ‘ slotsno locking required among the activities communicating with any particular activity ğ‘‹ ğ‘– , but leads to high space wastage. (ii) each post-box entry ğ‘ƒ ğ‘– is represented as a linked-list -low space overhead, but may lead to significant performance overheads due to the locking contention among the activities communicating with any particular activity ğ‘‹ ğ‘– . We use the hash-maps as a middle ground for supporting communication among the activities. In Section 6 we discuss an optimization where we can further reduce the overheads of this hash-map based postbox to a large extent for the common case of all-to-all communication (with static scheduling policy).
The exact configuration of the slots of each postbox entry depends on the type of communication: signal-only, data-only, or mixed-mode. We briefly explain the first two modes and then explain the mixed-mode type of postbox, in more detail.
Signal Only Postbox If the communicating activities are guaranteed to never send/receive any data-messages, then we simply represent each slot in the hashmap as a list of pairs of the form (sender, counter). When an activity ğ‘‹ ğ‘– wants to send a signal to ğ‘‹ ğ‘— , we simply increment the counter of ğ‘‹ ğ‘— in ğ‘ƒ ğ‘– At the receiving activity, we atomically decrements the counter, if non-zero we return 1. Else, we return 0 (indicates that the signal is not yet available).
Data Only Postbox If the communicating activities are guaranteed to send/receive only data-messages, then we represent each slot as a list of pairs of the form (sender, data-message). When an activity wants to send a data-message, we append the message to the appropriate list, and for the receiving activity we take out and return the first message of the sender available in the list. If no such message is available, we return NULL.
Mixed-mode Postbox. We use this type of postbox, when the communicating activities may send either type of messages. We implement each slot as a list, where each element of the list is of the form shown in Figure . Consider an element ğ‘’ of the form (ğ‘—, ctr, m, next) in one of the lists of ğ‘ƒ ğ‘– . If ctr is non-zero then ğ‘’ represents ctr number of contiguous signals sent from ğ‘‹ ğ‘— to ğ‘‹ ğ‘– . Else, ğ‘’ represents a data-message m sent from ğ‘‹ ğ‘— to ğ‘‹ ğ‘– . For example, Figure shows an example list, on receiving the following signals/data-messages from ğ‘‹ 2 to ğ‘‹ 1 : signal, signal, signal, and data-messages m1 and m2.
The postbox supports two routines: sendMsg and recvMsg. The sendMsg routine updates the appropriate list, and the recvMsg routine returns the appropriate signal/data-message, if available. We skip the details of these routines for brevity. The details can be found in the extended report .  Note: (I) The recvMsg routine is non-blocking in nature. The actual waiting, if at all, is performed by the wait-call invoking the recvMsg of the postbox. (II) We use a static analysis to decide which type of postbox is to be used, based on the signal/wait commands specified in the input program.
5.2 Signal Algorithm
We now describe the wrapper methods emitted by the CPS transformation (Section 4.2) to handle the signal commands: signalCPS, signalSendCPS, signalAllCPS and signalAllSendCPS. The first two methods take variable number of arguments, corresponding to the list of activities to whom the signal/message is to be sent. The wrapper methods signalCPS and signalAllCPS simply call sig-nalSendCPS and signalAllSendCPS, respectively, by passing the message argument ğ‘š as NULL. We now describe the signalSend-CPS and signalAllSendCPS methods (signatures shown in Figure ). An interesting point about these wrapper methods is that they are in CPS form and take the continuation ğ¾ as an argument.
The method signalSendCPS first checks the predicate ğ‘’. If true, it does the actual signalling by sending the message to each receiving iteration. Finally, it invokes the continuation. The design of signalAllSendCPS is similar, except that it stores the message of each sender ğ‘– at the ğ‘– ğ‘¡â„ element of a shared array. The details of these algorithms can be found in the extended report .
5.3 Wait Algorithm
We now describe the wrapper methods emitted by the CPS transformation (Section 4.2) to handle the wait commands: waitCPS, waitRedCPS, waitAllCPS and waitAllRedCPS. The first two methods take as arguments the list of (target) activities from whom the signal/message is to be received. The wrapper methods waitCPS and waitAllCPS simply call waitRedCPS and waitAllRedCPS, respectively, by passing the reduction specific arguments as NULL. Similar to the signal wrapper methods, these methods are also in CPS form. For brevity, we only describe the waitRedCPS and waitAllRedCPS methods.
The method waitRedCPS (signature in Figure ) first checks if the conditional-expression ğ‘’ is true. If so, it first checks if the signal/message has been received from all of the target activities. For each received data-message, it performs the reduction operation. If all the signals/messages have been received, then it invokes the continuation ğ¾. Else, it creates a closure remembering the set of activities whose signals/messages are yet to be processed and void scheduler-static(ğ‘â„ğ‘†ğ‘–ğ‘§ğ‘’) // ğ‘â„ğ‘†ğ‘–ğ‘§ğ‘’ unused here begin // work already divided during enqueing in Figure . executeWL(WL[ğ‘¡ğ‘–ğ‘‘]);  pushes the closure to the appropriate work-queue, before returning from the function. This ensures that the thread executing the wait-wrapper function does not block (or busy wait). The wait-AllRedCPS method works similarly, by waiting for all the messages to be available before performing the reduction. The details of these algorithms can be found in the extended report .
5.4 Reduction Operations
We now highlight some salient points about our reduction strategy. As discussed in Section 5.3, the reduction operation is invoked eagerly for point-to-point synchronization (waitRedCPS), as and when the message from any target activity is processed. However, for the all-to-all synchronization (waitAllRedCPS), we efficiently perform the reduction after all the messages have been received, in a lazy manner. We now describe the intuition behind this design.
One main drawback of the eager method of reduction is that it is inherently serial in nature; hence each activity may take up to ğ‘‚ (ğ‘ ğ‘ ) steps for reduction, where ğ‘ ğ‘ is the number of activities participating in reduction. While for small values of ğ‘ ğ‘ this cost may be minimal, it can be prohibitively high, for large values of ğ‘ ğ‘ ; a common use-case being performing all-to-all reduction (realized by consecutive calls to signalAllSend and waitAllRed commands of UWOmp ğ‘ğ‘Ÿğ‘œ ). To address this issue in case of all-to-all reduction we use the lazy mode of reduction. The algorithm works on the principle of the popular parallel message-exchange based protocol that leads to each activity performing ğ‘‚ (ğ‘™ğ‘œğ‘” 2 (ğ‘ ğ‘ )) steps; in this scheme, after every time step ğ‘¡, each activity holds a reduced value over the messages of 2 ğ‘¡ activities. However, for small values of ğ‘ ğ‘ , we continue to use the eager mode and avoid the storage overhead of the shared array.
5.5 Supporting Different Scheduling Policies
UWOmp++ could not handle any scheduling policies of OpenMP except static scheduling. Considering the importance of scheduling policies beyond static, we also provide support for dynamic, guided and runtime scheduling.
In Section 4.3, we discuss how the getSchedule function handles the runtime schedule option during execution. We now discuss the details of the remaining three schedulers.
static scheduler. The scheduler function scheduler-static (Figure ) simply executes all the closures present in WL . We skip the definition of executeWL for brevity. In this scheduling, each thread maintains its own local worklist and as a result, in the waitRedCPS function (described earlier in Section 5.3), the locking mechanism before and after the enqueue operation is not required.
dynamic-scheduler and guided-scheduler. As discussed in Section 4.3, for dynamic scheduling we use the global worklist. In scheduler-dynamic (Figure ), each thread atomically dequeues (at most) ğ‘â„ğ‘†ğ‘–ğ‘§ğ‘’ number of closures from the worklist and executes them. The scheduler-guided function works similar, except that ğ‘â„ğ‘†ğ‘–ğ‘§ğ‘’ is updated after each atomic dequeue. We skip the code for the same, for brevity.