3 UWOmp ğ‘ğ‘Ÿğ‘œ : Extending UWOmp++
We now describe three new extensions to UWOmp++ that can improve the expressiveness and lead to efficient code. Two of these extensions (support for point-to-point synchronization among the activities, and performing reduction at the point of synchronization) are novel to OpenMP as well. The third extension admits powerful scheduling policies (dynamic, guided, and runtime) of OpenMP, apart from the static scheduling policy that was already supported by UWOmp++. We call this extended language UWOmp ğ‘ğ‘Ÿğ‘œ . Point-to-Point Synchronization. UWOmp ğ‘ğ‘Ÿğ‘œ proposes an extension to UW-OpenMP, where a programmer can specify point-topoint synchronization among the activities of a parallel for-loop. Figure summarizes the list of commands supported by UWOmp ğ‘ğ‘Ÿğ‘œ (along with brief syntax), for easy reference. All these commands are conditional in nature and support (i) signal and wait operations to a subset of activities or all of them, and (ii) (optionally) reduction operations. Note: a signal/wait commands to/on a non-existing iteration are treated as nops. Reduction. Consider the example code snippet shown in Fig. (Source ) to perform iterated averaging on an N element array, written in UWOmp++. Here, each activity ğ‘‹ ğ‘– first computes a new value for the i ğ‘¡â„ element using A[i-1] and A[i+1] and then computes the absolute difference compared to the older value. Towards the end of each iteration of the while-loop, each activity  waits for ğ‘‹ 1 to sequentially reduce the array diff to the shared variable diffSum, which is used to check the convergence condition specified in the while-loop predicate. The sequential reduction operation can pose serious performance overheads. Note that, we cannot use the OpenMP reduction operation to perform the reduction here, as the reduced value would only be available after the end of the parallel for-loop. To address these issues, UWOmp ğ‘ğ‘Ÿğ‘œ supports a blocking reduction operation within the activities of a parallel for-loop. For example, in Fig. , after computing diff[i], each activity ğ‘‹ ğ‘– sends a signal to all the other activities with the value of diff[i]. Then, the code invokes a blocking reduction operation, specifying the variable (diffSum) to hold the reduced value, and the reduction operation (ADD). In contrast to the UW-OpenMP version, in UWOmp ğ‘ğ‘Ÿğ‘œ , all threads together perform the reduction operation in parallel. Further, to reduce the number of message exchanges, Section 5.4 presents an optimization such that messages, linear (not quadratic) in the number of activities are exchanged to perform the reduction. Note: (1) For readability, we use verbose reduction operator names (e.g., ADD in place of '+'). ( ) Like the regular reduction operations in OpenMP, UWOmp ğ‘ğ‘Ÿğ‘œ also supports user-defined reduction operations; details skipped for brevity. Schedules. Due to its design decisions, UW-OpenMP supports only static scheduling. Considering the importance of other scheduling policies of OpenMP, UWOmp ğ‘ğ‘Ÿğ‘œ supports all of them by using a runtime extension. Details in Section 5.5.