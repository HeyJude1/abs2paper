III. RELATED WORK
The importance of random forests and gradient boosting models has triggered a considerable amount of research in recent years to accelerate the inference of decision-treeensemble models on a range of platforms, including CPUs, GPUs , , FPGAs , CPUs with neural network hardware accelerators , and memristor-based memory .
Because of the scope of this paper, this section will focus on CPU-based inference, which can be roughly divided into 1) methods that translate the decision-tree ensemble into compilable code with the decision-tree-node comparisons directly mapped on if-then-else statements or predicates, and 2) methods that generate internal data structures from the decision-tree definitions that are processed by fixed functions to perform the inference. Examples of the first category include TreeLite , VPRED , an optimized version of VPRED using cache-blocking , lleaves , and the optimized 'ifelse' trees presented in , .
Scikit-Learn , XGBoost , LightGBM , ONNX Runtime and the native tree discussed in belong to the second category and implement more conventional algorithms based on breadth-first and depth-first traversal of the decision trees. QuickScorer , takes a different approach that is based on processing feature comparisons related to multiple split nodes throughout the tree ensemble in a first step, followed by determining the actual traversed paths through the trees and the overall prediction result from these processing results that are encoded as bit vectors and are operated on using logical bitwise instructions. This is fundamentally different from conventional tree-traversal algorithms that only process tree nodes when they are on a currently traversed path through a tree. V-QuickScorer is an improved version of QuickScorer exploiting SIMD extensions. RapidScorer can be regarded as a further improvement of QuickScorer removing some of its limitations related to deeper trees. The tree tiling technique proposed as part of the TreeBeard compiler is also based on performing the feature comparisons for all nodes within a given tree tile in parallel using SIMD instructions, from which the traversed paths are then determined. Tree tiles are, however, located within individual trees, and different data structures are used.
Besides the above schemes that process a decision-tree ensemble model 'as is', other optimizations have been proposed that optimize performance by limiting or omitting part of the processing. One example are 'early exit' schemes , which do not process all trees in an ensemble to improve inference performance by compromising slightly on accuracy. Another example are oblivious decision trees such as CatBoost and others , which are constrained to use identical node comparisons involving the same input features and thresholds for split nodes at the same tree depth.
Many of the above methods convert the decision trees into perfect trees of the same size. These are trees in which each split node has two child nodes and all leaf nodes are at the same level, resulting in identical path lengths between the root node and any leaf node. This enables efficient exploitation of SIMD instructions to parallelize multiple tree traversals by performing these in lock-step with all traversals ending at the same time. In order to keep the processing steps simple for SIMD exploitation, typically no node-level optimizations are performed to improve spatial locality properties. The main disadvantage of perfect trees is the exponential growth of the number of nodes as a function of the tree depth, which limits its application to shallow trees (e.g., with a maximum depth up to around eight) to prevent a tree-size 'explosion'. Although perfect trees can work efficiently for gradient boosting models that usually involve more shallow trees, this may not always apply to random forests which can involve deeper tree structures .
When comparing the above related work with the approaches proposed in this paper, the following are notable. In the next section, we will describe two optimized tree traversal algorithms, OBF and ODF, based on conventional breadth-first and depth-first tree traversal concepts, that have been extended to support SIMD vectorization and node-level access probability exploitation (ODF) for both shallow and deep trees. Except for which describes an optimization sorting the most likely child node at the left side but uses a different data structure, we have not found anything similar to our optimizations, in particular related to the efficient application of SIMD vectorization to process deeper trees through partition-and node-level iterations that will be described in the next section. Sections V and VI will present different combinations of SIMD vectorization and multithreading to parallelize multiple tree traversals processing multiple input samples within a batch and/or multiple trees within an ensemble. Although some of the above related work applies similar parallelization concepts in a static fashion, we have not found a comparable approach involving runtime selection between the large number of combinations covered in this paper.