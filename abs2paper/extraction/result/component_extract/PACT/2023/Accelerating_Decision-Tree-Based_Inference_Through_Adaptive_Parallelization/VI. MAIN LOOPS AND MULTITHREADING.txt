VI. MAIN LOOPS AND MULTITHREADING
During inference, all trees within an ensemble have to be traversed for each sample in a given input batch. Consequently, there exist two basic loops in a predict function, one iterating through the samples in an input batch and one iterating through the trees in the ensemble:
for i ∈ {0, . . . , I − 1} do for t ∈ {0, . . . , T − 1} do tree traversal(t, i) end for end for with I being the input batch size, T being the number of trees in the ensemble, i being the index of the current input sample, and t being the index of the current tree being processed. Alternatively, the order of the loops can also be exchanged:
for t ∈ {0, . . . , T − 1} do for i ∈ {0, . . . , I − 1} do tree traversal(t, i) end for end for
The latter code fragment will involve higher spatial and temporal locality properties in relation to the trees that are being processed in the outer loop because each tree structure will be processed during a longer continuous period of time, whereas this applies in a similar way to the input samples for the former code fragment. Although the final prediction result will be the same in both cases, the two loop orders can result in different prediction speeds on a given computer system.
If the predict function uses SIMD instructions to process multiple trees in parallel or multiple samples within an input batch as was discussed in the previous section, then the loop variable t of the 'tree loop' respectively i of the 'input loop' will be incremented by the number of tree traversals that are processed in parallel in each loop iteration using SIMD instructions, denoted here by p. In case the number of trees within an ensemble would not be a multiple of p then this can be resolved by 'padding' the ensemble with additional trees that do not impact the final prediction results (e.g., zero leaf labels). Alternatively, the 'remaining' trees can be processed by non-simd-vectorized predict functions. The same principle can be applied to the input batch in case of SIMD parallelization over the input samples.
In addition to SIMD vectorization, the predict function can also be accelerated using multithreading. As part of the experiments that are presented in the next section, one of the two loops in the above code fragments will be parallelized using OpenMP . If the tree loop is parallelized, special precautions have to be taken to prevent race conditions to occur when the results of two parallel tree traversals that process the same input sample are added to the (intermediate) prediction results of that sample. These precautions (e.g., an OpenMP reduction clause) can, however, negatively affect the performance gain that is achieved through multithreading.
Considering the two possible combinations of the tree and sample loops as inner and outer loops, the three possible applications of OpenMP to these loops (outer loop, inner loop, no application), and the three possible applications of SIMD vectorization (vectorized processing of multiple trees for one input sample, vectorized processing of multiple input samples for a single tree, no application), then this results in a total of 2 × 3 × 3 = 18 possible combinations. The loop order will now be represented by a two character combination ti or it for an outer tree/inner input sample loop respectively outer input sample/inner tree loop. If a loop is parallelized using OpenMP, then the corresponding character will be written as uppercase. If SIMD vectorization is applied to parallelize the processing of input samples or trees then the corresponding character will be underlined. For example, a predict function involving a 'tree outer loop' and 'sample inner loop' with the latter being parallelized using OpenMP, also using SIMD vectorization to simultaneously process multiple trees for a single input sample is represented by the character combination tI. class. 2 28 8250 K 2750 K SUSY class. 2 18 3750 K 1250 K Covertype class. 7 54 11.3 K 3.8 K YearPredictionMSD regr.
-90 463 K 51 K