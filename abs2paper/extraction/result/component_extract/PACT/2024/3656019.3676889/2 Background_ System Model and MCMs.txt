2 Background: System Model and MCMs
In this section, we explain our single-core pipeline model and provide the necessary background on MCMs and how they can be enforced at the pipeline level.
2.1 Single-Core Pipeline Model
We consider a fairly generic pipeline model that supports out-oforder execution of instructions while providing precise exceptions through in-order (i.e., in program order) fetch and commit. The pipeline consists of multiple structures that manage the out-of-order execution. Different cores use different structures, but commonly used examples include the reorder buffer (ROB), load-store queue (LSQ), physical register file, and post-commit store buffer (SB).
Because MCMs concern the ordering of memory operations (loads, stores, fences), PipeGen's transformations focus on the structures that manage the out-of-order execution of memory operations. Even in a single-core pipeline, management of memory operations can be complicated, due to the desire to speculatively execute loads before all previous (in program order) memory operations have completed. To ensure that PipeGen is broadly applicable, we consider pipelines with three quite different designs for managing memory operations as case studies. There are, of course, many designs because of the many possible trade-offs between structure size, complexity, performance, and power, and we considered these three designs to showcase the versatility of PipeGen. In each of these designs there is an issue queue (IQ) into which all of the instructions are inserted in program order. The designs differ from each other based on what happens to a memory instruction upon dispatch from the issue queue.
Design 1: LQ/SQ/WB. Design-1 uses three distinct structures to manage memory instructions: store queue (SQ), post-commit write buffer (WB), and load queue (LQ). At dispatch from the issue queue, a store is allocated an address-tagged entry in the SQ. When a store executes, it writes the value into its SQ entry. When a store commits, it frees its SQ entry and writes to the tail of the WB. Similarly, at dispatch, a load is allocated an address-tagged entry in the LQ. At execute, a load searches the SQ for the most recent store to the same address that is older than the load. If no match is found in the SQ, the load accesses the WB for the most recent store to the same address; if none is found, the load accesses the memory system (i.e., starting with the L1 data cache). To detect misspeculation in which a load speculatively reads an address before an older store (which is possible because an older store's address might not yet have been available when the load was ready to execute), when a store executes it checks the LQ for younger loads that have already executed; a match indicates misspeculation.
This design provides the most performance of the three we consider. However, all three structures require associative searches. A load must be able to find address-matching entries in the SQ and WB, and a store must be able to find address-matching entries in the LQ.
Design 2: LSQ. Design-2 uses a single load-store queue (LSQ) and no WB. The LSQ serves the purpose of both the LQ and SQ Design 3: LB. Design-3 allows loads to speculatively enter a load buffer (LB) as soon as their addresses are available. (We use a different term here -buffer rather than a queue -to reinforce that the unit is simply a staging area for executing the loads.) Because addresses might be resolved in an arbitrary order, loads in this design can potentially execute out-of-order, and loads may not receive data from older stores.
We assume single-core pipelines have the necessary instructions for providing software-directed ordering (e.g., mfence) but they are implemented as NOPs until PipeGen transforms the pipeline.
2.2 MCMs
A multicore pipeline must preserve both single-threaded correctness ğ‘ğ‘›ğ‘‘ enforce the architecture's MCM, where an MCM defines the legal apparent orderings of memory operations across all threads. Many consistency models exist, from strongly-ordered models like sequential consistency (SC) and x86TSO to weak models like release consistency (RC) and ARMv8. We briefly discuss two widely used models we focus on in this paper: TSO and ARMv8.
2.2.1 x86TSO
. The x86TSO MCM is similar to SC, but relaxes Store â†’ Load ordering across different addresses. This relaxation permits the use of the WB in Design-1, which would violate the stricter SC. When software wants Store â†’ Load ordering to be enforced, it must insert an mfence instruction between the store and the load. The mfence enforces ordering between memory instructions by ensuring older instructions have finished executing before younger instructions execute. With an mfence between a store and load, the load must stall to execute in-order with the store or speculatively execute and then check if it misspeculated. x86TSO orderings are shown above in Table .
2.2.2 ARMv8
. The ARMv8 MCM relaxes all orderings, only keeping same address dependencies as they are required for singlethreaded correctness. When ordering is required, it can be added with load acquires, store releases, and fences. Fences, called Data Memory Barriers (DMB), come in several varieties, including DMB SY (orders all loads and stores), DMB LD (orders Load â†’ Load and Load â†’ Store), and DMB ST (orders Store â†’ Store). Load acquires and store releases are annotated versions of loads and stores, respectively, that also enforce some orderings: specifically the load
2.3 MCM Enforcement
Architects have developed mechanisms for ğ‘šğ‘ğ‘›ğ‘¢ğ‘ğ‘™ğ‘™ğ‘¦ transforming an out-of-order single-core pipeline such that it does not violate the desired MCM. We consider three MCM enforcement mechanisms in this work: In-Order Memory Instructions, Load-Replay , and Invalidation Tracking . These are the mechanisms that PipeGen will ğ‘ğ‘¢ğ‘¡ğ‘œğ‘šğ‘ğ‘¡ğ‘–ğ‘ğ‘ğ‘™ğ‘™ğ‘¦ implement when performing its transformations.
In-Order Memory Instructions. One mechanism to order memory instructions is to execute them in order. To order memory instruction type X before memory instruction type Y, an instruction of type Y must stall execution until all older instructions of type X have completed. For example, our Design-1 has a post-commit WB that enables loads to be reordered with respect to older stores. To prevent that reordering, we could require a load to stall until the WB is empty (i.e., all older stores have completed).
2.3.2 Load-Replay.
With load-replay a load may speculatively execute out-of-order, and this speculation is checked by replaying the load at commit time. If the replayed load's value matches the initial load value, it has correctly speculated. If not, the new value is written and older instructions are squashed, as they may have used the misspeculated value.
2.3.3 Invalidation Tracking.
Invalidation tracking is an alternative mechanism to avoid the need to replay loads at commit. A core observes the incoming cache coherence traffic-specifically, invalidation messages-to identify which addresses have been written by other cores. Any loads that have speculatively read from those addresses may have misspeculated. They, as well as older instructions, are then squashed. Similar to the load-replay mechanism, invalidation handling also enforces Store â†’ Load if there is no WB, since the load must re-execute to again read an updated value.  3
The input to PipeGen is an MCM-oblivious single-core pipeline.
In theory, an architect could specify the core pipeline using any language for expressing finite state machines. HDLs like Verilog or BlueSpec or even state-machine languages like Murphi , for example, would all suffice. However, none of these generalpurpose languages would make it easy for an automated tool like PipeGen to perform its compiler-like analysis and transformations.
We could either mandate a restricted, stylized version of one of these languages or use a domain-specific language (DSL), and we have chosen the latter.