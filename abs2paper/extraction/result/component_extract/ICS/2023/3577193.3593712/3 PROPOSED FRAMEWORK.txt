3 PROPOSED FRAMEWORK
The key idea of our TL approach is to leverage the GC to predict high-performing configurations on related tasks in few-shot autotuning.
Our proposed method consists of two phases: model training and model inference, as shown in Figure . Model training uses GC to fit data collected from source tasks in an expert-defined tuning space. In our work, the source tasks correspond to different input sizes for the same application, and the tuning space is specified via application source code annotation and predefined parameter values. The source tasks, tuning space, and source input sizes are presented to an existing autotuner with a fixed evaluation budget to collect a small, quality training dataset of empirical performance. Model inference uses the fitted GC model to propose high-performing configurations for new tasks, which are then empirically evaluated. We discuss the modules in greater detail in the remainder of this section.
3.1 Model Training
Autotuning problems require experts to delineate key highlevel features. The GC also requires several interventions to permit its general usage in autotuning and to improve its utility as a few-shot TL autotuner.
3.1.1 GC for Autotuning. We make several adaptations for GC to generalize it for the autotuning problem. TOP: Model Training, which uses GC to train fitted models with data collected from source tasks (multiple input sizes of an application) in a human-designed tuning space. BOTTOM: Model Inference, which uses the fitted GC models to propose high-performing configurations for new tasks and evaluates them.
Variable Preprocessing. Standard GCs model real variables but do not model mixed-integer (discrete, integer, and categorical) variables. To address this issue, we adopt a new GC approach proposed for synthetic data generation . In this GC approach, numeric variables (real or integer) are modeled by truncated Gaussian distributions, and categories are reordered by their frequency in the fitting data. The GC also reduces the bias from distribution shape by converting all variable distributions to standard normal distribution before computing covariance.
GC as an Autotuner. GC can be used as an autotuner given a dataset of observed configurations in a defined tuning space. Each tunable parameter in an autotuning space can be represented by a marginal variable in the GC model; the combination of parameter interactions can be described through the joint model of the GC, permitting representation of distributions throughout a tuning space. The resulting fitted model identifies appropriate marginal and joint distributions. The fitted model can generate new configurations through the GC's probability integral transform, which statistically resembles the training data's observed marginal and joint behaviors. Any configurations a GCs generates can be empirically evaluated to determine its fitness without iterative feedback.
3.1.2 GC Model
Fitting for Few-Shot Tuning. Unlike existing TL autotuning methods, the GC does not benefit from access to extensive or exhaustive datasets. Without modeling the relationships between performance and parameter configurations, GC lacks a mechanism to disfavor parameter configurations with subpar performance. Nevertheless, we can intentionally filter training data based on observed highperformance and fit the GC only to high performance configurations. In the TL setting, GC-based autotuners generate high-performing configurations immediately and minimize the exploration of low-performing regions.
Quantile Filtering. We investigate dataset filtering based on performance quantiles to include only top-performing configurations in the training data for GC modeling. The best quantiles should result in a training data subset with similar distribution for high-performing configurations while maintaining ample tuning space coverage. To motivate the need for the proper threshold quantile, we present a brief analysis from an exhaustively tuned Syr2k task using Kullback-Leibler (KL) divergence , a statistical measure of the difference between two probability distributions. Zero KL divergence indicates that the compared distributions are identical; increasing differences between compared distributions increases divergence. We also analyze the tuning space coverage based on the filtered dataset since filtering can prevent some configurations from being generated. Quantile filtering cannot be too aggressive. As shown in Table , the tuning space coverage decreases gradually at first but decreases dramatically (i.e., 0.82 to 0.07) when the filtering quantile decreases from 30% to 20%. The significant decrease suggests that a majority of parameter options, especially categorical parameters, have been eliminated. Generating near-optimal configurations for many tasks requires variation within the tuning space, so filtering must not overly restrict coverage. The table also indicates that reducing the filtering quantile of source data reduces the average marginal KL divergence between the represented data and the top 10% of all possible configurations of this particular Syr2k tuning task. Again, the filtering quantile cannot be reduced indefinitely without consequence: an aggressive filter can increase divergence. We expect the optimum to change between tasks; overreliance on the source task optimum harms the generalization of the ùëì (ùëê, ùë°) relationship.
A smaller divergence for the filtered source increases the likelihood of sampling optimal configurations by redistributing the sampling probability from suboptimal areas of the space to regions that closely resemble known near-optimal configurations. Based on this trend and our experiments, we recommend using less than 50% of the original tuning data to exclude low-performing characteristics from prior data. This excludes many evaluations that prior autotuners made to inform the surrogate model rather than to improve the best-known optimum. Empirically, we determine that at least the top 15% of data from related tuning runs is needed to avoid over-specification. We utilize the top 30% of prior data in our experiments to ensure adequate information is available for complex tuning tasks without overly harming the tuning space coverage.
3.2 Model Inference
The fitted GC model represents learned distributions that can be used for inference, but additional steps must be taken to utilize it as an effective TL autotuner.
3.2.1 Conditional Sampling.
Quantile filtering increases the likelihood that a sampled configuration from the GC will reproduce optimal traits in new tasks, but this fails to respect the specific tuning needs for different tasks. Meaningful transfer between tasks requires us to label fitting data with a representation of the task, ùë°. This permits conditional sampling; we specify the condition that every sample indicates a particular task. Conditional sampling imposes arbitrary constraints on the model during generation, which affect the distributions of unconstrained variables before generating their values. We explain the mathematical mechanics of conditional sampling for GCs in greater detail in our repository. Conditional sampling prompts the GC to reconstruct the best-fit distribution it learned for the indicated task; if that task was not observed in prior tuning, the same model mechanics "recover" a transferred relationship for the new task.
Conditional sampling is particularly effective for the GC because it identifies and isolates critical information from the model. Since the GC operates on filtered high-performing source data, conditional sampling generates configurations that are expected to perform well for the transferred task.
3.2.2 Advantages over Alternative Generative Models.
Other generative models can fit a labeled dataset and generate constrained samples, but the GC has lower latency and yields more usable samples than alternatives. Table demonstrates the inference latency of comparable deep neural-networkbased generative methods such as CTGAN and TVAE . GC has the lowest latency of all, which is comparable to purely random sampling. The GC's advantage in latency is partially due to the acceptance rate of generated samples, also shown in Table . The separation of joint and marginal models permits the GC to satisfy constraints before generating other values, so only repeated parameter configurations are removed from its generated configurations. Some other models, such as the CopulaGAN [1], can also utilize conditional sampling; however, it can fail to generate any configurations when prompted to produce out-of-distribution data, which is important for transferring tuning to new tasks.
CTGAN and TVAE generate excess samples and then employ filters to discard ill-conditioned data. These methods are computationally inefficient. While relaxing constraints can help reduce their generation latency, it comes at the cost of compromising the quality of the generated data, which no longer best fits the desired task. CTGAN and TVAE are not ideal for few-shot transfer learning autotuning scenarios, where both latency and utility are crucial factors to consider.
CopulaGAN, CTGAN, and TVAE are proposed for synthetic data generation and are effective when provided with large amounts of data. In autotuning, however, we often have limited data. GC is more effective for these settings because of its computational simplicity.
3.2.3 Managing Probability of Success.
The success rate for generative autotuning is subject to randomness, even though the transferred distribution is biased toward values that are expected to be near-optimal. Therefore, it is crucial to understand the probabilities involved in GC generation to determine whether the technique is appropriate and what evaluation budget is necessary to expect a certain threshold of success.
The GC's autotuning process samples ùëò configurations without replacement from a distribution that spans |ùê∂ | potential candidates. Within the distribution are |ùêº | ideal candidates, which are optimal or near-optimal. Frequently, the top 1% of evaluations in real-world benchmarks have nearly equivalent performance. Identifying one or more of these top 1% candidates within the budgeted ùëò trials is an acceptable goal for few-shot TL autotuning. The probability that one or more such ideal candidates are selected within ùëò trials is hypergeometric sampling, described by Equation :
ùëÉ (#ùëÇùëùùë°ùëñùëöùëéùëô ‚â• 1) = ùëò ‚àëÔ∏Å ùëñ=1 |ùêº | ùëñ |ùê∂ | ‚àí |ùêº | ùëò ‚àíùëñ |ùê∂ | ùëò . (1)
If we fit all source task data and |ùê∂ | is the size of the entire configuration space, then sampling the top 1% of performance within a few shots is unlikely. Using quantile filtering on the source data for the GC can make some configurations statistically improbable or impossible to generate, eliminating them from the search. These excluded configurations are expected to be suboptimal because they fail to exhibit characteristics common with known optimal-like data from source task tuning.
Eliminating suboptimal configurations with quantile filtering reduces the size |ùê∂ |. Recall from Table that the tuning space coverage decreases dramatically after a certain quantile. The best filtering quantile will minimize KL divergence from the optimal distribution and limit |ùê∂ | without overspecifying the search space since the latter also contributes to the probability of the few-shot success. We can determine the reduced |ùê∂ | from the GC by estimating the number of unique samples generated by the fitted GC. Nevertheless, we can only measure the resulting change in |ùêº | with exhaustive evaluation, which is needed to quantify the probability of success in Equation 1.
The exact reduction in |ùêº | is unknown but can be modeled as a proportion of the eliminated configurations, which represents the opportunity cost of some removed configurations being optimal. With adjusted |ùê∂ | and |ùêº |, the value of ùëò in Equation 1 can be increased until the probability meets a desired confidence level. This provides an adequate budget of evaluations ùëò that generates one or more ideal candidates with probability equal to the specified confidence (e.g., 95%). This budget-engineering calculation operates similarly to a convergence guarantee because it permits evaluations of the GC's viability via the size of its budget constraint without performing any empirical evaluations.
3.3 Addressing Limitations for Autotuning
Even with our modifications, a few of the known limitations of GC models have limited significance in our intended use case of TL autotuning for source code annotations.
3.3.1 Underfitting
Cross-Variable Dependencies. The GC expresses codependence between variables using linear correlation, which will underfit complex variable codependencies. The GC's correlation is expressed between variable pairs, so the number of simultaneously interacting variables is less important than the complexity of dependence between variable pairs. In most cases for source-code autotuning, annotations are functionally independent of one another or adhere to the linear correlation that the model can express.
3.3.2 False
Ordering and Transitivity for Categories. The GC's linearized representation of categorical values implies and attempts to leverage a total ordering that may not exist between categories. This creates transitive relationships that may prove counterproductive for the marginal optimization of categorical data. One way to counteract this behavior is to utilize binary expansion or one-hot encodings for each category, but this can create many variables when applied to large categories. Many source code annotations consist of only two values, such as the presence or absence of a #pragma annotation, which limits the variable to two categories. Other categorical variables in annotation autotuning are limited to fewer than ten values, which bound the error that marginal kernels must overcome to acceptable degrees.
3.3.3 Model-Fitting
Complexity. Fitting a GC has cubic time complexity based on the number of variables due to the joint covariance model. Other TL methods gain a competitive edge when the GC models fifty or more variables, which can make some modifications, such as one-hot encoding, less desirable in practice. Source code annotations pose some inherent limits on the number of tunable variables due to the decreasing performance significance of additional, non-bottleneck optimization points in an application. Larger applications require explicit measures, such as importance sampling, to identify the most critical variables to tune. Our current techniques continue to rely on experts for annotation and can also rely on them to curate an appropriately sized set of variables.