7 CONCLUSION
This paper presented the design and implementation of CMLCompiler, an open-source unified compiler for classical Machine Learning (CML) inference. CMLCompiler proposed two unified abstractions: operator representations and extended computational graphs (ECGs). Operator representations convert CML operators into tensor formats, while an ECG organizes these converted operators in an optimization-friendly way. The CMLCompiler framework performs the conversion and graph optimization based on two unified abstractions, then outputs an optimized computational graph to deep learning compilers or frameworks. CMLCompiler also enables the hybrid deployment of CML and DL with a unified framework. Our implementations of CMLCompiler on top of TVM show the effectiveness and achieve up to 4.38x speedup on CPU, 3.31x speedup on GPU, and 5.09x speedup on IoT devices, compared to the stateof-the-art solutions -scikit-learn, Intel sklearn, and hummingbird. Our support for CML and DL mixed pipelines achieves up to 3.04x speedup compared with cross-framework implementations.