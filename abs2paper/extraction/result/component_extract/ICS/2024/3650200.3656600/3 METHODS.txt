3 METHODS
In this section, we will introduce the DAWN and the technical details of BOVM and SOVM. In Section 3.1, we will illustrate the principle of DAWN. We will then discuss the optimization of boolean vector-matrix operation (BOVM) that enables DAWN's efficiency in Section 3.2. Furthermore, we will expand on BOVM and introduce its extension to sparse matrices, known as sparse optimized boolean vector-matrix operation (SOVM), in Section 3.3. In Section 3.5, we use an example to demonstrate difference between BFS and DAWN.
3.1 Principle
DAWN relies on the result of matrix multiplication to assist in determining which edge visits can be skipped. However, matrix multiplication is a costly operation, requiring ğ‘‚ (ğ‘› 3 ) time and ğ‘‚ (ğ‘› 2 ) space.
Our main contribution is the simplification of matrix multiplication, which does not mean that we can compute matrix multiplication faster, but rather that we focus on only a portion of the results of matrix multiplication for the shortest path problem. Specifically, our new approach is able to determine which rows and columns of the matrix multiplication result have an impact on the shortest path problem.
Figure illustrates the correspondence between Boolean matrix operations and shortest path discovery in a graph. The blue markers indicate the result vector, while the red markers indicate a particular row of the adjacency matrix. ğ‘–,ğ‘— ğ‘›Ã—ğ‘› , the element ğ‘ (ğ‘˜ )  ğ‘–,ğ‘— represents the number of paths with length ğ‘˜ from ğ‘£ ğ‘– to ğ‘£ ğ‘— . Theorem 3.2. In unweighted graphs, the length of the shortest path from ğ‘£ ğ‘– to ğ‘£ ğ‘— is ğ‘˜ ğ‘šğ‘–ğ‘› , if and only if
ğ‘ (ğ‘˜ ğ‘šğ‘–ğ‘› ) ğ‘–,ğ‘— â‰  0 âˆ§ ğ‘– â‰  ğ‘— âˆ§ ğ‘˜ ğ‘šğ‘–ğ‘› âˆ’1 ğ‘˜=1 ğ‘ (ğ‘˜ )
ğ‘–,ğ‘— = 0. Fact 1. In unweighted graphs, any shortest paths of length ğ‘˜ can be expressed as the connection of two shortest paths with lengths ğ‘˜ âˆ’ 1 and 1, where ğ‘˜ â‰¥ 2.
Obviously, we can obtain an expression for all paths,
ğ‘ƒ (ğ‘–, ğ‘—) ğ‘šğ‘–ğ‘› = ğœ– (ğ‘– ) âˆ‘ï¸ ğ‘˜=1 ğ‘ (ğ‘˜ ) ğ‘–,ğ‘— = ğ‘˜ ğ‘šğ‘–ğ‘› âˆ’1 âˆ‘ï¸ ğ‘˜=1 ğ‘ (ğ‘˜ ) ğ‘–,ğ‘— + ğ‘ (ğ‘˜ ğ‘šğ‘–ğ‘› ) ğ‘–,ğ‘— + ğœ– (ğ‘– ) âˆ‘ï¸ ğ‘˜=ğ‘˜ ğ‘šğ‘–ğ‘› +1 ğ‘ (ğ‘˜ ) ğ‘–,ğ‘— , (1)
where 1 â‰¤ ğ‘˜ ğ‘šğ‘–ğ‘› â‰¤ ğœ– (ğ‘–). It is evident that the sum of array is minimized when the first non-zero value of ğ‘ (ğ‘˜ ) ğ‘–,ğ‘— is encountered.
Theorem 3.2 and Fact 1 state the sufficient condition for breaking the loop and ending it:
(1) DAWN already found the shortest paths between all pairs of nodes in the graph; (2) The distance vector does not change when a loop ends, which means no new paths were found in the loop.
3.2 BOVM
We describe the vector-vector multiplication as follows,
ğ‘ (2) ğ‘–,ğ‘— = ğ‘ ğ‘–,1 ğ‘ 1,ğ‘— + ğ‘ ğ‘–,2 ğ‘ 2,ğ‘— â€¢ â€¢ â€¢ + ğ‘ ğ‘–,ğ‘› ğ‘ ğ‘›,ğ‘— , (2)
which denotes the collection of path combinations from ğ‘– to ğ‘— through any node. Thus, it is unnecessary to consider all possible combinations when determining the presence of a path from i to j; only cases whereğ‘ ğ‘–,ğ‘™ > 0 âˆ§ ğ‘ ğ‘™,ğ‘— > 0 can affect the value of ğ‘ (2)  ğ‘–,ğ‘— . If ğ‘ (2)  ğ‘–,ğ‘— represents any value greater than 0, it signifies the existence of a shortest path from node ğ‘– to ğ‘—. Consequently, we can simplify this formula by utilizing a Boolean data type.
We converted the Formula 2 to a Boolean-type as follows,
ğ‘ (2) ğ‘–,ğ‘— = ğ‘›âˆ’1 âˆ‘ï¸ ğ‘™=0 ğ›¼ [ğ‘™] âˆ§ ğ›½ [ğ‘™], (3)
which requires ğ‘‚ (ğ‘›) time. Since only the non-zero elements in ğ›¼ and ğ›½ affect the multiplication result, we can compress the vectors by retaining only their non-zero elements, and get Formula 4 as follows,
ğ‘ (2) ğ‘–,ğ‘— = ğ‘™ğ‘’ğ‘› ğ›¾ âˆ’1 âˆ‘ï¸ ğ‘™=0 ğ›¼ [ğ›¾ [ğ‘™]], (4)
where ğ‘™ğ‘’ğ‘› ğ›¾ represents the length of ğ›¾ and ğ›¾ is a compressed version of ğ›½, containing only the indices of non-zero elements.
In Formula 4, if the value of
ğ›¼ [ğ›¾ [ğ‘™]] is 1, the result ğ‘ (2)
ğ‘–,ğ‘— will be 1. Once the first element of ğ‘¡ğ‘Ÿğ‘¢ğ‘’ is obtained, the sum will always yield a value of ğ‘¡ğ‘Ÿğ‘¢ğ‘’ and indicates that the path exists from ğ‘– to ğ‘—. Hence, we let the loop end at the time.
We can ensure that the path we first discover is the shortest path by Theorem 3.2, and skip the computation of any paths ended with ğ‘— in next operations. We can extend this vector operation to the CSC format matrix to assist DAWN in reducing neighbor node access and discovering the shortest path. We get the BOVM as the Algorithm 1, where ğ›¼ and ğ›½ are the dense vector, ğ‘ ğ‘¡ğ‘’ğ‘ represents the steps of the shortest paths in the iteration. Line 4 of Algorithm 1 implements the Formula 4, while lines 7-8 implement the stopping criterion provided by Fact 1.
Input: CSC, ğ›¼, ğ›½, distance, step, is_converged Output: distance, is_converged 1 while step < n do 2 step â‡ step + 1 ;
3 for i âˆˆ [0,n-1] & distance[i] = false do 4 start â‡ CSC.columns_ptr[ğ›¼[i]] ; 5 end â‡ CSC.columns_ptr[ğ›¼[i] + 1] ; 6 while (j âˆˆ [start, end-1]) & (ğ›¼[CSC.row[j]] = true) & (CSC.row[k] != i) do 7 ğ›½[i] â‡ true ; 8 distance[i] â‡ step ; 9 if is_converged =
ğ‘‡ (ğ‘›) = ğœ– (ğ‘– ) âˆ’1 âˆ‘ï¸ ğ‘¥=1 ğ‘›âˆ’ğ‘™ğ‘’ğ‘›[ğ›¼ ğ‘¥ ] âˆ‘ï¸ ğ‘–=0 ğ· ğ‘’ğ‘¥ğ‘–ğ‘¡ (ğ‘–, ğ‘¥) , (5)
ğ‘‡ (ğ‘›) < ğœ– (ğ‘– ) âˆ’1 âˆ‘ï¸ ğ‘¥=1 1 âˆ’ 1 âˆ’ ğ‘ ğœ– (ğ‘–) âˆ’ 1 ğ‘¥ â€¢ ğ‘š < 1 + ğ‘ 2 ğœ– (ğ‘–)ğ‘š. ( 6
)
where
3.3 Sparse Optimized Operation
The performance of BOVM on sparse graphs, especially those with large diameters, is often limited by the expensive cost of vector-matrix multiplication, making it difficult to outperform BFS. Reducing the number of vector multiplications has become a critical issue in enabling DAWN to be widely used.
We propose the method of SOVM to optimized DAWN on the sparse graphs, which combines graph traversal algorithms with vector-matrix multiplication, limiting the operation to nodes and their neighboring nodes. Specifically, we first obtain the set of neighboring nodes, exclude nodes that have already appeared in the result vector, then calculate the vector multiplication values of these nodes, obtaining paths of length step with target nodes in the neighboring nodes set, and finally update the shortest paths in the result vector.
Although the process is complex, we can simplify it by utilizing the properties of Boolean matrix operations. It is important to note that SOVM operates on CSR matrices, while BOVM operates on CSC matrices. The boolean vectormatrix multiplication is as follows,
ğ›¾ [ğ‘–] = ğ‘› âˆ‘ï¸ ğ‘™=0 ğ›¼ [ğ‘™] âˆ§ ğ´[ğ‘–] [ğ‘™]. (7)
If we use matrix
ğ´ = {ğ›½ 0 , ğ›½ 1 , â€¢ â€¢ â€¢ ğ›½ ğ‘›âˆ’2 , ğ›½ ğ‘›âˆ’1 }
, we can simplify the boolean vector-matrix multiplication as follows,
ğ›¾ = ğ‘™ğ‘’ğ‘› ğ›½ â€² âˆ’1 ğ‘˜=0 ğ›½ ğ›½ â€² [ğ‘˜ ] , (8)
where ğ›½ â€² is the compress version of ğ›½. Formula 8 indicates that the BOVM can be achieved by computing multiple inner products of vectors in succession.
If we transpose the matrix A to a CSR matrix ğ´_ğ¶ğ‘†ğ‘… = {ğ›¼ 0 , ğ›¼ 1 , â€¢ â€¢ â€¢ ğ›¼ ğ‘›âˆ’2 , ğ›¼ ğ‘›âˆ’1 }, Formula 8 can be simplified as follows,
ğ›½ = ğ‘™ğ‘’ğ‘› ğ›½ â€² âˆ’1 ğ‘˜=0 ğ›¼ ğ›½ â€² [ğ‘˜ ] , (9)
and it means that we can use ğ‘™ğ‘’ğ‘› ğ›½ â€² times of array merges to replace boolean vector-matrix multiplication in the SSSP tasks. We get the optimized method as the Algorithm 2. Algorithm 2 utilizes a simpler method to merge vectors, and is particularly interested in the newly added elements of ğ›½ after merging these arrays. We aim to skip any duplicate elements since these shortest paths have already been discovered. We only visit the edges and update the shortest path when the element is missing in the ğ›½ array.
Specifically, SOVM starts from the set of neighbor nodes, skips all nodes that have already appeared in the result vector (line 1), finds the target nodes in neighboring nodes set that have not yet appeared in the result vector (line 4), and then updates their shortest paths. Formula 9 provides theoretical support for such operations, and SOVM can automatically exclude the cycles without additional judgment.
ğ‘‡ (ğ‘›) = ğ‘† ğ‘¤ğ‘ğ‘ (ğ‘– ) âˆ‘ï¸ ğ‘—=0 ğ‘‘ + ( ğ‘—) = ğ¸ ğ‘¤ğ‘ğ‘ (ğ‘–), (10)
where ğ‘‘ + ( ğ‘—) is the out-degree of node ğ‘—. ğ‘† ğ‘¤ğ‘ğ‘ (ğ‘–) and ğ¸ ğ‘¤ğ‘ğ‘ (ğ‘–) denotes the number of nodes and edges included in the largest WCC (Weakly Connected Component) to which node ğ‘– belongs. The time complexity of DAWN for APSP is determined by the largest WCC in the graph,
ğ‘‡ (ğ‘›) = ğ‘›âˆ’1 âˆ‘ï¸ ğ‘–=0 ğ¸ ğ‘¤ğ‘ğ‘ (ğ‘–) = ğ‘† ğ‘¤ğ‘ğ‘ â€¢ ğ¸ ğ‘¤ğ‘ğ‘ + ğ‘›âˆ’1âˆ’ğ‘† ğ‘¤ğ‘ğ‘ âˆ‘ï¸ ğ‘–=0 ğ¸ ğ‘¤ğ‘ğ‘ (ğ‘–), (11)
ğ‘‡ (ğ‘›) < 2ğ‘† ğ‘¤ğ‘ğ‘ â€¢ ğ¸ ğ‘¤ğ‘ğ‘ , (12)
where ğ‘† ğ‘¤ğ‘ğ‘ and ğ¸ ğ‘¤ğ‘ğ‘ denote the number of nodes and edges included in the largest WCC in graph. The time complexity of DAWN based on the SOVM is ğ‘‚ (ğ‘† ğ‘¤ğ‘ğ‘ â€¢ ğ¸ ğ‘¤ğ‘ğ‘ ) for APSP tasks.
In summary, DAWN based on SOVM achieves better time complexity, requiring ğ‘‚ (ğ‘† ğ‘¤ğ‘ğ‘ â€¢ ğ¸ ğ‘¤ğ‘ğ‘ ) and ğ‘‚ (ğ¸ ğ‘¤ğ‘ğ‘ (ğ‘–)) time for APSP and SSSP tasks on the unweighted graphs, compared to BFS which requires ğ‘‚ (ğ‘›ğ‘š) and ğ‘‚ (ğ‘š), respectively.
It is important to note that this complexity improvement only occurs in non-connected graphs, whereas in connected graphs, DAWN and BSF both require ğ‘‚ (ğ‘›ğ‘š) and ğ‘‚ (ğ‘š) time for APSP and SSSP tasks.
3.4 Memory
In this section, we elaborate on how DAWN achieves reduced memory usage compared to BFS. Typically, the memory requirements of the BFS algorithm can be divided into three components: CSR matrix, the distance vector, and the priority queue. This implies that BFS cannot operate with less than 4ğ‘š + 8ğ‘› bytes of memory.
DAWN's memory requirements also consist of three components: the CSR matrix, the distance vector, and two boolean arrays. The two boolean arrays are utilized to store the paths updated in the previous and current iterations (details in Algorithm 2). As DAWN is a backward BFS algorithm, we can maintain a boolean array on the GPU instead of distance vector, with path length updates occurring in memory. The GPU memory byte-addressable, and even boolean variables are allocated a byte of space.
Therefore, DAWN necessitates a minimum of 4ğ‘š+3ğ‘› bytes of memory. We can get the formula as follows,
ğœ‚ = 4ğ‘š + 3ğ‘› 4ğ‘š + 8ğ‘› = 4ğ· + 3 4ğ· + 8 , (13)
where ğ· represents the average degree of the graph. For instance, when considering the theoretical minimum memory usage, DAWN requires only 91.58% of the memory used by Gunrock on the graph uk-2005. While the theoretical difference is approximately 8.4%, in experiments conducted under constrained GPU memory conditions, DAWN can solve the BFS task on uk-2005, whereas Gunrock fails to allocate sufficient GPU memory. It is noteworthy that as the sparsity of the graph increases, the memory advantage of DAWN becomes more pronounced.
3.5 Difference
To further examine the differences between DAWN and BFS, we present the technical details used in these two algorithms. Algorithm 3 describes the general BFS algorithm, and the benchmark implementations from GAP and Gunrock both employed more sophisticated optimization techniques in the experiment, where ğ‘ğ‘ represents the priority queue and ğ‘ ğ‘œğ‘¢ğ‘Ÿğ‘ğ‘’ is the source node of the SSSP task.
For Line 15 of Algorithm 2, if no new shortest paths are found in this loop, then exit, according to Fact 1. We utilize step to mark the current node being visited as a neighbor node of the source node at the layer ğ‘ ğ‘¡ğ‘’ğ‘ in DAWN. Lines 4-6 of Algorithm 2 indicate that some edge visitations can be skipped. This means that the nodes that have already been visited in the previous layer do not need to be visited again, as the shortest path has already been determined. The theorem supporting this decision is referred to as Theorem 3.2, which states that the first discovered path from the source node to a reachable node is the shortest path. The processing steps of DAWN is as follows,
(1) Firstly, DAWN reads the input vector and identifies the single-step reachable nodes from the source node ğ‘ , (2) Then, searching for the single-step reachable nodes from the updated nodes which updating in the previous step, while skipping nodes that have already been discovered to have a path from the source node ğ‘  and reachable nodes with an out-degree of 0, (3) Next, DAWN repeats the second step until output vector stabilizes. (4) Finally, exit loop and output the result vector.
On the other hand, in BFS, the operations of accessing nodes and edges, and checking whether the path needs to be updated are necessary for every node and edge, refer to Line 6-10 in Algorithm 3.
We illustrate the difference between the BFS algorithm and DAWN through a example in Figure . The red color indicates the nodes and edges that are visited in the current step, the blue nodes and edges represent that have already been visited, and the green edges represent that have not yet been visited. The ğ‘–ğ‘›ğ‘ğ‘¢ğ‘¡ represents the paths updated in the previous iteration, while the ğ‘œğ‘¢ğ‘¡ğ‘ğ‘¢ğ‘¡ indicates the paths updated in the current iteration. The ğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ signifies the outcome of the algorithm, specifically denoting the shortest In the third step of Figure , node 5 has four outbound edges to node 1, 4, 6, 10. BFS must traverse these edges, and then BFS would note that the destination vertex of these edges had already been visited and the destination vertex would not be in the output frontier. However, DAWN does not traverse these edges. The compressed vector for node 5 is {1, 2, 3, 6, 10}, and ğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ is {1, 1, 1, 0, 0, 0, 1, 0, 0, 0}. The values of ğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ , ğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ , ğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ , and ğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ are all 1, indicating that DAWN will skip these edges, because the shortest paths of them were already found.
In the SSSP task for node ğ‘ , the BFS algorithm visited a total of 10 nodes and 17 edges, while DAWN visited only 8 nodes and 12 edges, resulting in 2 fewer nodes and 5 fewer edges being visited by DAWN.
Overall, the fundamental difference between DAWN and BFS lies in whether the algorithm relies on a priority queue to prevent revisiting nodes and edges.