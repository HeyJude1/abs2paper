4 RESULTS
In this section, we will outline the experimental setup and present initial experimental data. Following this, we proceed to show the performance of DAWN with regard to scalability and its effect in accelerating the SSSP task.
4.1 Experiment Introduction
In our experimental trials, we leverage a set of 66 general graphs sourced from the SuiteSparse Matrix Collection and the Gunrock benchmark datasets .
In scenarios where a node is not part of the largest WCC of the graph, but instead resides in a smaller connected component, DAWN has the potential to accomplish the task in constant time, while BFS requires the construction of a priority queue.
Therefore, we have established a randomly generated set comprising 500 nodes, where each node executes the SSSP task 64 times. All computations are conducted within this node-set. It is noteworthy that these nodes are not exclusively part of the largest connected component, and our dataset includes non-connected graphs. We underscore our focus on evaluating the performance of the BFS algorithm across diverse graph types, including connected and non-connected graphs, as well as both generated and real-world graphs.
Performing the task consecutively serves to minimize the influence of external factors on experimental results, such as interference from background processes. We adopted the arithmetic mean as the anticipated value and subjected the sample distribution to a t-distribution test. After eliminating samples that deviated from the assumptions of the tdistribution, and computing the mean of the remaining samples, we get the final result. The parameters of the test machine are detailed in Table . Our comparison includes various versions of the BFS algorithm, and the results are presented in Table . We provide accessible links to graphs: . The number of nodes in these graphs ranges up to 139ùëÄ, with edges extending up to 921ùëÄ. The parameters of the experimental graphs are detailed in Table . Edges
< 1M 1M ‚àº 5M 5M ‚àº 20M 20M ‚àº 500M > 500M 16 16 23 8 3
Specifically, the results for DAWN running on GPUs were obtained using a thread block size of 1024, a configuration viable on GPUs since the Pascal architecture introduced in 2016. Although the optimal block partitioning scheme depends on several factors (e.g., matrix density, shared memory size, bandwidth, etc.), we adopt a fixed block size to enhance result reproducibility.
Gunrock is a CUDA library for graph-processing designed specifically for the GPU, which achieves a better balance between performance and expressiveness via coupling highperformance GPU computing primitives and optimization strategies, particularly in the area of fine-grained load balancing. .
We strongly encourage readers to delve into the provided codebase and verify the reported results. The code and more information for our algorithm are available on [GitHub]. In the repository, we offer additional insights into the actual running times and graph details for each proposed solution, accompanied by a description of artifacts and evaluation methodologies. These details are provided to enhance the reproducibility of any results presented in this paper.
4.2 Scalability
It is important to validate DAWN's feature of high parallelism and scalability. We measure the scalability of DAWN using multi-threading efficiency as follows, simplified from Gustafson-Barsis's law ,
ùúÇ ùë° = ùëá ùêµ ùëá ùëÅ √ó ùëÅ , (14)
where ùëá ùêµ represents the baseline execution time, ùëá ùëÅ represents the execution time of the program with ùëÅ threads, and ùëÅ is the number of threads. In Table and 6, the multithreading efficiency for DAWN based on SOVM and BFS API from GAP on the I5-13600KF and EPYC Milan 7T83 are depicted, respectively.  When utilizing up to 32 threads on the EPYC processor, the core frequency remains constant at 3.5 GHz. However, when scaling up to 64 threads, the frequency of all cores diminishes to 2.54 GHz. In contrast, the I5 processor does not experience any reduction in core frequency. It is important to note that the exact performance gains are contingent upon the particular hardware configuration utilized, and considerations such as power and thermal constraints impose limitations on the maximum achievable performance.
The I5 processor integrates a combination of performance and efficiency cores, where the former delivers higher clock speeds, and the latter excels in power efficiency. Hence, DAWN achieves a linear speedup when scaling from 1 thread to 6 threads, but the performance improvement slows down when scaling from 6 to 12 threads due to the performance gap between the two types of cores. Additionally, the I5 processor does not have enough physical cores to achieve significant performance gains beyond 14 threads.
Across diverse hardware configurations, DAWN demonstrates better multi-threading efficiency compared to GAP. Futhurmore, the scalability of the algorithm is influenced by a considerable number of factors, among which the characteristic of the graph is a significant factor.
Figure and 4 illustrate DAWN's capability for speedup across different thread counts on some of the graphs. Specifically, on the mycielskian16, which is a dense graph with a lowdiameter of 2, DAWN exhibits lower thread efficiency compared to other sparse graphs. This phenomenon underscores the impact of multiple factors on the increase or decrease in algorithm performance. For instance, Graph mouse_gene is denser than mycielskian16, and with a diameter of 12, yet DAWN exhibits superior thread efficiency on mouse_gene. Therefore, we emphasize the comprehensive performance of the algorithm across a wider variety of graphs.   In Table , the speedup for DAWN based on SOVM over BFS API from GAP on an I5-13600KF is depicted, with the values derived from the mean of repeated experiments, following the methodology outlined in Section 4.1. The first row shows the speedup of DAWN over BFS API from GAP, both on I5-13600KF, and the next row shows the speedup of DAWN on RTX3080TI over BFS API from GAP on I5-13600KF. Due to the significant increase in scalability and parallelism, DAWN based on the SOVM outperformed GAP in most graphs (62 out of 66), achieving an impressive average speedup of 3.769√ó.
However, the DAWN algorithm demonstrates comparatively lower performance in four specific graphs (coPapers-DBLP, com-DBLP, coAuthorsDBLP, coPapersCiteseer), all representing citation and collaboration networks. These graph types are characterized by high clustering coefficients and relatively short average shortest paths. Despite the deployment of a more potent processor, BFS API from Gunrock falls short of surpassing the performance of GAP on these graphs. Nevertheless, in other scale-free graphs such as social networks and the internet, the DAWN algorithm exhibits superior performance.
Numerous well-established studies have presented evidence that the eccentricity of the real graphs is log ùëõ . Therefore, we get the small-world graphs (23 out of 66) which the average shortest path in the graph is less than log ùëõ, includes the citation and collaboration networks mentioned before.
The Direction-Optimizing BFS algorithm will achieve the speedups when the active frontier is a substantial fraction of the total graph, which commonly occurs in small-world graphs . However, DAWN outperforms GAP on the most small-world graphs (19 out of 23) and achieves an average speedup of 2.332√ó. Furthermore, in other real graph with a high-diameter such as road networks, DAWN achieves an average speedup of 4.483√ó over GAP.
Figure shows the running time for DAWN and GAP. The y-axis represents the average running time, with each
4.4 Performance Comparison with Gunrock
In Table , the first row shows the speedup of DAWN( ) on an I5-13600KF over BFS API from Gunrock on RTX3080TI. The next rows shows the speedup of DAWN over BFS API from Gunrock, both on RTX3080TI. Figure illustrates the running time for DAWN and BFS API from Gunrock. Red markers correspond to DAWN, while green markers represent Gunrock. Impressively, DAWN outperformed Gunrock in the majority of graphs (63 out of 66), achieving an average speedup of 9.410√ó. On the Graphs uk-2005 and arabic-2005, Gunrock encountered an out-of-memory error, thus preventing the acquisition of runtime data for these two graphs. The testing machine equipped with 12GB of physical GPU memory, with 9.7GB available. The available GPU memory for both DAWN and Gunrock is identical, indicating that when executing similar tasks, DAWN requires less GPU memory compared to Gunrock. Apart from the aforementioned two graphs, DAWN demonstrates performance inferior to that of Gunrock on the Graph web-BerkStan, and also falls short compared to DAWN and GAP running on CPU. This phenomenon may be attributed to the scale-free nature of web-BerkStan, leading to load imbalance during computation and significantly impacting algorithm performance. Gunrock, possessing robust load balancing capabilities, holds an advantage in such scenarios. It is crucial to note that DAWN does not prioritize load balancing as the primary focus of our investigation. Nonetheless, despite these challenges, DAWN outperforms Gunrock on the majority of graphs due to algorithmic optimizations.
4.5 Performance on Different Platforms
The differences in the speedup distribution of DAWN compared to different algorithms are attributed to the nature of the graphs, such as the number of nodes and the average shortest path length. Therefore, we will proceed to compare the performance of DAWN on the different platforms. Figure illustrates the performance gap of DAWN between CPU and GPU. Light purple bars indicate cases where DAWN's performance on CPU is inferior to that on GPU, while dark purple bars represent the opposite scenario.
In more than half of the graphs (37 out of 66), DAWN(20) exhibits superior performance compared to DAWN. For instance, on web graphs, DAWN and the GAP algorithm achieved enhanced performance, which demonstrates that the powerful single-core performance of CPUs provide better acceleration for algorithms.
However, this single-core performance acceleration has its limitations. Once the graph size exceeds one million nodes, the advantage of single-core performance can no longer compensate for the performance disparity induced by a greater ) over DAWN number of cores. Furthermore, on graphs with a smaller number of nodes, the communication overhead between the CPU and GPU appears more costly than computational expenses, leading to inferior performance compared to algorithms running on CPU.
DAWN achieved performance superiority on graphs with an average of 0.209 million nodes and 5.854 million edges (considering undirected edges as two directed edges). On the other hand, DAWN demonstrated performance superiority on graphs with an average of 13.820 million nodes and 146.592 million edges.
In summary, DAWN is more efficient and yielding a higher speedup when compared to Gunrock and GAP.