4 Experiments
4.1 Experimental Setup
Datasets. We evaluate our method on three commonly used datasets, i.e., CIFAR-10, CIFAR-100 , and ImageNet . Following prior works , we assume that the number of novel classes is known. Specifically, we randomly select 50% of the classes as seen classes, and the remaining classes are regarded as novel classes, e.g., the number of novel classes is 50 for CIFAR-100. On each dataset, we consider two types of labeled ratios, i.e., only 10% or 50% of data in seen classes are labeled. For the ImageNet dataset, we subsample 100 classes to form the ImageNet-100 dataset for fair comparisons with existing works.
Following prior works , we evaluate our method with respect to the accuracy of seen classes, novel classes, and all classes. For seen classes, the accuracy is calculated as the normal classification task. For novel classes, we first utilize the Hungarian algorithm to solve the optimal prediction-target class assignment problem and then calculate the accuracy of novel classes. For overall accuracy, we also solve the optimal assignment in the entire unlabeled dataset to calculate the novel class accuracy, measuring the overall performance.
Implementation Details. Following , we utilize the self-supervised learning method SimCLR [Chen et al., 2020a] to pre-train the backbone and fix the first three blocks. In LPS, the weak augmentation contains random crop and horizontal flip, and the strong augmentation is RandAugment . For CIFAR-10 and CIFAR-100, we utilize ResNet-18 as our backbone which is trained by the standard SGD with a momentum of 0.9 and a weight decay of 0.0005. We train the model for 200 epochs with a batch size of 512. For the Im-ageNet dataset, we opt for ResNet-50 as our backbone. This choice also undergoes training via the standard SGD, featuring a momentum coefficient of 0.9 and a weight decay of 0.0001. The training process spans 90 epochs, with a batch size of 512. and The cosine annealing learning rate schedule is adopted on CIFAR and ImageNet datasets. These experiments are conducted on a single NVIDIA 3090 GPU.
4.2 Comparing with Existing Methods
Baselines. We compare LPS with SSL methods, open-set SSL methods, NCD methods, and OpenSSL methods. The NCD methods consider that the labeled data only has disjoint classes compared with the unlabeled data and aim at clustering novel classes without recognizing seen classes. For novel classes, clustering accuracy can be obtained directly. For seen classes, we first regard them as novel classes and leverage the Hungarian algorithm to match some of the discovered classes with seen classes, and then calculate the classification accuracy. We select two competitive NCD methods DTC and RankStats in the experiments. Moreover, we include GCD For the SSL and open-set SSL methods, we leverage their capability in estimating out-of-distribution samples to extend to the OpenSSL setting. For comparison, we select FixMatch , which assigns pseudo-labels to unlabeled samples based on confidence. The classification accuracy of seen classes can be reported directly according to pseudo-labels. For novel classes, we first estimate samples without pseudo-labels as novel classes and then utilize k-means to cluster them. The open-set SSL methods maintain the classification performance of seen classes by rejecting novel classes. We compare with DS 3 L and calculate its accuracy in the same way as FixMatch.
For the OpenSSL methods, we compare with ORCA , NACH , and OpenNCD . We also compare the self-supervised pre-trained model SimCLR and conduct K-means on the primary features to calculate the accuracy.
Results. The results on three datasets are reported in Table . The mean accuracy is computed over three runs for each method. Although the non-OpenSSL methods perform well on their original tasks, their overall performance is unsatisfactory in the OpenSSL setting. The results of SimCLR are obtained by the pre-trained model without extra fine-tuning, and the OpenSSL methods are based on the pre-trained model. It is obvious that the OpenSSL methods achieve significant performance improvements compared to non-OpenSSL methods. Compared with the state-of-the-art OpenSSL methods, our method LPS achieves the best overall performance across all datasets. On the CIFAR-10 dataset, LPS outperforms NACH by 1.2% in novel class accuracy. Likewise, on the CIFAR-100 dataset, LPS demonstrates superiority, yielding a substantial 3.2% improvement. Particularly concerning the ImageNet-100 dataset, LPS has the capacity to surpass existing state-of-the-art methods, resulting in a 3.8% increase in overall accuracy. Experimental results demonstrate that LPS can effectively balance the learning of seen and novel classes.
Distribution Analysis. For further validation of our approach, we present a comprehensive analysis of the KL divergence trend between the estimated and prior class distributions, along with the estimated class distributions at the  foundation of SimCLR pre-trained backbone, the visualization, and NMI results highlight the efficacy of our approach in enhancing representation learning.  Fine-tuning the Pre-trained Backbone. Furthermore, it is noteworthy that all previous OpenSSL methods adopt a practice of freezing the parameters within the first three blocks of the backbone, solely fine-tuning the last block, with the intention of mitigating overfitting. However, such an approach constrains the extent of performance enhancement, as the backbone's parameters remain unmodifiable and unoptimized to better suit downstream tasks. To establish that our method is not susceptible to the overfitting dilemma, we conducted a series of experiments on the CIFAR dataset employing stateof-the-art OpenSSL methods while fine-tuning the backbone.
The results are reported in Table . The experimental results reveal that existing OpenSSL methods manifest modest performance improvement, if any, in comparison to their initial frozen counterparts. In contrast, our proposed method, unaffected by overfitting concerns, consistently yields substantial performance gains across both seen and novel classes. Specifically, the overall accuracy for CIFAR-10 experiences a notable improvement of 2.9%, while an impressive 6.3% increase is observed for CIFAR-100. These results underscore 64.5 49.9 54.3
Table : Accuracy when removing key components of our method. We report the average accuracy over three runs on CIFAR datasets with 50% seen classes (50% labeled) and 50% novel classes.
the effectiveness of LPS in harnessing the additional learnable parameters for further enhancing model performance.
Ablation Analysis. Moreover, we conduct a comprehensive analysis of the contributions of distinct components in our approach. The objective function of LPS comprises the adaptive margin loss (L AM ), the pseudo-label contrastive clustering loss (L PC ), the unsupervised contrastive learning loss (L UC ), and the entropy regularizer (R Entropy ). Concretely, the ablation study is mainly conducted by removing each term individually from the objective function except for the adaptive margin which is replaced by a standard cross-entropy. As observed in Table , the removal of any components leads to performance degradation. The substantial drop in novel performance after removing the entropy regularizer highlights its significant role in the process of novel class discovery. Moreover, the utilization of both pseudo-label contrastive loss and adaptive margin loss substantially improves the accuracy of novel classes.