7 Additional Results
In addition, we conduct more experiments to validate the robustness of the proposed method. We first conduct a series experiments on CIFAR-100 dataset with different numbers of novel classes, and the results are reported in the Figure To further evaluate the performance when fine-tuning the pre-trained backbone, we conduct a series of experiments on the CIFAR dataset with 50% seen classes (10% labeled) and 50% novel classes. From Table , we can see that both ORCA and NACH show significant declines (over 10% overall accuracy), while our method LPS maintains high performance on CIFAR-100 and shows further improvements on CIFAR-10, which further verifies that LPS is not susceptible to the overfitting dilemma.