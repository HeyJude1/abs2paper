5 Conclusion
This paper revisits prior SSL algorithms, focusing on two crucial questions: how to design an effective threshold mechanism and how to utilize the pseudo-labels assigned lower confidence. To address these challenges, we introduce two strategies named class-specific adaptive threshold (CAT) and binary classification consistency (BCC) regulation. CAT leverages predictions on unlabeled data and classifier weights to establish a threshold mechanism that aligns with the evolving learning status of each class. BCC regulation identifies candidate classes for each unlabeled sample and encourages consistent candidate-negative divisions across diverse perturbed views of the same sample. With these two modules incorporated, the proposed AllMatch maximizes the utilization of unlabeled data and achieves impressive pseudo-label accuracy. We conduct extensive experiments on multiple benchmarks, including both balanced and imbalanced settings. The results demonstrate that AllMatch achieves state-of-the-art performance and is capable of dealing with real-world challenges.   The weight associated with the BCC regulation in the overall loss, denoted as λ b , is systematically evaluated in Figure .
For both CIFAR-10 with 40 labeled samples and CIFAR-100 with 400 labeled samples, AllMatch achieves optimal performance when λ b is set to 1.0. Either larger or smaller values can result in slight performance degradation. Overall, All-Match assigns equal importance to the supervision signals of pseudo-label and candidate-negative division, leveraging the latter to boost the potential within the top-k predictions of low-confidence pseudo-labels.
A.2 Grid Search for the Upper Bound of the Number of Candidate Classes.
As shown in Figure , we examine the upper bound of the number of candidate classes, denoted as K. In the case of CIFAR-10 with 40 labeled samples, the performance of All-Match is largely unaffected by K due to its effective distinction between candidate and negative classes through a comparison between local and global top-k confidence. Moreover, for CIFAR-100 with 400 labeled samples, the model achieves optimal performance when K is set to 10. A smaller K may exclude the ground truth from the candidate classes, leading to negative impacts. Additionally, a larger K can result in a trivial division between candidate and negative classes, causing performance degradation. Considering the comparable learning difficulty, we set the upper bound K to 10 for CIFAR-10/100, SVHN, and STL-10. However, Ima-geNet is known to be more challenging than the aforementioned datasets. Through grid search, we find that setting K to 20 provides optimal results on ImageNet.
A.3 Learning Process Visualization
To gain further insights into AllMatch, we compare its learning process with previous algorithms on four benchmarks: CIFAR-10 with 40 labels, STL-10 with 40 labels, CIFAR-10 with 10 labels, and CIFAR-100 with 400 labels. The former two are presented in Figure of the main paper and the latter two are provided in Figure of the Appendix. Among the involved SSL algorithms, SoftMatch serves as a weight-based method, varying from other threshold-based algorithms. In the following parts, we will first describe the analysis regarding SoftMatch in detail and subsequently provide the revealed findings about the learning process of AllMatch. SoftMatch models sample weights by a dynamic Gaussian function, where the mean µ t and standard deviation σ t are evaluated by predictions on unlabeled data. The weight for unlabeled data u, denoted as λ(u), is defined as follows.
λ(u) = e − min(c−µ t ,0) 2 2×(σ t /n) 2 (14)
Here, c denotes the prediction confidence of sample u and n is set to 2 in SoftMatch to adjust the standard deviation. While each unlabeled sample receives a positive weight, samples with confidence significantly lower than µ t are assigned close-to-zero weights, thus having minimal impact on the overall loss. Consequently, in this paper, we distinguish between the implementation and analysis of SoftMatch. Specifically, the implementation follows the sample weight scheme mentioned in Equation ( ). Besides, in the analysis part, we consider unlabeled samples with confidence lower than µ t − σ t (λ(u) < e −2 ) as dropped samples, thereby approximating SoftMatch as a threshold-based method. Based on the above analysis, the class-average threshold for SoftMatch is defined as µ t − σ t , and its selected pseudo-label acc and utilization ratio for unlabeled data can be computed like other threshold-based algorithms.
Figure presents the evolving process of numerous training indicators on CIFAR-10 with 10 labels and CIFAR-100 with 400 labels. AllMatch demonstrates several commonalities between the two datasets. Firstly, the threshold exhibits the expected behavior, beginning with a small value and steadily increasing thereafter. Secondly, AllMatch shows a smooth threshold evolution on both benchmarks, thus providing a better estimation of the learning status when compared to previous models. Thirdly, while prior methods suffer from the degradation of pseudo-label accuracy in the later training stages, AllMatch effectively alleviates this issue. Lastly, the binary pseudo-label accuracy consistently outperforms the pseudo-label accuracy, indicating that the BCC regulation effectively identifies the candidate class for all unlabeled data.
In addition to the aforementioned commonalities, there are also some differences in the performance of AllMatch on different benchmarks. For CIFAR-10 with 10 labels, All-Match not only achieves improved pseudo-label accuracy but also utilizes the unlabeled data more effectively, highlighting its significant advantages over existing algorithms, especially when labeled samples are extremely limited. On the other hand, for CIFAR-100 with 400 labels, FixMatch achieves the optimal pseudo-label accuracy by leveraging a high constant threshold throughout training. In comparison,  The threshold for CIFAR-10 with 10 labels is restricted within the range of [0.9, 1.0] to avoid overfitting noisy pseudo-labels in the early training stages. In the analysis of SoftMatch, we employ µt − σt as its threshold. Samples with a confidence lower than µt − σt are assigned negligible weights, essentially treated as if they were discarded. Consequently, we employ µt − σt as the class-average threshold of SoftMatch. Moreover, its selected pseudo-label acc and utilization ratio for unlabeled data can be computed like other threshold-based algorithms. Here, µt and σt denote the estimated mean and standard deviation of the overall confidence on unlabeled data.  AllMatch achieves comparable pseudo-label accuracy while substantially improving the utilization ratio of the unlabeled set, indicating a better trade-off between the utilization of unlabeled data and pseudo-label accuracy.
A.4 T-SNE Visualization
To gain an intuitive understanding of AllMatch, we employ T-SNE to plot the high-dimensional features of various SSL algorithms, including SoftMatch, FreeMatch, FlexMatch, and AllMatch, on STL-10 with 40 labeled samples, as depicted  in Figure . Compared with FreeMatch and FlexMatch, All-Match achieves more separable and tightly clustered features, indicating that the introduced CAT serves as a better indicator for the evolving learning status of the model. Furthermore, while SoftMatch maintains appropriate inter-class and intraclass distances, it overfits many erroneous pseudo-labels, exemplified by the excessive light blue points within the green cluster. In contrast, AllMatch effectively pushes ambiguous pseudo-labels towards the decision boundary, thus minimizing their impact on the classifier. Consequently, AllMatch extracts easy-to-distinguish features for the unlabeled samples, establishing a solid foundation for a robust classifier.
A.5 Confusion Matrix
In Figure , we provide the confusion matrices of several SSL algorithms when applied to STL-10 with 40 labeled samples: SoftMatch, FlexMatch, FreeMatch, and AllMatch. To emphasize the classes with an accuracy below 0.7, we denote them with red circles. The results presented in Figure suggest that previous models typically encounter challenges when recognizing samples in class 3, class 5, and class 7. Fortunately, AllMatch successfully mitigates this issue and promotes the accuracy of these three categories, which primarily stems from the accurate learning status estimation provided by CAT and the maximal utilization of the unlabeled set supported by BCC. Overall, AllMatch achieves enhanced classwise accuracy compared to previous models, indicating its effectiveness.
B Combination with Imbalanced Algorithms
To explore the compatibility of the proposed method with existing imbalanced SSL algorithms, we examine the combination of ABC, which is the current state-of-the-art imbalanced SSL algorithm, with several balanced SSL algorithms on CIFAR-10-LT and CIFAR-100-LT. ABC uses Bernoulli masks to approximate class-balanced sampling, thus learning a balanced auxiliary classifier. As illustrated in Table , the combination of ABC and AllMatch consistently outperforms the baseline and other methods. Therefore, AllMatch can be jointly deployed with existing imbalanced SSL algorithms when encountering severe class imbalance.
C Detailed Training Settings
For better reproduction, we present the detailed training settings for balanced and imbalanced SSL in Table and Table 8, respectively.