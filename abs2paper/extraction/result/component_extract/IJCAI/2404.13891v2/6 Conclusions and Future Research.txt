6 Conclusions and Future Research
This work proposes to minimize weighted counterfactual regret with OMD and optimistic variant. It provides a new perspective to understand DCFR's superior performance and derives a novel CFR variant PDCFR+. PDCFR+ discounts cumulative regrets from early iterations to mitigate the negative effects of dominated actions and consistently leverages predictions to accelerate convergence. Experimental results demonstrate that PDCFR+ achieves competitive results compared with other CFR variants. Recent work proposes two fixes for PRM+, achieving O(1/T ) convergence in normal-form games. It is worthwhile to investigate whether our algorithm can achieve similar convergence by introducing a specific weighting sequence. Besides, combining PDCFR+ with function approximations and integrating it with the dynamic discounting framework are also promising future works.
To illustrate the sequential decision process, we use the game of Kuhn Poker as an example. The typical formalism for describing an imperfect information game involves an extensive-form game forming a game tree as depicted in Figure . The lack of information is represented by information sets for each player.
The sequential decision process encodes the decision problem confronted by an individual player. Figures showcase the sequential decision processes from the perspective of player 1 and 2, respectively. A one-to-one correspondence exists between information sets in the extensive-form game and decision nodes in the sequential decision process.
For player 1's decision process, there are seven decision nodes, i.e., J = {j0, j1, j2, j3, j4, j5, j6}. At decision node j0, the action set is A j0 = {start} with earliest reachable decision nodes C j0,start = {j1, j2, j3} following the action start. Similarly, at decision node j1, the action set is A j1 = {check, bet} with earliest reachable decision nodes C j1,check = {j4} after taking the action bet.
There is a local strategy x j ∈ ∆ nj for each decision node j. For example, x j1 ∈ ∆ 2 is a vector indexed over {check, bet} for decision node j1, where x j1 [check] and x j2 [bet] represents the probabilities of selecting the actions check and bet, respectively. We can construct a sequence-form strategy ẋ based on local strategies. For example, ẋ is vector indexed over {(j0, start), (j1, check), (j1, bet), (j2, check), (j2, bet), (j3, check), (j3, bet), (j4, f old), (j4, call), (j5, f old), (j5, call), (j6, f old), (j6, call)}. The probabilities in the sequence-form strategy are similar to the reach probabilities in the extensiveform game. For instance, ẋ
] = x j0 [start]x j1 [bet], and ẋ[(j6, f old)] = x j0 [start]x j3 [check]x j6 [f old].
The payoff matrix A of the game Kuhn Poker is presented in the Table . The first column of the matrix is player 1's sequence-form strategy, the first row of the matrix is player 2's sequence-form strategy. The matrix is sparse, and we only display the non-zero payoff for clarity. It is important to note that the payoff matrix A encodes the losses for player 1, while the utility for player 1 is listed in Figure .
(j0, start) (j1, check) (j1, bet) (j2, f old) (j2, call) (j3, check) (j3, bet) (j4, f old) (j4, call) (j5, check) (j5, bet) (j6, f old) (j6, call) (j0, start) (j1, check) +1 +1 (j1, bet) -1 +2 -1 +2 (j2, check) -1 +1 (j2, bet) -1 -2 -1 +2 (j3, check) -1 -1 (j3, bet) -1 -2 -1 -2 (j4, f old) +1 +1 (j4, call) +2 +2 (j5, f old) +1 +1 (j5, call) -2 +2 (j6, f old) +1 +1 (j6, call) -2 -2
Table : The payoff matrix of Kuhn Poker.
Kuhn Poker is a simplified form of poker proposed by Harold W. Kuhn . The game employs a deck of three cards, represented by J, Q, K. At the beginning of the game, each player receives a private card drawn from a shuffled deck and places one chip into the pot. The game involves four kinds of actions: 1) fold, giving up the current game, and the other player gets all the pot, 2) call, increasing his/her bet until both players have the same chips, 3) bet, putting more chips to the pot, and 4) check, declining to wager any chips when not facing a bet. In Kuhn Poker, each player has an opportunity to bet one chip. If neither player folds, both players reveal their cards, and the player holding the higher card takes all the chips in the pot. The utility for each player is defined as the difference between the number of chips after playing and the number of chips before playing.
Leduc Poker is a larger poker game first introduced in . The game uses six cards that include two suites, each comprising three ranks (Js, Qs, Ks, Jh, Qh, Kh). Similar to Kuhn Poker, each player initially bets one chip, receives a single private card, and has the same set of action options. In Leduc Poker, the game unfolds over two betting rounds. During the first round, players have an opportunity to bet two chips, followed by a chance to bet four chips in the second round. After the first round, one public card is revealed. If a player's private card is paired with the public card, that player wins the game; otherwise, the player holding the highest private card wins the game.
HUNL Subgame (x) (x = 3, 4) introduced in ] is a heads-up no-limit Texas hold'em(HUNL) sub-game generated by and solved in real-time by the state-of-the-art poker agent Libratus 2 . In HUNL, both players (P1 and P2) start each hand with 20,000 chips, dealt two private cards from a standard 52-card deck. P1 initially places 100 chips to the pot, followed by P2 adding 50 chips. P2 starts the first round of betting. Then players alternate in choosing to fold, call, check or raise. A round ends when a player calls if both players have acted. After the first round, three public cards are dealt face up for all players to observe, and P1 starts a similar round of betting. In the third and fourth rounds, 2 https://github.com/CMU-EM/LibratusEndgames  one additional public card is dealt and betting starts again with P1. Unless a player has folded, the player with the best five-card poker hand, constructed from their two private cards and the five public cards, wins the pot. In the case of a tie, the pot is split evenly. HUNL Subgame (3) begins at the start of the final betting round with 500 chips in the pot. HUNL Subgame (4) begins at the start of the final betting round with 3,750 chips in the pot. In the first betting round, we use bet sizes of 0.5x, 1x the size of the pot, and an all-in bet. In other betting rounds, we use 1x the pot and all-in.
fold fold fold fold fold call call call call call fold call P1 J P1 Q P1 K P2 Q P2 K P2 J P2 K P2 J P2 Q check bet check check check check bet bet bet bet bet check bet call fold check bet call fold call fold call fold call check bet fold call check bet check bet -1 -1 -1 -1 -1 -1 -1 -2 -2 +1 +1 +2 +1 +2 -1 +1 +2 +1 +2 +1 -2 +1 -1 +2 +1 +2 -2 +1 -2 -2 chance node player 1's node
Liar's Dice (x) (x = 4, 5) [Lisỳ et al., 2015] is a dice game where each player gets an x-sided dice and a concealment cup. At the beginning of the game, each player rolls their dice under their cup, inspecting the outcome privately. The first player then begins bidding of the form p-q, announcing that there are at least p dices with the number of q under all the cups. The highest dice number x can be treated as any number. Then players take turns to take action: 1) bidding of the form p-q, p or q must be greater than the previous player's bidding, 2) calling 'Liar', ending the game immediately and revealing all the dices. If the last bid is not satisfied, the player calling 'Liar' wins the game. The winner's utility is 1 and the loser -1.
Goofspiel (x) (x = 4, 5) is a bidding card game. At the beginning of the game, each player receives x cards numbered 1 . . . x, and there is a shuffled point card deck containing cards numbered 1 . . . x. The game proceeds in x rounds. In each round, players select a card from their hand to make a sealed bid for the top revealed point card. When both players have chosen their cards, they show their cards simultaneously. The player who makes the highest bid wins the point card. If the bids are equal, the point card will be discarded. After x rounds, the player with the most point cards wins the game. The winner's utility is 1 and the loser -1. We use a fixed deck of decreasing points.
GoofspielImp (x) (x = 4, 5) is an imperfect information variant of Goofspiel (x) where players are only told whether they have won or lost the bid, but not what the other player played.
Battleship (x) (x = 2, 3) is a classic board game where players secretly place a ship on their separate grids of size 2 × x at the start of the game. Each ship is 1 × 2 in size and has a value of 2. Players take turns shooting at their opponent's ship, and the ship that has been hit at all its cells is considered sunk. The game ends when one player's ship is sunk or when each player has completed three shots. The utility for each player is calculated as the sum of the values of the opponent's sunk ship minus the sum of the values of their own lost ship.
We measure the sizes of the games in many dimensions and report the results in Table . In the table, #Histories measures the number of histories in the game tree. #Infosets measures the number of information sets in the game tree. #Terminal histories measures the number of terminal histories in the game tree. Depth measures the depth of the game tree, i.e., the maximum number of actions in one history. Max size of infosets measures the maximum number of histories that belong to the same information set. is invariant to positive rescaling of xt+1 j . So all choice of η > 0 result in the same strategy. Without loss of generality, we set η = 1 and R t j = xt+1 j , which corresponds to the algorithm WCFR+. Similarly, when employing optimistic OMD with ψ = 1 2 ∥•∥ 2 2 as the algorithm A, it updates the decision according to
zt j = argmin z′ j ∈R n ≥0 −w t r t j , z′ j + 1 2η z′ j − zt−1 j 2 2 = argmin z′ j ∈R n ≥0 −2ηw t r t j , z′ j + z′ j − zt−1 j 2 2 = argmin z′ j ∈R n ≥0 2 −ηw t r t j , z′ j + z′ j 2 2 − 2 z′ j , zt−1 j = argmin z′ j ∈R n ≥0 z′ j − zt−1 j − ηw t r t j 2 2 = [ zt−1 j + ηw t r t j ] + , and
xt+1 j = argmin x′ j ∈R n ≥0 −w t+1 v t+1 j , x′ j + 1 2η x′ j − zt j 2 2 = argmin x′ j ∈R n ≥0 −2ηw t+1 v t+1 j , x′ j + x′ j − zt j 2 2 = argmin z′ j ∈R n ≥0 2 −ηw t+1 v t+1 j , x′ j + x′ j 2 2 − 2 x′ j , zt j = argmin x′ j ∈R n ≥0 x′ j − zt j − ηw t+1 v t+1 j 2 2 = [ zt j + ηw t+1 v t+1 j ] + ,
The only effect of the step size η is a rescaling of all decisions xt j by a constant. The output strategy
x t+1 j = xt+1 j / xt+1 j 1
is invariant to positive rescaling of xt+1 j . So all choice of η > 0 result in the same strategy. Without loss of generality, we set η = 1, R t j = zt j , and Rt+1 j = xt+1 j , which corresponds to the algorithm PWCFR+.
Proof. In each iteration t, player 1 and player 2 generates a sequence-form strategy ẋt and ẏt , respectively. The expected loss for player 1 is ẋ⊤ A ẏ. Subsequently, player 1 receives a loss vector lt x = A ẏt , while player 2 receives a loss vector lt y = −A ⊤ ẋt .
For player 1's total weighted regret, we have
R T τ ,x = max ẋ′ ∈X T t=1 τ t lt x , ẋt − ẋ′ = max ẋ′ ∈X T t=1 τ t A ẏt , ẋt − ẋ′ = T t=1 τ t ( ẋt ) ⊤ A ẏt − min ẋ′ ∈X T t=1 τ t ẋ′⊤ A ẏt = T t=1 τ t ( ẋt ) ⊤ A ẏt − min ẋ′ ∈X ẋ′⊤ A T t=1 τ t ẏt = T t=1 τ t ( ẋt ) ⊤ A ẏt − T t=1 τ t min ẋ′ ∈X ẋ′⊤ A ȳT τ .
Similarly, for player 2's total weighted regret, we have
R T w,y = max ẏ′ ∈Y T t=1 τ t ℓ t y , ẏt − ẏ′ = max ẋ′ ∈X T t=1 −τ t A ⊤ ẋt , ẏt − ẏ′ = − T t=1 τ t ( ẋt ) ⊤ A ẏt + max ẏ′ ∈Y T t=1 τ t ( ẋt ) ⊤ A ẏ′ = − T t=1 τ t ( ẋt ) ⊤ A ẏt + T t=1 τ t max ẏ′ ∈Y ( xT τ ) ⊤ A ẏ′ . So, δ 1 ( xT τ , ȳT τ ) + δ 2 ( xT τ , ȳT τ ) = ( xT w ) ⊤ A ȳT w − min ẋ′ ∈X ẋ′⊤ A ȳT w + max ẏ′ ∈Y ( xT w ) ⊤ A ẏ′ − ( xT w ) ⊤ A ȳT w = max ẏ′ ∈Y ( xT w ) ⊤ A ẏ′ − min ẋ′ ∈X ẋ′⊤ A ȳT w = 1 T t=1 τ t R T τ ,x + R T τ ,y
Hence, the weighted average strategy profile ( xT τ , ȳT τ ) forms a R T τ ,x +R T τ ,y T t=1 w t -Nash equilibrium.
The proof is based on , with the addition of a weight to each iteration.
Proof. According to the Theorem 2, we need to know the bound of R T τ . By decomposing the total weighted regret into the sum of the total weighted counterfactual regrets R T j,τ under each decision node, we have
R T τ ≤ j∈J R T j,τ + .
For the weighted counterfactual regret R T j,τ , we have
R T j,τ = max x ′ j ∈∆ n j T t=1 τ t ℓ t j , x t j − x ′ j = max x ′ j ∈∆ n j T t=1 τ t ℓ t j , x t j − ℓ t j , x ′ j = max x ′ j ∈∆ n j T t=1 τ t ℓ t j , x t j 1, x ′ j − ℓ t j , x ′ j = max x ′ j ∈∆ n j T t=1 τ t ℓ t j , x t j 1 − ℓ t j , x ′ j = max x ′ j ∈∆ n j T t=1 τ t r t j , x ′ j = max x ′ j ∈∆ n j T t=1 τ t w t w t r t j , x ′ j = max x ′ j ∈∆ n j T t=1 τ t w t − lt j , x ′ j When employing OMD with ψ = 1 2 ∥•∥ 2
2 as the algorithm A, it updates the decision according to
xt+1 j = argmin x′ j ∈R n ≥0 −w t r t j , x′ j + 1 2η x′ j − xt j 2 2 .
∀ x′ j ∈ ∆ nj , according to Lemma 1, we have that
−w t r t j , xt j − x′ j ≤ 1 η 1 2 x′ j − xt j 2 2 − 1 2 x′ j − xt+1 j + η 2 2 −w t r t j 2 2 Hence, T t=1 τ t w t −w t r t j , xt j − x′ j ≤ T t=1 1 η τ t w t 1 2 x′ j − xt j 2 2 − 1 2 x′ j − xt+1 j + η 2 2 −w t r t j 2 2 = 1 2η τ 1 w 1 x′ j − x1 j 2 2 − 1 2η τ T w T x′ j − xT +1 j 2 2 + 1 2η T −1 t=1 τ t+1 w t+1 − τ t w t x′ j − xt+1 j 2 2 + T t=1 η 2 τ t w t −w t r t j 2 2 ≤ 1 2η τ 1 w 1 + T t=1 η 2 τ t w t w t r t j 2 2
where we use τ t w t a non-increasing sequence and
x1 j = argmin x′ ∈R n j ≥0 1 2 ∥ x′ ∥ 2 2 = 0, x′ j ∈ ∆ nj in the last step.
Using the fact that the strategies produced by WCFR+ do not depend on the chosen step size η > 0, we can choose the η > 0 that minimizes the right hand side:
T t=1 τ t w t −w t r t j , xt j − x′ j ≤ τ 1 w 1 T t=1 τ t w t r t j 2 2
Since WCFR+ chooses the next strategy in decision node j as
x t j = xt j / xt j 1 , we have xt j , r t j = xt j , ℓ t j , x t j 1 − ℓ t j = ℓ t j , x t j xt j 1 − xt j , ℓ t j = ℓ t j , x t j xt j 1 − xt j 1 x t j , ℓ t j = 0 So, R T j,τ = max x′ j ∈∆ n j T t=1 τ t w t w t r t j , x ′ j = max x′ j ∈∆ n j T t=1 τ t w t −w t r t j , xt j − x′ j ≤ τ 1 w 1 T t=1 τ t w t r t j 2 2 and R T τ ≤ j∈J R T j,τ + ≤ |J | τ 1 w 1 T t=1 w t τ t r t j 2 2
Combining the Theorem 2, we have that the weighted average strategy profile ( xT τ , ȳT τ ) after T iterations forms a
j∈Jx∪Jy τ 1 w 1 T t=1 τ t w t r t j 2 2 / T t=1 τ t -Nash equilibrium.
Lemma 1. ] Let D ∈ R n be closed and convex, let ℓ ∈ R n , x t ∈ D, and let ψ : D → R be a 1-strongly convex differentiable regularizer with respect to some norm ∥•∥, and let ∥•∥ * be the dual norm to ∥•∥. Assume
x t+1 := argmin x ′ ∈D ℓ t , x ′ + 1 η B ψ (x ′ || x t )
Then ∀x ′ ∈ D, the following inequality holds:
η ℓ t , x t − x ′ ≤ B ψ (x ′ ; x t ) − B ψ (x ′ ; x t+1 ) + η 2 2 ℓ t 2 * C.4 Proof of Theorem 4
The proof is based on , with the addition of a weight to each iteration.
Proof. According to the Theorem 2, we need to know the bound of R T τ . By decomposing the total weighted regret into the sum of the total weighted counterfactual regrets R T j,τ under each decision node, we have R T τ ≤ j∈J R T j,τ + .
For the weighted counterfactual regret R T j,τ , we have R T j,τ = max
x ′ j ∈∆ n j T t=1 τ t ℓ t j , x t j − x ′ j = max
x ′ j ∈∆ n j T t=1 τ t ℓ t j , x t j − ℓ t j , x ′ j = max
x ′ j ∈∆ n j T t=1 τ t ℓ t j , x t j 1, x ′ j − ℓ t j , x ′ j = max
x ′ j ∈∆ n j T t=1 τ t ℓ t j , x t j 1 − ℓ t j , x ′ j = max
x ′ j ∈∆ n j T t=1 τ t r t j , x ′ j = max
x ′ j ∈∆ n j T t=1 τ t w t w t r t j , x ′ j = max
x ′ j ∈∆ n j ∀ x′ j ∈ ∆ nj , we have Using the fact that the strategies produced by PWCFR+ do not depend on the chosen step size η > 0, we can choose the η > 0 that minimizes the right hand side: Lemma 2. For any a, b ∈ R n and ρ > 0, it holds that ⟨a, b⟩ ≤ ρ 2 ∥a∥ 2 * + 1 2ρ ∥b∥ 2 .
Lemma 3. Let D ⊆ R n be closed and convex, let ℓ t ∈ R n , x t ∈ D, and let ψ : D → R ≥0 be a 1-strongly convex differentiable regularizer with respect to some norm ∥•∥, and let ∥•∥ * be the dual norm to ∥•∥. Then,
x t+1 := argmin x ′ ∈D ℓ t , x ′ + 1 η B ψ (x ′ || x t )
is well defined (that is, the minimizer exists and is unique), and for all x ′ ∈ D satisfies the inequality
ℓ t , x t+1 − x ′ ≤ 1 η B ψ (x ′ || x t ) − B ψ (x ′ || x t+1 ) − B ψ (x t+1 || x t )