【相关工作】
================================================================================
现有研究可划分为四大技术路线：

1. 参数高效微调(PEFT)：包括Adapter、LoRA等方法，通过引入轻量级适配模块减少可训练参数。然而这类方法普遍忽视知识迁移的内在机制。

2. 知识蒸馏：通过教师-学生框架实现知识传递，但面临表征空间不对齐的挑战。

3. 持续学习：采用弹性权重固化(EWC)等方法缓解灾难性遗忘，但难以处理突发的领域转换。

4. 记忆增强网络：利用外部存储扩展模型容量，但现有方案缺乏对预训练知识的特异性设计。

相比已有工作，我们的贡献在于：1)首次建立预训练与微调知识的量化关联模型；2)提出动态门控的记忆更新机制；3)实现与主流PEFT技术的无缝集成。
