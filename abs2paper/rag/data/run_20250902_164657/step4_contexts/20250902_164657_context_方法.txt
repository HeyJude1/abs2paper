结构化RAG上下文
================================================================================
【方法 部分的上下文】
--------------------------------------------------
上下文长度：2446 字符

上下文内容：
### Methodology 总结
**总结1** (来源: 3656019.3676895):
方法概述：
1、方法名称: MIREncoder
2、核心思想: 通过多模态自监督预训练方法，将LLVM IR（中间表示）同时建模为词序列和依赖图两种模态，以提取语法、语义和结构特征，用于高性能计算（HPC）的性能优化任务。

3、主要流程/组件
组件/步骤一: IR词序列处理
- 功能：将IR指令拆分为子词单元，通过训练的WordPiece分词器转换为数值化序列（类似BERT处理方式）
- 关键点：采用64长度限制的语句级编码，包含特殊标记[CLS]/[SEP]，支持Masked Language Modeling任务

组件/步骤二: 依赖图生成
- 功能：使用PROGRAML工具将IR转换为包含数据流、控制流和调用流的多图结构
- 关键点：节点特征为IR语句，通过分词器转换为数值特征供图神经网络处理

组件/步骤三: 多模态预训练任务
1) 掩码语言建模(MLM)：
- 随机掩码15%IR词序列，通过Transformer层预测被掩码内容
- 采用80-10-10的掩码策略避免模型对[MASK]标记过拟合

2) 图自编码(GAE)：
- 使用GNN层编码多图为低维表示，并重建原...

**总结2** (来源: 3656019.3676895):
方法概述：
1、方法名称: MIREncoder
2、核心思想: 通过多模态自监督预训练方法，将LLVM IR（中间表示）同时建模为词序列和依赖图两种模态，以提取语法、语义和结构特征，用于高性能计算（HPC）的性能优化任务。

3、主要流程/组件
组件/步骤一: IR词序列处理
- 功能：将IR指令拆分为子词单元，通过训练的WordPiece分词器转换为数值化序列（类似BERT处理方式）
- 关键点：采用64长度限制的语句级编码，包含特殊标记[CLS]/[SEP]，支持Masked Language Modeling任务

组件/步骤二: 依赖图生成
- 功能：使用PROGRAML工具将IR转换为包含数据流、控制流和调用流的多图结构
- 关键点：节点特征为IR语句，通过分词器转换为数值特征供图神经网络处理

组件/步骤三: 多模态预训练任务
1) 掩码语言建模(MLM)：
- 随机掩码15%IR词序列，通过Transformer层预测被掩码内容
- 采用80-10-10的掩码策略避免模型对[MASK]标记过拟合

2) 图自编码(GAE)：
- 使用GNN层编码多图为低维表示，并重建原...

**总结3** (来源: 3577193.3593710):
方法概述：
1、方法名称: CMLCompiler
2、核心思想: 通过将经典机器学习（CML）模型转换为深度学习（DL）计算图，利用成熟的DL编译器和框架实现跨硬件部署与性能优化。核心创新在于设计了两层统一抽象——算子表示（Operator Representations）和扩展计算图（ECG），以解决CML与DL在算子类型、数据格式和模型结构上的本质差异。

3、主要流程/组件
组件/步骤一: 模型解析器（Model Parser）
- 功能：将CML模型的算子表示转换为扩展计算图（ECG）。初始化算子节点并构建数据依赖边，设置权重稀疏性（sparsity）和数据类型（dtype）等属性。最终输出结构化的ECG表示。

组件/步骤二: 图优化器（Graph Optimizer）
- 功能：基于ECG特性进行三类无损优化：
  1) 数据类型重写（Dtype Rewriting）：根据硬件SIMD指令集优化算子数据类型（如bool→int8），通过算法保证精度无损；
  2) 稀疏算子替换（Sparse Operator Replacing）：对高稀疏权重采用压缩存储格式（CSR）并...


### 研究趋势分析
**Methodology 趋势**:
- 技术趋势: 深度学习技术广泛应用, 端到端技术广泛应用, Transformer技术广泛应用
- 研究模式:  在43/5篇论文中被提及(860.0%), '在38/5篇论文中被提及(760.0%), n在32/5篇论文中被提及(640.0%)


### 参考原文
**论文 3656019.3676895 - 方法 章节**:
片段1: 3 MIREncoder
Most source-code based performance optimization tasks in HPC usually involve compilable languages such as C, C++, CUDA, and so on. A large number of these languages can be compiled and optimized using the LLVM infrastructure. LLVM IRs are a portable, high-level assembly language that ca...
片段2: It is fairly simple to extract IRs from source code such as C, C++. IRs generated from source code are usually devoid of most stylistic choices and redundant code. This is why we choose to work with IRs for performance optimizations. Figure shows a high-level overview of our approach. For the first ...



