{
  "section_name": "方法",
  "context": "### Methodology 总结\n**总结1** (来源: 3656019.3676895):\n方法概述：\n1、方法名称: MIREncoder\n2、核心思想: 通过多模态自监督预训练方法，将LLVM IR（中间表示）同时建模为词序列和依赖图两种模态，以提取语法、语义和结构特征，用于高性能计算（HPC）的性能优化任务。\n\n3、主要流程/组件\n组件/步骤一: IR词序列处理\n- 功能：将IR指令拆分为子词单元，通过训练的WordPiece分词器转换为数值化序列（类似BERT处理方式）\n- 关键点：采用64长度限制的语句级编码，包含特殊标记[CLS]/[SEP]，支持Masked Language Modeling任务\n\n组件/步骤二: 依赖图生成\n- 功能：使用PROGRAML工具将IR转换为包含数据流、控制流和调用流的多图结构\n- 关键点：节点特征为IR语句，通过分词器转换为数值特征供图神经网络处理\n\n组件/步骤三: 多模态预训练任务\n1) 掩码语言建模(MLM)：\n- 随机掩码15%IR词序列，通过Transformer层预测被掩码内容\n- 采用80-10-10的掩码策略避免模型对[MASK]标记过拟合\n\n2) 图自编码(GAE)：\n- 使用GNN层编码多图为低维表示，并重建原...\n\n**总结2** (来源: 3656019.3676895):\n方法概述：\n1、方法名称: MIREncoder\n2、核心思想: 通过多模态自监督预训练方法，将LLVM IR（中间表示）同时建模为词序列和依赖图两种模态，以提取语法、语义和结构特征，用于高性能计算（HPC）的性能优化任务。\n\n3、主要流程/组件\n组件/步骤一: IR词序列处理\n- 功能：将IR指令拆分为子词单元，通过训练的WordPiece分词器转换为数值化序列（类似BERT处理方式）\n- 关键点：采用64长度限制的语句级编码，包含特殊标记[CLS]/[SEP]，支持Masked Language Modeling任务\n\n组件/步骤二: 依赖图生成\n- 功能：使用PROGRAML工具将IR转换为包含数据流、控制流和调用流的多图结构\n- 关键点：节点特征为IR语句，通过分词器转换为数值特征供图神经网络处理\n\n组件/步骤三: 多模态预训练任务\n1) 掩码语言建模(MLM)：\n- 随机掩码15%IR词序列，通过Transformer层预测被掩码内容\n- 采用80-10-10的掩码策略避免模型对[MASK]标记过拟合\n\n2) 图自编码(GAE)：\n- 使用GNN层编码多图为低维表示，并重建原...\n\n**总结3** (来源: 3577193.3593710):\n方法概述：\n1、方法名称: CMLCompiler\n2、核心思想: 通过将经典机器学习（CML）模型转换为深度学习（DL）计算图，利用成熟的DL编译器和框架实现跨硬件部署与性能优化。核心创新在于设计了两层统一抽象——算子表示（Operator Representations）和扩展计算图（ECG），以解决CML与DL在算子类型、数据格式和模型结构上的本质差异。\n\n3、主要流程/组件\n组件/步骤一: 模型解析器（Model Parser）\n- 功能：将CML模型的算子表示转换为扩展计算图（ECG）。初始化算子节点并构建数据依赖边，设置权重稀疏性（sparsity）和数据类型（dtype）等属性。最终输出结构化的ECG表示。\n\n组件/步骤二: 图优化器（Graph Optimizer）\n- 功能：基于ECG特性进行三类无损优化：\n  1) 数据类型重写（Dtype Rewriting）：根据硬件SIMD指令集优化算子数据类型（如bool→int8），通过算法保证精度无损；\n  2) 稀疏算子替换（Sparse Operator Replacing）：对高稀疏权重采用压缩存储格式（CSR）并...\n\n\n### 研究趋势分析\n**Methodology 趋势**:\n- 技术趋势: 深度学习技术广泛应用, 端到端技术广泛应用, Transformer技术广泛应用\n- 研究模式:  在43/5篇论文中被提及(860.0%), '在38/5篇论文中被提及(760.0%), n在32/5篇论文中被提及(640.0%)\n\n\n### 参考原文\n**论文 3656019.3676895 - 方法 章节**:\n片段1: 3 MIREncoder\nMost source-code based performance optimization tasks in HPC usually involve compilable languages such as C, C++, CUDA, and so on. A large number of these languages can be compiled and optimized using the LLVM infrastructure. LLVM IRs are a portable, high-level assembly language that ca...\n片段2: It is fairly simple to extract IRs from source code such as C, C++. IRs generated from source code are usually devoid of most stylistic choices and redundant code. This is why we choose to work with IRs for performance optimizations. Figure shows a high-level overview of our approach. For the first ...\n\n",
  "context_length": 2446
}