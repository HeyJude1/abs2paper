{
  "方法": "### 3.1 方法概述  \n提出MIREncoder框架用于LLVM IR分析，通过同时建模IR的token序列和依赖图特征实现多模态表征学习。核心创新在于Transformer与GNN的协同集成。\n\n### 3.2 问题建模  \n给定LLVM IR程序P={S,G}（S为token序列，G=(V,E)为依赖图），目标学习联合嵌入空间fθ(S,G)→R^d以保留序列和结构特性。\n\n### 3.3 架构设计  \n#### 3.3.1 IR序列处理器  \n- BERT-style Transformer编码器  \n- WordPiece分词（专用于LLVM IR词汇表）  \n- 12层结构（768隐藏维，12注意力头）\n\n#### 3.3.2 依赖图处理器  \n- PROGRAML生成多类型边（数据流/控制流/调用图）  \n- GIN网络（5层消息传递）\n\n### 3.4 核心算法  \n#### 3.4.1 多模态预训练  \n- MLM任务：15%掩码率（80%替换为[MASK]）  \n- GAE任务：L_GAE=||A-σ(ZZ^T)||_F^2\n\n#### 3.4.2 跨模态注意力  \nAttention(Q,K,V)=softmax(QK^T/√d)V交替计算模态间信息流\n\n### 3.5 实现优化  \n- 共享词嵌入矩阵  \n- 混合精度训练  \n- GPU内存峰值控制在16GB以内"
}