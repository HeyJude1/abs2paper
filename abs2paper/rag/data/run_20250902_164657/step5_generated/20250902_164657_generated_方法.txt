【方法】
================================================================================
### 3.1 方法概述  
提出MIREncoder框架用于LLVM IR分析，通过同时建模IR的token序列和依赖图特征实现多模态表征学习。核心创新在于Transformer与GNN的协同集成。

### 3.2 问题建模  
给定LLVM IR程序P={S,G}（S为token序列，G=(V,E)为依赖图），目标学习联合嵌入空间fθ(S,G)→R^d以保留序列和结构特性。

### 3.3 架构设计  
#### 3.3.1 IR序列处理器  
- BERT-style Transformer编码器  
- WordPiece分词（专用于LLVM IR词汇表）  
- 12层结构（768隐藏维，12注意力头）

#### 3.3.2 依赖图处理器  
- PROGRAML生成多类型边（数据流/控制流/调用图）  
- GIN网络（5层消息传递）

### 3.4 核心算法  
#### 3.4.1 多模态预训练  
- MLM任务：15%掩码率（80%替换为[MASK]）  
- GAE任务：L_GAE=||A-σ(ZZ^T)||_F^2

#### 3.4.2 跨模态注意力  
Attention(Q,K,V)=softmax(QK^T/√d)V交替计算模态间信息流

### 3.5 实现优化  
- 共享词嵌入矩阵  
- 混合精度训练  
- GPU内存峰值控制在16GB以内
