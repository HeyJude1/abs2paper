{
  "user_requirement": "基于深度学习的图像分类方法研究",
  "top_k_per_type": 5,
  "relevant_summaries": {
    "relatedwork": [
      {
        "paper_id": "3650200.3656628",
        "summary_text": "相关工作总结：\n\n1、现有方法一：**输入张量数据分布式推理（DeepThings、MoDNN、CoEdge、EdgeFlow）**\n核心思想: \n- DeepThings通过分配输入张量数据的感受野，实现卷积层的独立推理；\n- MoDNN采用贪心算法划分卷积层和全连接层的输入张量，按设备算力分配负载；\n- CoEdge提出异构设备自适应负载划分技术，综合考虑计算资源和网络带宽；\n- EdgeFlow基于DAG模型重构分区方法，通过分析模型图的输入输出关系分配层操作。\n主要局限性: \n- 上述方法均针对CNN架构设计，未考虑Transformer等非CNN模型的并行需求；\n- 分区策略对动态网络条件和设备异构性的适应性不足（仅CoEdge部分涉及）。\n\n2、现有方法二：**Transformer模型并行（Megatron-LM）**\n核心思想: \n- 利用矩阵乘法并行（Mat-Mul）分析Transformer运算行为；\n- 通过算子级并行实现单层内的计算加速。\n主要局限性: \n- 缺乏针对异构设备网络条件和计算能力的动态分区算法；\n- 仅支持层内并行，无法有效利用跨层流水线机会。\n\n3、现有方法三：**跨层流水线并行（PipeEdge）**\n核心思想: \n- 将输入批次划分为微批次（micro-batches）；\n- 在多设备间建立执行流水线，实现层间并行。\n主要局限性: \n- 论文未明确提及该方法是否解决了动态资源调度问题；\n- 对微批次划分粒度与延迟/吞吐量的权衡关系缺乏理论分析。\n\n研究缺口：\n1. CNN并行方法无法直接迁移至Transformer架构\n2. 现有Transformer并行方案缺乏：\n   - 异构设备感知的动态分区机制\n   - 层内与层间并行的协同优化\n3. 边缘环境下网络波动与计算资源变化的适应性不足",
        "source_sections": 