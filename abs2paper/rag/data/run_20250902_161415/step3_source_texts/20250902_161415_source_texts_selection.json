{
  "selected_source_texts": {
    "Retrospection_on_the_Performance_Analysis_Tools_for_Large-Scale_HPC_Programs": {
      "方法": [
        "III. METHODOLOGY\nAlthough there are widely adopted performance tools in large-scale HPC systems, there is no existing work that provides a comprehensive study of the existing performance analysis tools for performance analysis of large-scale HPC programs according to our knowledge. In this section, we describe our testbed of the performance analysis tools and the corresponding comparable metrics on the common concerns for performance analysis.",
        "We evaluate a homebuilt cluster with hardware and software configuration as shown in Table . Specifically, the cluster consists of 32 computing nodes. Each node is equipped with one 36-core Intel Golden 6240 processor running at 2.60 GHz frequency. There is 384 GB of memory for each node. All nodes are connected with a 100 Gbps network. The storage has over 160 Gbps I/O bandwidth. All programs are compiled with GCC 9.4.0 with -O3 compiler optimizations. We use OpenMPI 4.0.7 for MPI communication.",
        "We use OpenMPI 4.0.7 for MPI communication. For a comprehensive comparison of the existing large-scale performance tools, we evaluate the following performance tools that are well-known for providing rich performance guidance for large-scale HPC programs:\n• HPCToolkit is a sampling-based performance analysis tool that provides insights into the performance bottlenecks of the target programs. HPCToolkit can collect traces and generate profiles from the collected data.",
        "HPCToolkit can collect traces and generate profiles from the collected data. In our evaluation, we leverage the default sampling rate at 300Hz per event type for HPCToolkit. • TAU is an instrumentation-based performance analysis tool that provides the ability to collect wide ranges of performance data. TAU requires re-compilation with its own compilation toolchains (e.g., tau cc) to obtain the detailed function traces.",
        "For trading off the overhead and abundance of data collection, TAU provides both profile run (denoted as TAU-P) that do not collect detailed function traces and trace run (denoted as TAU-T) that collect detailed function traces.",
        "In our evaluation, we enable the auto event throttling with default settings (numcalls > 100, 000 && usecs/call < 10) for the TAU-P run and only collects MPI functions for TAU-T. • Scalasca is an instrumentation-based performance analysis tool that targets scalable performance tracing and analysis. Scalasca requires re-compilation with instrumentation compiler toolchains (e.g., scorep ) to obtain the detailed function traces.",
        "Scalasca requires one profile run (denoted as Scalasca-P) before collecting the full trace (denoted as Scalasca-T) for the target programs to obtain reasonable configurations as well as function filters for lower overhead. In our evaluation, we collect without any filters for Scalasca-P and tracing with the provided configuration as well as filters that only collect MPI communication traces.",
        "The aforementioned performance tools are representative of state-of-the-art performance analysis tools and are widely adopted in the HPC community. We evaluate these tools based on the following criteria: abundance and overhead of data collection, trace analysis, hotspots analysis, scalability, and performance variance.",
        "Note that although primitive diagnosing of the above performance issues does not require full event traces, MPI communication traces are still required for several advanced root cause analysis of specific performance issues in state-of-the-art research . We evaluate these tools with the NAS Parallel Benchmarks (NPB) and the real-world application LULESH .",
        "Specifically, we use class B input for NPB-16 processors, class D for NPB-1,024 processors, and -s 40 -i 400 for LULESH in our evaluation according to the evaluation scale. For HPCToolkit, we use -t -e REALTIME -e PAPI TOT INS to enable the trace function and performance metric collection function. For TAU, we enable the auto throttling function, callpath, and communication matrix collection.",
        "For TAU, we enable the auto throttling function, callpath, and communication matrix collection. For Scalasca, to generate the filter file and trace configuration (e.g., max buffer size), we first use scalasca -analyze and scalascaexamine to profile the target benchmarks and applications. We use the same input datasets for all the performance analysis tools to ensure a fair comparison. The performance analysis tools can be evaluated with two aspects: data collection and analysis capabilities.",
        "We evaluate the performance analysis tools based on the following criteria:\n1) Data Collection: For both primitive and advanced performance analysis, developers first need to collect enough performance data from the target program execution. In this paper, we call the ability to collect different types of performance data as abundance of data collection. The abundance of data collection is essential for supporting various useful and important performance analysis tasks.",
        "For large-scale homogeneous clusters, we investigate whether the performance analysis tools can collect the following performance data: • CPU Performance Counter: The ability to collect CPU performance counter data, often represented as PAPI or Linux perf events. It can provide deep insights into the hardware performance bottlenecks of the target program (e.g., top-down microarchitecture analysis ).",
        "Besides, the time and storage overhead of data collection is another important aspect for evaluating the performance analysis tools. Specifically, time overhead is measured as the execution time of the target program with and without the performance analysis tools. Storage overhead is measured as the storage space required to store the collected performance data.",
        "Storage overhead is measured as the storage space required to store the collected performance data. The overhead of data collection is essential for minimizing the impact of the performance analysis tools on the target program execution. The higher time overhead leads to significant time and commercial costs for performance analysis and limits the applicability of the performance analysis tools at a large scale.",
        "The higher storage overhead leads to the difficulty of storing and analyzing the collected performance data, which may further result in unexpected fails due to exceeding the storage capacity (e.g., maximum 1 TB storage budgets adopted in our evaluated homebuilt HPC cluster). 2) Analysis Capabilities: For performance analysis capabilities of the evaluated performance analysis tools, it is difficult to provide a quantitative metric for comparison.",
        "Instead, we provide the pros and cons of the evaluated performance analysis tools based on the following common performance analysis tasks for large-scale HPC programs: We evaluate the performance analysis tools with the trace analysis capabilities with their built-in visualization GUI interface for intuitive comparison. • Hotspot Analysis -Hotspots indicate functions or code regions that consume the most significant time or resources.",
        "For a fair comparison, we run the default hotspot analysis within each evaluated performance tool and provide the top few functions reported by these tools. Apparently, for the same program execution with the same input at the same scale, the analysis results of the top 10 hotspots should be similar, which gains the most attention for developers to further investigate the performance optimization opportunities.",
        "• Scalability Analysis -Scalability analysis aims to identify the causes of poor performance scalability of target program execution at different scales. Poor scalability can lead to low utilization of large-scale computation resources and even the inability to obtain higher performance even running with more nodes. We evaluate the performance analysis tools with 16 and 1024 processes to evaluate the tool's ability to analyze the scalability issues.",
        "• Performance Variance Analysis -Performance variance indicates the significant performance slowdown of the different execution instances of the same program. For a fair comparison, we run the program with and without injected disturbances to evaluate their ability to identify the performance variance. For each evaluated analysis capability, we qualitatively investigate the intuitiveness, accuracy, and completeness of the analysis results provided by the performance analysis tools.",
        "Specifically, the analysis results should be intuitive for developers to understand the performance issues of the target program. The analysis results should be accurate to provide reliable guidance for optimizing the performance of the target program. Besides, the analysis results should also be actionable to provide optimization guidance for the target program, such as providing problematic code locations, calling contexts, and comprehensive diagnosis of root causes."
      ]
    },
    "3701997": {
      "实验评价": [
        "4 Evaluation\nThis section mainly presents the experimental results and analysis of the previously mentioned methods, divided into six parts. In Section 4.1, we introduce the configurations and settings of both the simulated and real environments. In Section 4.2, we select multiple DNN models and large language models (LLMs) to evaluate the memory optimization effectiveness of BTSearch compared to other methods.",
        "In Section 4.3, we compare the inference latency optimization of GenEFlow with other methods under the same configuration. The experiments assess the model inference efficiency of these methods without considering memory constraints. In Section 4.4, we set different device memory limitations to validate the minimum memory requirements for model inference optimization and evaluate the optimization effects of various methods.",
        "In Section 4.5, we evaluate the inference latency of GenEFlow across multiple models by altering the number of devices and heterogeneous configurations, analyzing how these factors impact model inference latency. In Section 4.6, we compare the inference latency optimization of GenEFlow with other methods in a real environment. 4.1 Experimental Setup\nExperiment Platforms. The parameters of the experimental platform and simulation configuration are shown in Table .",
        "The parameters of the experimental platform and simulation configuration are shown in Table . Our experiments are conducted in two distinct environments. The first scenario is a simulated environment using a local PC (CPU*8 @2.5GHz, 32GB RAM) to mimic Experiment Models. We select VGG13 , ResNet50 , InceptionV3 , MobileNetV3 , SqueezeNet , GoogLeNet , and RegNet as the models. The models are pretrained models sourced from PyTorch.hub.",
        "The models are pretrained models sourced from PyTorch.hub. They are converted to the .onnx format using the torch.onnx .export() command from PyTorch. Moreover, we also evaluate our framework on three LLMs, BERT , GPT-2 , and Qwen2 . For running CNN models, the input data shape is , and for LLMs, the input data shape is . 4.2 Memory Optimization Analysis during Inference Process\nThis experiment aims to validate the memory optimization method proposed in Section 3.2.",
        "The comparison of the method with different baselines is shown in Table . The adopted baselines are as follows: (i) Random, which randomly selects an executable operator each time; (ii) PEFT , a heuristic algorithm optimizing for inference efficiency; and (iii) Greedy , which selects the operator with the largest input tensor to execute each time, aiming to minimize memory consumption as much as possible. BTsearch consistently achieves optimal results across all models.",
        "BTsearch consistently achieves optimal results across all models. All methods yield the same for VGG13 and GPT-2 with a single valid topological order. Similarly, models like MobileNetV3, SqueezeNet, and EfficientNet-50, despite having branching structures, result in identical outcomes due to simplified operators. However, ResNet-50, InceptionV3, GoogLeNet, BERT, and Qwen2 variations occur. PEFT optimizes execution time, favoring larger-scale operators early in the order.",
        "PEFT optimizes execution time, favoring larger-scale operators early in the order. Greedy selects operators based on input tensor size, outperforming PEFT. BTSearch guarantees optimal results by exploring all legal topological orders. Compared to random selection, BTSearch achieves up to a 12% improvement. To illustrate BTSearch's efficacy, we use GoogLeNet to compare memory overheads under Random and BTSearch.",
        "As shown in Figure , while initial stages show minimal optimization due to fixed orders, subsequent multi-branch DAG structures benefit from optimized execution, reducing memory usage and expanding optimization possibilities for inference latency. Next, we analyze the efficiency of the BTSearch algorithm. In models with multiple valid operator execution orders, compare the execution times of different methods.",
        "In addition, a comparison is made between the pruning frequency of the BTSearch algorithm and the total number of complete topological orderings searched. The comparative data are shown in Table . From the table, Random, PEFT, and Greedy optimize memory quickly, with time complexity O(N) for N model operators.",
        "BTSearch, despite higher time complexity, completes optimization and reaches the millisecond level of 10 3 ms, which is acceptable for fixed hardware environments and single inference tasks. Because the BTSearch method aims to optimize memory consumption, GenEFlow is provided with a broader search space to support more complex models and computational tasks. The \"Pruned\" and \"Searched\" columns in BTSearch show pruned and total searched orderings, respectively.",
        "BTSearch efficiently prunes orders that do not meet requirements based on graph states. Pruning reduces the search space significantly, considering fewer complete orderings and is especially effective when executed before many DAG operators start. Due to the lack of complex branching structures in GPT-2, the number of pruned orderings by BTSearch is 0.",
        "For the BERT and Qwen2 models, due to their complexity and the large number of operators, BTSearch prunes and searches a more significant number of orderings, resulting in better optimization. This approach ensures BTSearch navigates a manageable number of orderings, enhancing efficiency for complex models like InceptionV3, GoogLeNet, BERT, and Qwen2.",
        "4.3 Acceleration Optimization Analysis during Inference Process\nThe experiment evaluates the GenEFlow algorithm for model inference efficiency, excluding memory constraints. Inter-device bandwidth is limited to 2000 Mbps, and memory limits per device Here K fmh represents\nN fmh i =1 (k fmh i + 1) D−1 , K cout represents N cout j =1 (k cout j + 1) D−1\n, and K len represents\nN len l =1 (k len l + 1) D−1 . are set to 5000 MB, eliminating memory impact.",
        "are set to 5000 MB, eliminating memory impact. GenEFlow parameters include a single-objective GA, elite preservation, 250,000 population size, 50 max iterations, 1e-6 convergence threshold, and 10 max convergence generations. These settings aim to optimize model partitioning for efficient distributed inference.",
        "These settings aim to optimize model partitioning for efficient distributed inference. The GA search space upper bound S, as shown in Table , can be expressed as\nS = N fmh i (k fmh i +1) D−1 × N cout j (k cout j +1) D−1 × N len l (k len l +1) D−1 ,\nwhere k fmh i represents the output tensor size of the operators split by feature map height (fmh), k cout j represents the output channel size of the operators split by output channels (cout), k len l represents the tensor size of the operators split by output length (len), and D represents the number of distributed devices.",
        "Additionally, N fmh represents the number of operators split by feature map height (fmh), N cout represents the number of operators split by output channels (cout), and N len represents the number of operators split by output length (len). The table shows that the GPT-2, BERT, and Qwen2 models have a large search space due to their higher number of operators (Op Number). Consequently, the upper bounds of the search space for these models are much higher compared to models like VGG13 and ResNet50.",
        "The comparison in Figure illustrates GenEFlow's superior inference latency without memory constraints. It outperforms CoEdge by up to 33.9%. GenEFlow incurs minimal computational overhead and partitions each layer individually, enhancing its efficiency. In contrast, CoEdge optimizes layers individually, yielding inferior results holistically. Model size strongly correlates with inference latency.",
        "Model size strongly correlates with inference latency. GenEFlow excels in optimizing complex models but produces similar results to CoEdge for smaller models like SqueezeNet. The slight dip in GenEFlow's performance for Incep-tionV3 may stem from longer chromosome encoding and inadequate population size, leading to local optima. The Efficient-b0 model, with minimal computational overhead, favors DeepThings, which achieves marginally better results than GenEFlow.",
        "As shown in Figure , it compares the data transfer volume in the final operator scheduling obtained by the EfficientNet-b0 model under the GenEFlow and CoEdge methods. Compared to CoEdge, GenEFlow notably reduces communication by analyzing data transfer volumes, which is attributed to its holistic optimization objective encompassing computation and communication processes. The GA fosters offspring with lower latency, indirectly minimizing data communication during distributed inference.",
        "compares the optimization time for each method in this experiment. Except for GenE-Flow, all methods optimize the operators sequentially, resulting in faster optimization speeds at the second level. In contrast, the GenEFlow algorithm takes significantly longer, ranging from 1.7 to 36.4 hours. This is mainly due to using a genetic algorithm, which involves a lot of computation.",
        "This is mainly due to using a genetic algorithm, which involves a lot of computation. In this experiment, the number of distributed devices is fixed at 4, so the chromosome encoding length in the GenEFlow algorithm is proportional to the number of model operators. Therefore, models with a more significant number of operators require more time for population initialization and individual fitness evaluation within the population.",
        "4.4 Optimization Effect Analysis under Memory Limitation Conditions\nWe aim to validate the optimization effects of different methods on model inference efficiency while considering memory constraints. We set various device memory limitations to verify whether the optimization methods meet the specified memory constraints. If the memory requirements are met, then the inference acceleration effects of each model under memory constraints are analyzed as shown in Table .",
        "Prioritizing the adjustment of operator partitioning, GenEFlow optimizes inference memory overhead, facilitating efficient task execution even under stringent memory constraints. Memory thresholds are directly linked to the scale of model operators. CoEdge and GenEFlow minimize computational overhead, significantly reducing memory consumption compared to local and DeepThings' deployment methods.",
        "Tight memory constraints limit partitioning methods, reducing GenEFlow's search space and potential acceleration. GenEFlow adapts to varying memory constraints by considering device memory limits during GA application. Other methods lack memory consideration and remain fixed at specific thresholds, limiting their applicability and latency reduction even with increased memory availability.",
        "4.5 Heterogeneous Device Scalability and Inference Latency Analysis\nWe evaluate GenEFlow's inference latency on VGG13, ResNet50, MobileNetV3, and EfficientNet-b0 models by changing the number of devices and heterogeneous device configurations. The communication bandwidth is 2000 MB/s, the memory limit for each device is 5000 MB, the number of distributed devices is four, and the CFLOPS of the devices for each device is set to 0.5.",
        "Figure shows that as the number of devices increases, the inference latency of the models The memory limit is applied to each device. × indicates that the inference task cannot be completed under this memory limit. -indicates that increasing memory will not improve the optimization effect. first increases and then decreases, reaching the lowest latency when the number of distributed devices grows to four.",
        "When the number of distributed devices exceeds four, the inference latency gradually increases because the increase in communication time between devices outweighs the reduction in computation time due to distributed inference. We then fixed the number of devices to four and varied the CFLOPS values of each device to test the inference latency of models under heterogeneous device configurations. As shown in Figure . \"Heterogeneous Configuration\" refers to the CFLOPS settings of the four devices.",
        "\"Heterogeneous Configuration\" refers to the CFLOPS settings of the four devices. Configurations 1 through 7 correspond to the following CFLOPS settings: 1 (0.8, 0.8, 0.8, 0.8), 2 (0.8, 0.8, 0.8, 0.5), 3 (0.8, 0.8, 0.5, 0.5), 4 (0.8, 0.5, 0.5, 0.3), 5 (0.5, 0.5, 0.5, 0.3), 6 (0.5, 0.5, 0.3, 0.3), and 7 (0.3, 0.3, 0.3, 0.3).",
        "As the CFLOPS values decrease, the overall inference time of the models tends to decrease, particularly for the VGG13 and ResNet50 models, where the reduction in latency is most significant in Configurations 6 and 7. 4.6 Analysis of Inference Acceleration on Heterogeneous Edge Devices\nIn a real environment, we compare the inference acceleration effects of different baselines on the models InceptionV3, ResNet50, Vgg19, SqueezeNet, and MobileNetV3.",
        "Each operator of these models can be executed individually in all hardware configurations. The baseline methods include the following: (1) Local, where inference tasks are performed individually on each core and the average is taken as the result; (2) DeepThings, as described previously; and (3) CoEdge, as described previously. Figure shows the inference acceleration effects under different hardware configurations, with the results normalized to GenEFlow.",
        "From the results, it can be seen that GeneFlow is able to achieve optimal inference latency optimization in most cases. Therefore, on heterogeneous edge devices, the GeneFlow method can significantly enhance the inference performance of the models."
      ]
    }
  },
  "statistics": {
    "total_papers": 2,
    "total_sections": 2,
    "total_chunks": 53,
    "paper_details": {
      "Retrospection_on_the_Performance_Analysis_Tools_for_Large-Scale_HPC_Programs": {
        "sections": [
          "方法"
        ],
        "section_count": 1
      },
      "3701997": {
        "sections": [
          "实验评价"
        ],
        "section_count": 1
      }
    }
  }
}