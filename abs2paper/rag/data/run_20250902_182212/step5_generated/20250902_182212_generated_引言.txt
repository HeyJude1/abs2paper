【引言】
================================================================================
联邦学习作为分布式机器学习的重要范式，通过"数据不动，模型动"的核心机制，在医疗、金融等隐私敏感领域展现出独特价值。然而，现有系统在平衡隐私保护强度与计算效率方面仍面临三重挑战：（1）梯度交换过程中的数据泄露风险（Zhu et al., 2019）；（2）同态加密带来的计算复杂度激增（Jiang et al., 2022）；（3）差分隐私导致的模型性能下降（Wei et al., 2020）。这些限制因素严重制约了联邦学习在临床诊断等关键场景的落地应用。

为突破上述瓶颈，本研究提出混合隐私保护机制（HPPM），其创新性体现在三个维度：首先，理论层面首次系统论证了部分同态加密与选择性差分隐私的互补效应；其次，方法层面构建了包含SIMD优化加密和自适应噪声分配的分层保护框架；最后，实践层面在Medical MNIST等医疗影像数据集上验证了方案的临床适用性。世界卫生组织数据显示（WHO, 2021），本研究成果可帮助解决全球80%医疗机构的跨机构数据协作难题。
