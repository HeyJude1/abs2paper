{
  "structured_contexts": {
    "引言": "### Background 总结\n**总结1** (来源: Hybrid_CUDA_Unified_Memory_Management_in_Fully_Homomorphic_Encryption_Workloads):\n问题背景总结：\n1、研究领域: 高性能计算与密码学（具体为GPU加速的全同态加密技术）\n2、核心问题: 如何通过混合内存分配策略（cudaMallocAsync + cudaMallocManaged）优化全同态加密在零售GPU上的内存管理效率，解决传统方法中内存不足(OOM)和性能瓶颈问题。\n3、研究动机: \n- 理论价值：全同态加密(FHE)因高计算/内存需求阻碍实际部署，需突破性能限制\n- 实践价值：零售GPU内存有限且不可扩展，需开发高效内存管理方案以支持隐私计算应用（如云端机器学习）\n4、潜在应用: \n- 隐私保护的云计算服务\n- 加密数据上的安全机器学习推理\n- 资源受限环境（如边缘设备）的密文计算\n\n（注：总结严格基于原文中关于FHE应用瓶颈、GPU内存限制及混合内存策略目标的描述，未引入外部信息。）\n\n**总结2** (来源: Hybrid_CUDA_Unified_Memory_Management_in_Fully_Homomorphic_Encryption_Workloads):\n问题背景总结：\n1、研究领域: 高性能计算与密码学（具体为GPU加速的全同态加密技术）\n2、核心问题: 如何通过混合内存分配策略（cudaMallocAsync + cudaMallocManaged）优化全同态加密在零售GPU上的内存管理效率，解决传统方法中内存不足(OOM)和性能瓶颈问题。\n3、研究动机: \n- 理论价值：全同态加密(FHE)因高计算/内存需求阻碍实际部署，需突破性能限制\n- 实践价值：零售GPU内存有限且不可扩展，需开发高效内存管理方案以支持隐私计算应用（如云端机器学习）\n4、潜在应用: \n- 隐私保护的云计算服务\n- 加密数据上的安全机器学习推理\n- 资源受限环境（如边缘设备）的密文计算\n\n（注：总结严格基于原文中关于FHE应用瓶颈、GPU内存限制及混合内存策略目标的描述，未引入外部信息。）\n\n**总结3** (来源: 2309.11930v2):\n问题背景总结：  \n1、研究领域: 半监督学习（Semi-Supervised Learning, SSL）与开放世界识别（Open-World Recognition）的交叉领域，具体为开放世界半监督学习（OpenSSL）。  \n\n2、核心问题: 如何在未标记数据中同时存在已知类别（seen classes）和未知新类别（novel classes）的情况下，实现有效的半监督学习，即同步提升模型对已知类别的分类能力与对新类别的聚类能力。  \n\n3、研究动机:  \n- **理论价值**: 现有SSL方法假设未标记数据仅包含已知类别，而实际场景中未标记数据常混杂新类别，传统方法无法直接适用。  \n- **实践价值**: 解决开放世界半监督学习问题可降低对人工标注的依赖，更贴合真实应用场景（如大规模图像分类中未知类别的自动发现）。  \n\n4、潜在应用:  \n- 图像分类系统（如ImageNet数据集）中自动识别并归类未标注的新物体类别。  \n- 医学影像分析中利用少量标注数据同时识别已知疾病和发现潜在新病症。\n\n### Challenges 总结\n**总结1** (来源: 0728):\n### 核心挑战总结：\n\n#### 挑战一：**固有知识利用不足**  \n**分析**:  \n现有微调方法（如PEFT）主要关注算法优化或数据构建，但忽视了对预训练大语言模型（LLMs）固有知识的系统性挖掘与利用。研究表明，预训练LLMs的内部表征可能包含正确知识（即使输出错误），但当前微调范式缺乏有效机制将这些潜在知识显式整合到下游任务中。这一挑战源于对模型行为与知识表征之间关联性的理解不足，以及缺乏量化知识迁移的数学工具。\n\n#### 挑战二：**知识适应方向不明确**  \n**分析**:  \n微调过程中，LLMs从通用预训练知识到任务特定知识的适应过程是隐式的（如概率分布偏移），现有方法无法显式捕捉和强化这种适应方向。例如，模型可能生成相同token（如\"engage\"），但其预测概率分布的变化隐含了专业化知识的转移（如\"catalyze\"概率提升）。这种挑战源于概率空间的高维复杂性，以及缺乏将分布差异转化为可操作信号的机制。\n\n#### 挑战三：**数据稀缺下的性能瓶颈**  \n**分析**:  \n高质量人工标注数据集构建成本高昂，而现有数据增强方法（如输入输出对反转）难以充分...\n\n**总结2** (来源: 0728):\n### 核心挑战总结：\n\n#### 挑战一：**固有知识利用不足**  \n**分析**:  \n现有微调方法（如PEFT）主要关注算法优化或数据构建，但忽视了对预训练大语言模型（LLMs）固有知识的系统性挖掘与利用。研究表明，预训练LLMs的内部表征可能包含正确知识（即使输出错误），但当前微调范式缺乏有效机制将这些潜在知识显式整合到下游任务中。这一挑战源于对模型行为与知识表征之间关联性的理解不足，以及缺乏量化知识迁移的数学工具。\n\n#### 挑战二：**知识适应方向不明确**  \n**分析**:  \n微调过程中，LLMs从通用预训练知识到任务特定知识的适应过程是隐式的（如概率分布偏移），现有方法无法显式捕捉和强化这种适应方向。例如，模型可能生成相同token（如\"engage\"），但其预测概率分布的变化隐含了专业化知识的转移（如\"catalyze\"概率提升）。这种挑战源于概率空间的高维复杂性，以及缺乏将分布差异转化为可操作信号的机制。\n\n#### 挑战三：**数据稀缺下的性能瓶颈**  \n**分析**:  \n高质量人工标注数据集构建成本高昂，而现有数据增强方法（如输入输出对反转）难以充分...\n\n**总结3** (来源: 2406.15763v2):\n### 核心挑战总结：\n\n#### 挑战一：**伪标签质量与数量的权衡问题**  \n**分析**:  \n- **具体内容**: 现有阈值策略（如FixMatch的高固定阈值）为确保伪标签质量，会丢弃大量低置信度样本，导致未标记数据利用率不足。  \n- **根源**:  \n  1. **问题复杂性**: 模型训练初期预测不稳定，高阈值会过滤潜在有用信息；  \n  2. **技术瓶颈**: 静态阈值无法动态适应不同类别/阶段的学习状态；  \n  3. **数据限制**: 标记数据稀缺时，过度依赖高置信度伪标签加剧样本浪费。  \n\n#### 挑战二：**学习状态估计的偏差问题**  \n**分析**:  \n- **具体内容**: 现有方法（如FlexMatch、FreeMatch）仅依赖伪标签置信度评估学习状态，易受数据采样偏差或类间相似性干扰。  \n- **根源**:  \n  1. **技术瓶颈**: 单指标（如平均置信度）难以全面反映模型学习进展；  \n  2. **问题复杂性**: 类别不平衡或特征重叠时，伪标签可靠性下降。  \n\n#### 挑战三：**低置信度伪标签的潜在价值浪费** ...\n\n### Innovations 总结\n**总结1** (来源: Oikonomos-II_A_Reinforcement-Learning_Resource-Recommendation_System_for_Cloud_HPC):\n本文创新点总结：\n\n1、提出了一种基于强化学习的异构云环境HPC应用实例推荐系统 (类型: [新方法/新系统])  \n• 采用深度上下文多臂老虎机算法，克服了早期搜索型和预测型方法的局限性  \n• 首次实现混合型推荐系统，结合了两种传统方法的优势  \n\n2、改进了Neural-LinUCB算法 (类型: [算法优化])  \n• 通过引入软更新(soft update)机制，支持使用更深层的神经网络  \n• 实现了更复杂的上下文-奖励关系建模能力  \n\n3、在四种不同HPC应用上进行了系统性性能验证 (类型: [实验分析])  \n• 证明了强化学习方法的鲁棒性  \n• 展示了方案的通用性和可复用潜力  \n• 实证显示在大多数情况下能成功选择最优实例类型  \n\n注：所有贡献点均直接提取自论文引言部分明确列出的三个贡献项，并按照方法创新、算法改进和实验验证三个维度进行了分类。其中第一个贡献具有双重属性，既是新方法也是新系统实现。\n\n**总结2** (来源: Oikonomos-II_A_Reinforcement-Learning_Resource-Recommendation_System_for_Cloud_HPC):\n本文创新点总结：\n\n1、提出了一种基于强化学习的异构云环境HPC应用实例推荐系统 (类型: [新方法/新系统])  \n• 采用深度上下文多臂老虎机算法，克服了早期搜索型和预测型方法的局限性  \n• 首次实现混合型推荐系统，结合了两种传统方法的优势  \n\n2、改进了Neural-LinUCB算法 (类型: [算法优化])  \n• 通过引入软更新(soft update)机制，支持使用更深层的神经网络  \n• 实现了更复杂的上下文-奖励关系建模能力  \n\n3、在四种不同HPC应用上进行了系统性性能验证 (类型: [实验分析])  \n• 证明了强化学习方法的鲁棒性  \n• 展示了方案的通用性和可复用潜力  \n• 实证显示在大多数情况下能成功选择最优实例类型  \n\n注：所有贡献点均直接提取自论文引言部分明确列出的三个贡献项，并按照方法创新、算法改进和实验验证三个维度进行了分类。其中第一个贡献具有双重属性，既是新方法也是新系统实现。\n\n**总结3** (来源: 2406.15763v2):\n本文创新点总结：\n\n1. 提出类特定自适应阈值机制（CAT）  \n(类型: 新方法)  \n- 通过全局估计（未标记数据的平均置信度）和局部调整（基于分类器权重的类特定学习状态评估）两阶段策略，动态调整每个类别的阈值  \n- 相比现有动态阈值方法（如FreeMatch/FlexMatch），能更精准反映模型学习状态（见图b,c/f,g中的利用率和伪标签准确率优势）\n\n2. 设计二元分类一致性（BCC）正则化策略  \n(类型: 新方法)  \n- 将类别空间划分为候选类和负类，强制不同扰动视图下保持一致的候选-负类划分  \n- 动态确定top-k候选类参数k，利用低置信度伪标签的语义指导价值（实现100%未标记数据利用率）  \n- 实验证明λ_b=1.0时达到最优平衡（图）\n\n3. 系统验证框架的有效性  \n(类型: 深入的实验分析)  \n- 在CIFAR-10/100、SVHN、STL-10等基准测试中达到SOTA性能  \n- 特别在极端少样本场景（如CIFAR-10仅10标签）展现显著优势  \n- 通过t-SNE可视化证明特征可分性提升，混淆矩阵显示困难类别（如STL-10的3/5/7类...\n\n### Methodology 总结\n**总结1** (来源: 2309.11930v2):\n方法概述：  \n1、方法名称: **LPS (Learning Pace Synchronization)**  \n2、核心思想: 通过自适应边际损失（Adaptive Margin Loss）和伪标签对比聚类（Pseudo-Label Contrastive Clustering），同步模型对已知类别（seen classes）和新类别（novel classes）的学习速度，解决开放世界半监督学习（OpenSSL）中类别不平衡和未知类别聚类的问题。  \n\n3、主要流程/组件  \n**组件/步骤一: 自适应边际损失（Adaptive Margin Loss, L_AM）**  \n- **功能**: 动态调整不同类别的分类边界，抑制已知类别的过快学习，促进新类别的学习。  \n  - 基于当前模型预测的类别分布估计（π），通过KL散度计算类别特异性负边际（∆_j）。  \n  - 对高置信度的未标注数据生成伪标签，与标注数据共同优化损失。  \n\n**组件/步骤二: 伪标签对比聚类（Pseudo-Label Contrastive Clustering, L_PC）**  \n- **功能**...\n\n**总结2** (来源: 2309.11930v2):\n方法概述：  \n1、方法名称: **LPS (Learning Pace Synchronization)**  \n2、核心思想: 通过自适应边际损失（Adaptive Margin Loss）和伪标签对比聚类（Pseudo-Label Contrastive Clustering），同步模型对已知类别（seen classes）和新类别（novel classes）的学习速度，解决开放世界半监督学习（OpenSSL）中类别不平衡和未知类别聚类的问题。  \n\n3、主要流程/组件  \n**组件/步骤一: 自适应边际损失（Adaptive Margin Loss, L_AM）**  \n- **功能**: 动态调整不同类别的分类边界，抑制已知类别的过快学习，促进新类别的学习。  \n  - 基于当前模型预测的类别分布估计（π），通过KL散度计算类别特异性负边际（∆_j）。  \n  - 对高置信度的未标注数据生成伪标签，与标注数据共同优化损失。  \n\n**组件/步骤二: 伪标签对比聚类（Pseudo-Label Contrastive Clustering, L_PC）**  \n- **功能**...\n\n**总结3** (来源: Simulation_of_Large-Scale_HPC_Storage_Systems_Challenges_and_Methodologies):\n方法概述：\n1、方法名称: FIVES (Simulator for Scheduling on Storage Systems at Scale)\n\n2、核心思想: \nFIVES是一个面向高性能存储系统的仿真框架，通过模块化设计和自动化校准，实现存储系统行为的高效准确模拟。其核心思想是通过抽象化硬件平台和作业模型，结合贝叶斯优化进行参数校准，在保证仿真可扩展性的同时最大化模拟精度。\n\n3、主要流程/组件\n组件/步骤一: 仿真架构设计\n- 采用三层概念架构：作业管理器(创建/提交作业)、协调器(资源调度)、基础设施(硬件平台模拟)\n- 基于WRENCH和SimGrid框架实现，新增复合存储服务(CSS)组件支持分布式存储模拟\n\n组件/步骤二: 参数校准系统\n- 使用贝叶斯优化(BO)自动校准17个关键参数（平台带宽、作业文件数、节点参与数等）\n- 定义MAE损失函数评估仿真精度：真实与模拟I/O时间的百分比差异均值\n- 采用带宽分类策略（快/常规/慢作业）处理数据异质性\n\n组件/步骤三: 磁盘争用模型\n- 开发经验性对数模型：bw = bw_max * (1/(C + log n))\n...\n\n\n### 研究趋势分析\n**Challenges 趋势**:\n- 技术趋势: 数据稀缺技术广泛应用\n- 研究模式:  在40/5篇论文中被提及(800.0%), e在35/5篇论文中被提及(700.0%), n在33/5篇论文中被提及(660.0%)\n\n**Innovations 趋势**:\n- 技术趋势: 正则化技术广泛应用, 优化技术广泛应用\n- 研究模式: n在27/5篇论文中被提及(540.0%),  在23/5篇论文中被提及(460.0%), e在23/5篇论文中被提及(460.0%)\n\n**Methodology 趋势**:\n- 研究模式:  在32/5篇论文中被提及(640.0%), '在26/5篇论文中被提及(520.0%), n在26/5篇论文中被提及(520.0%)\n\n",
    "相关工作": "### RelatedWork 总结\n**总结1** (来源: 2406.15763v2):\n相关工作总结：\n\n1、现有方法一：一致性正则化与伪标签方法（Consistency Regulation & Pseudo Labeling）\n核心思想: \n- 通过弱增强样本生成伪标签，并强制其与强增强视图的预测保持一致（如FixMatch）。\n- 通过固定阈值（FixMatch）、课程学习类特定阈值（FlexMatch）、标记数据损失动态阈值（Dash）、无标记数据平均置信度阈值（FreeMatch）或高斯函数动态权重（SoftMatch）筛选高质量伪标签。\n\n主要局限性: \n- 固定阈值导致未标记数据利用率不足。\n- 现有方法对样本级约束（对比损失）或语义级监督的整合不足。\n\n2、现有方法二：对比学习增强方法（Contrastive-based Methods）\n核心思想: \n- 引入对比损失对全部未标记数据施加样本级约束（如CoMatch、SimMatch）。\n- 结合阈值策略与对比学习优势（如AllMatch的CAT阈值和BCC语义监督）。\n\n主要局限性: \n- FullMatch等并发工作仅通过强弱增强预测比较识别负类，未考虑样本与模型的全局学习状态。\n- 负类优化策略（如...\n\n**总结2** (来源: 2406.15763v2):\n相关工作总结：\n\n1、现有方法一：一致性正则化与伪标签方法（Consistency Regulation & Pseudo Labeling）\n核心思想: \n- 通过弱增强样本生成伪标签，并强制其与强增强视图的预测保持一致（如FixMatch）。\n- 通过固定阈值（FixMatch）、课程学习类特定阈值（FlexMatch）、标记数据损失动态阈值（Dash）、无标记数据平均置信度阈值（FreeMatch）或高斯函数动态权重（SoftMatch）筛选高质量伪标签。\n\n主要局限性: \n- 固定阈值导致未标记数据利用率不足。\n- 现有方法对样本级约束（对比损失）或语义级监督的整合不足。\n\n2、现有方法二：对比学习增强方法（Contrastive-based Methods）\n核心思想: \n- 引入对比损失对全部未标记数据施加样本级约束（如CoMatch、SimMatch）。\n- 结合阈值策略与对比学习优势（如AllMatch的CAT阈值和BCC语义监督）。\n\n主要局限性: \n- FullMatch等并发工作仅通过强弱增强预测比较识别负类，未考虑样本与模型的全局学习状态。\n- 负类优化策略（如...\n\n**总结3** (来源: 3656019.3689905):\n相关工作总结：\n\n1、现有方法一：结构化稀疏存储格式（Structured Sparse Formats）\n核心思想: 采用硬件友好的规则稀疏模式（如块稀疏），通过牺牲部分压缩率换取计算规整性，主要应用于机器学习领域。\n主要局限性: 存在精度与压缩率的固有权衡（accuracy-compression tradeoff），且受限于硬件强制的稀疏模式。\n\n2、现有方法二：坐标指针类格式（CSR及其变种）\n核心思想: 使用行偏移（row_ptr）和列索引（col_idx）的非规则存储方案，适用于超稀疏矩阵的科学计算场景。\n主要局限性: \n- 对中等稀疏度工作负载效率低下\n- 增加片上资源消耗（存储需求和通信开销）\n- 加剧内存带宽瓶颈（尤其在SpMM等带宽敏感任务中）\n\n3、现有方法三：位图存储格式（Bitmap-based Formats）\n核心思想: 通过位掩码标记非零元素位置，实现紧凑存储。\n主要局限性:\n- 缺乏成熟的索引策略\n- 处理长零值序列时效率低下\n- 需要昂贵比较操作消除无效计算\n\n4、现有方法四：分层存储技术（Hierarchical Storage Technique...\n\n### Challenges 总结\n**总结1** (来源: 0728):\n### 核心挑战总结：\n\n#### 挑战一：**固有知识利用不足**  \n**分析**:  \n现有微调方法（如PEFT）主要关注算法优化或数据构建，但忽视了对预训练大语言模型（LLMs）固有知识的系统性挖掘与利用。研究表明，预训练LLMs的内部表征可能包含正确知识（即使输出错误），但当前微调范式缺乏有效机制将这些潜在知识显式整合到下游任务中。这一挑战源于对模型行为与知识表征之间关联性的理解不足，以及缺乏量化知识迁移的数学工具。\n\n#### 挑战二：**知识适应方向不明确**  \n**分析**:  \n微调过程中，LLMs从通用预训练知识到任务特定知识的适应过程是隐式的（如概率分布偏移），现有方法无法显式捕捉和强化这种适应方向。例如，模型可能生成相同token（如\"engage\"），但其预测概率分布的变化隐含了专业化知识的转移（如\"catalyze\"概率提升）。这种挑战源于概率空间的高维复杂性，以及缺乏将分布差异转化为可操作信号的机制。\n\n#### 挑战三：**数据稀缺下的性能瓶颈**  \n**分析**:  \n高质量人工标注数据集构建成本高昂，而现有数据增强方法（如输入输出对反转）难以充分...\n\n**总结2** (来源: 0728):\n### 核心挑战总结：\n\n#### 挑战一：**固有知识利用不足**  \n**分析**:  \n现有微调方法（如PEFT）主要关注算法优化或数据构建，但忽视了对预训练大语言模型（LLMs）固有知识的系统性挖掘与利用。研究表明，预训练LLMs的内部表征可能包含正确知识（即使输出错误），但当前微调范式缺乏有效机制将这些潜在知识显式整合到下游任务中。这一挑战源于对模型行为与知识表征之间关联性的理解不足，以及缺乏量化知识迁移的数学工具。\n\n#### 挑战二：**知识适应方向不明确**  \n**分析**:  \n微调过程中，LLMs从通用预训练知识到任务特定知识的适应过程是隐式的（如概率分布偏移），现有方法无法显式捕捉和强化这种适应方向。例如，模型可能生成相同token（如\"engage\"），但其预测概率分布的变化隐含了专业化知识的转移（如\"catalyze\"概率提升）。这种挑战源于概率空间的高维复杂性，以及缺乏将分布差异转化为可操作信号的机制。\n\n#### 挑战三：**数据稀缺下的性能瓶颈**  \n**分析**:  \n高质量人工标注数据集构建成本高昂，而现有数据增强方法（如输入输出对反转）难以充分...\n\n**总结3** (来源: 2406.15763v2):\n### 核心挑战总结：\n\n#### 挑战一：**伪标签质量与数量的权衡问题**  \n**分析**:  \n- **具体内容**: 现有阈值策略（如FixMatch的高固定阈值）为确保伪标签质量，会丢弃大量低置信度样本，导致未标记数据利用率不足。  \n- **根源**:  \n  1. **问题复杂性**: 模型训练初期预测不稳定，高阈值会过滤潜在有用信息；  \n  2. **技术瓶颈**: 静态阈值无法动态适应不同类别/阶段的学习状态；  \n  3. **数据限制**: 标记数据稀缺时，过度依赖高置信度伪标签加剧样本浪费。  \n\n#### 挑战二：**学习状态估计的偏差问题**  \n**分析**:  \n- **具体内容**: 现有方法（如FlexMatch、FreeMatch）仅依赖伪标签置信度评估学习状态，易受数据采样偏差或类间相似性干扰。  \n- **根源**:  \n  1. **技术瓶颈**: 单指标（如平均置信度）难以全面反映模型学习进展；  \n  2. **问题复杂性**: 类别不平衡或特征重叠时，伪标签可靠性下降。  \n\n#### 挑战三：**低置信度伪标签的潜在价值浪费** ...\n\n### Baseline 总结\n**总结1** (来源: 2406.15763v2):\nBaseline选取总结：  \n1、对比方法:  \n[FixMatch]  \n[FlexMatch]  \n[Dash]  \n[FreeMatch]  \n[SoftMatch]  \n[CoMatch]  \n[SimMatch]  \n[FullMatch]  \n\n2、选取理由:  \n作者选择的Baseline覆盖了半监督学习（SSL）领域三大主流技术路线及最新进展：  \n- **技术路线覆盖性**：包括基于固定阈值（FixMatch）、课程学习启发的动态阈值（FlexMatch、Dash、FreeMatch）、软样本加权（SoftMatch）、对比损失约束（CoMatch、SimMatch）以及混合方法（FullMatch）。  \n- **代表性**：FixMatch是经典SOTA方法，结合了一致性正则化和伪标签技术；FlexMatch等动态阈值方法解决了FixMatch数据利用率低的问题；CoMatch/SimMatch代表对比学习路线；FullMatch是与本文同期工作的最新对比基线。  \n- **创新对比需求**：通过对比不同阈值策略（固定/动态/全局/类别自适应）和约束方式（阈值过...\n\n**总结2** (来源: 2406.15763v2):\nBaseline选取总结：  \n1、对比方法:  \n[FixMatch]  \n[FlexMatch]  \n[Dash]  \n[FreeMatch]  \n[SoftMatch]  \n[CoMatch]  \n[SimMatch]  \n[FullMatch]  \n\n2、选取理由:  \n作者选择的Baseline覆盖了半监督学习（SSL）领域三大主流技术路线及最新进展：  \n- **技术路线覆盖性**：包括基于固定阈值（FixMatch）、课程学习启发的动态阈值（FlexMatch、Dash、FreeMatch）、软样本加权（SoftMatch）、对比损失约束（CoMatch、SimMatch）以及混合方法（FullMatch）。  \n- **代表性**：FixMatch是经典SOTA方法，结合了一致性正则化和伪标签技术；FlexMatch等动态阈值方法解决了FixMatch数据利用率低的问题；CoMatch/SimMatch代表对比学习路线；FullMatch是与本文同期工作的最新对比基线。  \n- **创新对比需求**：通过对比不同阈值策略（固定/动态/全局/类别自适应）和约束方式（阈值过...\n\n**总结3** (来源: Allocation_Strategies_for_Disaggregated_Memory_in_HPC_Systems):\nBaseline选取总结：  \n1、对比方法:  \n- **Aggregated**（聚合内存分配策略）  \n- **Oldest-First**（基于任务运行时长优先的启发式算法）  \n- **Largest-First**（基于任务内存需求优先的启发式算法）  \n- **Priority**（动态优先级驱动的在线调度算法）  \n- **Stochastic**（基于统计内存行为的静态分配算法）  \n\n2、选取理由:  \n- **技术路线覆盖性**: 选择的Baseline涵盖了不同技术路径，包括传统聚合分配（Aggregated）、简单启发式规则（Oldest-First/Largest-First）、动态在线调度（Priority）和静态统计优化（Stochastic），以全面评估内存解耦场景下的性能差异。  \n- **SOTA代表性**: Priority和Stochastic是论文针对动态内存模式提出的新算法，需与经典启发式方法（Oldest-First/Largest-First）及默认聚合策略对比，验证其先进性。  \n- **场景适配验证**: Aggregated作为“...\n\n\n### 研究趋势分析\n**Challenges 趋势**:\n- 技术趋势: 数据稀缺技术广泛应用\n- 研究模式:  在40/5篇论文中被提及(800.0%), e在35/5篇论文中被提及(700.0%), n在33/5篇论文中被提及(660.0%)\n\n",
    "方法": "### Methodology 总结\n**总结1** (来源: 2309.11930v2):\n方法概述：  \n1、方法名称: **LPS (Learning Pace Synchronization)**  \n2、核心思想: 通过自适应边际损失（Adaptive Margin Loss）和伪标签对比聚类（Pseudo-Label Contrastive Clustering），同步模型对已知类别（seen classes）和新类别（novel classes）的学习速度，解决开放世界半监督学习（OpenSSL）中类别不平衡和未知类别聚类的问题。  \n\n3、主要流程/组件  \n**组件/步骤一: 自适应边际损失（Adaptive Margin Loss, L_AM）**  \n- **功能**: 动态调整不同类别的分类边界，抑制已知类别的过快学习，促进新类别的学习。  \n  - 基于当前模型预测的类别分布估计（π），通过KL散度计算类别特异性负边际（∆_j）。  \n  - 对高置信度的未标注数据生成伪标签，与标注数据共同优化损失。  \n\n**组件/步骤二: 伪标签对比聚类（Pseudo-Label Contrastive Clustering, L_PC）**  \n- **功能**...\n\n**总结2** (来源: 2309.11930v2):\n方法概述：  \n1、方法名称: **LPS (Learning Pace Synchronization)**  \n2、核心思想: 通过自适应边际损失（Adaptive Margin Loss）和伪标签对比聚类（Pseudo-Label Contrastive Clustering），同步模型对已知类别（seen classes）和新类别（novel classes）的学习速度，解决开放世界半监督学习（OpenSSL）中类别不平衡和未知类别聚类的问题。  \n\n3、主要流程/组件  \n**组件/步骤一: 自适应边际损失（Adaptive Margin Loss, L_AM）**  \n- **功能**: 动态调整不同类别的分类边界，抑制已知类别的过快学习，促进新类别的学习。  \n  - 基于当前模型预测的类别分布估计（π），通过KL散度计算类别特异性负边际（∆_j）。  \n  - 对高置信度的未标注数据生成伪标签，与标注数据共同优化损失。  \n\n**组件/步骤二: 伪标签对比聚类（Pseudo-Label Contrastive Clustering, L_PC）**  \n- **功能**...\n\n**总结3** (来源: Simulation_of_Large-Scale_HPC_Storage_Systems_Challenges_and_Methodologies):\n方法概述：\n1、方法名称: FIVES (Simulator for Scheduling on Storage Systems at Scale)\n\n2、核心思想: \nFIVES是一个面向高性能存储系统的仿真框架，通过模块化设计和自动化校准，实现存储系统行为的高效准确模拟。其核心思想是通过抽象化硬件平台和作业模型，结合贝叶斯优化进行参数校准，在保证仿真可扩展性的同时最大化模拟精度。\n\n3、主要流程/组件\n组件/步骤一: 仿真架构设计\n- 采用三层概念架构：作业管理器(创建/提交作业)、协调器(资源调度)、基础设施(硬件平台模拟)\n- 基于WRENCH和SimGrid框架实现，新增复合存储服务(CSS)组件支持分布式存储模拟\n\n组件/步骤二: 参数校准系统\n- 使用贝叶斯优化(BO)自动校准17个关键参数（平台带宽、作业文件数、节点参与数等）\n- 定义MAE损失函数评估仿真精度：真实与模拟I/O时间的百分比差异均值\n- 采用带宽分类策略（快/常规/慢作业）处理数据异质性\n\n组件/步骤三: 磁盘争用模型\n- 开发经验性对数模型：bw = bw_max * (1/(C + log n))\n...\n\n\n### 研究趋势分析\n**Methodology 趋势**:\n- 研究模式:  在32/5篇论文中被提及(640.0%), '在26/5篇论文中被提及(520.0%), n在26/5篇论文中被提及(520.0%)\n\n\n### 参考原文\n**论文 2309.11930v2 - 方法 章节**:\n片段1: 3 Adaptive Synchronizing\nTo start with, we describe the proposed adaptive marginal loss which regularizes the learning pace of seen classes to synchronize the learning pace of the model. Conventionally, the margin is defined as the minimum distance of the data to the classification boundary.\n片段2: For a sample (x, y), we have:\n∆(x, y) = f (x) y − max j̸ =y f (x) j (1)\nInstead of employing a fixed margin, LDAM introduces a class-specific margin, where the margin between rare classes and other classes is larger than the margin for frequent classes, for tackling class-imbalanced data. Specifical...\n\n",
    "实验评价": "### ExpeDesign 总结\n**总结1** (来源: 2309.11930v2):\n### 实验设计总结：\n\n1. **核心目标**:  \n   - 验证提出的LPS方法在开放集半监督学习（OpenSSL）场景下的鲁棒性和有效性。  \n   - 比较LPS与现有方法（SSL、OpenSSL、NCD等）在已知类和新类识别上的性能差异。  \n   - 分析LPS在微调预训练骨干网络时的抗过拟合能力。\n\n2. **数据集**:  \n   - **CIFAR-10/100**：标准图像分类数据集，分别包含10类和100类。实验中随机选择50%的类作为已知类（其中10%或50%数据有标签），其余为未标记的新类。  \n   - **ImageNet-100**：从ImageNet中抽取的100类子集，用于公平对比现有工作，实验设置与CIFAR类似（50%已知类+50%新类）。  \n\n3. **关键设置**:  \n   - **骨干网络**：CIFAR使用ResNet-18，ImageNet使用ResNet-50；均通过SimCLR预训练并固定前三层块。  \n   - **训练参数**：  \n     - CIFAR：SGD优化器（动量0.9，权重衰减0.0005），200 epo...\n\n**总结2** (来源: 2309.11930v2):\n### 实验设计总结：\n\n1. **核心目标**:  \n   - 验证提出的LPS方法在开放集半监督学习（OpenSSL）场景下的鲁棒性和有效性。  \n   - 比较LPS与现有方法（SSL、OpenSSL、NCD等）在已知类和新类识别上的性能差异。  \n   - 分析LPS在微调预训练骨干网络时的抗过拟合能力。\n\n2. **数据集**:  \n   - **CIFAR-10/100**：标准图像分类数据集，分别包含10类和100类。实验中随机选择50%的类作为已知类（其中10%或50%数据有标签），其余为未标记的新类。  \n   - **ImageNet-100**：从ImageNet中抽取的100类子集，用于公平对比现有工作，实验设置与CIFAR类似（50%已知类+50%新类）。  \n\n3. **关键设置**:  \n   - **骨干网络**：CIFAR使用ResNet-18，ImageNet使用ResNet-50；均通过SimCLR预训练并固定前三层块。  \n   - **训练参数**：  \n     - CIFAR：SGD优化器（动量0.9，权重衰减0.0005），200 epo...\n\n**总结3** (来源: Hybrid_CUDA_Unified_Memory_Management_in_Fully_Homomorphic_Encryption_Workloads):\n实验设计总结：\n\n1、核心目标:  \n- 验证三种内存管理方案（动态、静态、性能分析分配器）在不同GPU硬件上的性能表现  \n- 分析异步内存分配阈值对同态加密操作（特别是bootstrapping和ResNet推理）的影响  \n- 比较方案侵入性（代码修改程度）与性能收益的平衡关系  \n\n2、数据集:  \n- **BM-bootstrap**：包含连续bootstrapping操作的基准测试，涉及参数/密钥切换（约80GB内存占用）  \n- **Homomorphic ResNet**：同态加密版本的预训练深度学习模型，测试推理阶段性能（约200GB内存占用）  \n- **自定义HE函数测试集**：针对FGa/FGb/FVb等不同参数集的同态加密函数测试  \n\n3、关键设置:  \n- **硬件平台**：  \n  - 高端：NVIDIA A40 (48GB VRAM) - 仅测试最优的性能分析方案  \n  - 中端：GeForce GTX 1660 Ti (6GB VRAM)  \n  - 低端：GeForce GTX 1050 (2GB VRAM)  \n- **软件环境**：CUDA ...\n\n### Baseline 总结\n**总结1** (来源: 2406.15763v2):\nBaseline选取总结：  \n1、对比方法:  \n[FixMatch]  \n[FlexMatch]  \n[Dash]  \n[FreeMatch]  \n[SoftMatch]  \n[CoMatch]  \n[SimMatch]  \n[FullMatch]  \n\n2、选取理由:  \n作者选择的Baseline覆盖了半监督学习（SSL）领域三大主流技术路线及最新进展：  \n- **技术路线覆盖性**：包括基于固定阈值（FixMatch）、课程学习启发的动态阈值（FlexMatch、Dash、FreeMatch）、软样本加权（SoftMatch）、对比损失约束（CoMatch、SimMatch）以及混合方法（FullMatch）。  \n- **代表性**：FixMatch是经典SOTA方法，结合了一致性正则化和伪标签技术；FlexMatch等动态阈值方法解决了FixMatch数据利用率低的问题；CoMatch/SimMatch代表对比学习路线；FullMatch是与本文同期工作的最新对比基线。  \n- **创新对比需求**：通过对比不同阈值策略（固定/动态/全局/类别自适应）和约束方式（阈值过...\n\n**总结2** (来源: 2406.15763v2):\nBaseline选取总结：  \n1、对比方法:  \n[FixMatch]  \n[FlexMatch]  \n[Dash]  \n[FreeMatch]  \n[SoftMatch]  \n[CoMatch]  \n[SimMatch]  \n[FullMatch]  \n\n2、选取理由:  \n作者选择的Baseline覆盖了半监督学习（SSL）领域三大主流技术路线及最新进展：  \n- **技术路线覆盖性**：包括基于固定阈值（FixMatch）、课程学习启发的动态阈值（FlexMatch、Dash、FreeMatch）、软样本加权（SoftMatch）、对比损失约束（CoMatch、SimMatch）以及混合方法（FullMatch）。  \n- **代表性**：FixMatch是经典SOTA方法，结合了一致性正则化和伪标签技术；FlexMatch等动态阈值方法解决了FixMatch数据利用率低的问题；CoMatch/SimMatch代表对比学习路线；FullMatch是与本文同期工作的最新对比基线。  \n- **创新对比需求**：通过对比不同阈值策略（固定/动态/全局/类别自适应）和约束方式（阈值过...\n\n**总结3** (来源: Allocation_Strategies_for_Disaggregated_Memory_in_HPC_Systems):\nBaseline选取总结：  \n1、对比方法:  \n- **Aggregated**（聚合内存分配策略）  \n- **Oldest-First**（基于任务运行时长优先的启发式算法）  \n- **Largest-First**（基于任务内存需求优先的启发式算法）  \n- **Priority**（动态优先级驱动的在线调度算法）  \n- **Stochastic**（基于统计内存行为的静态分配算法）  \n\n2、选取理由:  \n- **技术路线覆盖性**: 选择的Baseline涵盖了不同技术路径，包括传统聚合分配（Aggregated）、简单启发式规则（Oldest-First/Largest-First）、动态在线调度（Priority）和静态统计优化（Stochastic），以全面评估内存解耦场景下的性能差异。  \n- **SOTA代表性**: Priority和Stochastic是论文针对动态内存模式提出的新算法，需与经典启发式方法（Oldest-First/Largest-First）及默认聚合策略对比，验证其先进性。  \n- **场景适配验证**: Aggregated作为“...\n\n### Metric 总结\n**总结1** (来源: Simulation_of_Large-Scale_HPC_Storage_Systems_Challenges_and_Methodologies):\n### 度量指标总结：\n\n#### 1、评估指标：\n- **Pearson's correlation coefficient（皮尔逊相关系数）**：衡量模拟累积I/O时间与真实累积I/O时间之间的线性相关性，用于验证模拟器是否能捕捉I/O时间的整体趋势。\n- **Job class matching rate（作业类别匹配率）**：统计模拟作业与真实作业属于同一类别的比例（文中为92%），反映模拟器对作业分类的准确性。\n- **I/O volume vs. time distribution（I/O量与时间分布）**：通过可视化对比真实与模拟作业的I/O量（字节）与I/O时间（秒）的分布，定性评估模拟行为是否覆盖真实场景的统计特性（如百分位范围）。\n\n#### 2、选取理由：\n论文选择上述指标基于以下合理性：\n- **核心目标适配性**：  \n  - Pearson相关系数直接服务于校准验证目标，量化模拟器对长期I/O时间趋势的捕捉能力，符合FIVES作为大规模作业模拟器的核心功能需求。  \n  - 作业类别匹配率和I/O分布分析针对异构作业环境设计，体现模拟器对不同类型作业（慢速/...\n\n**总结2** (来源: Simulation_of_Large-Scale_HPC_Storage_Systems_Challenges_and_Methodologies):\n### 度量指标总结：\n\n#### 1、评估指标：\n- **Pearson's correlation coefficient（皮尔逊相关系数）**：衡量模拟累积I/O时间与真实累积I/O时间之间的线性相关性，用于验证模拟器是否能捕捉I/O时间的整体趋势。\n- **Job class matching rate（作业类别匹配率）**：统计模拟作业与真实作业属于同一类别的比例（文中为92%），反映模拟器对作业分类的准确性。\n- **I/O volume vs. time distribution（I/O量与时间分布）**：通过可视化对比真实与模拟作业的I/O量（字节）与I/O时间（秒）的分布，定性评估模拟行为是否覆盖真实场景的统计特性（如百分位范围）。\n\n#### 2、选取理由：\n论文选择上述指标基于以下合理性：\n- **核心目标适配性**：  \n  - Pearson相关系数直接服务于校准验证目标，量化模拟器对长期I/O时间趋势的捕捉能力，符合FIVES作为大规模作业模拟器的核心功能需求。  \n  - 作业类别匹配率和I/O分布分析针对异构作业环境设计，体现模拟器对不同类型作业（慢速/...\n\n**总结3** (来源: 3656019.3676889):\n### 度量指标总结：\n\n1. **评估指标**:\n   - **Litmus Test Outcomes (允许/禁止的结果)**：衡量生成的流水线是否允许MCM允许的顺序，并禁止MCM禁止的顺序。\n   - **Ordering Enforcement (顺序执行)**：衡量流水线是否正确地强制执行了指定的内存一致性模型（MCM）顺序（如Load → Load, Store → Store, Store → Load, Load → Store）。\n   - **Fence Instruction Compliance (栅栏指令合规性)**：衡量流水线是否正确处理了栅栏指令（如x86TSO的mfence，ARMv8的LDAR、STLR、DMB SY等）的顺序要求。\n   - **Deadlock Avoidance (死锁避免)**：衡量流水线在强制执行顺序时是否避免了死锁情况（如Load Buffering中的死锁问题）。\n   - **Overly Conservative Orderings (过度保守的顺序)**：衡量流水线是否引入了比MCM要求更严格的顺序（如灰色单元格...\n\n### ResultAnalysis 总结\n**总结1** (来源: 2309.11930v2):\n实验结果分析总结：\n\n1、主要发现:\n- 在CIFAR-10数据集上，LPS方法在novel class准确率上比NACH提高1.2%；\n- 在CIFAR-100数据集上，LPS方法比baseline方法提高3.2%；\n- 在ImageNet-100数据集上，LPS方法的整体准确率比现有最优方法提高3.8%；\n- 当微调预训练主干网络时，LPS在CIFAR-10和CIFAR-100上的整体准确率分别提升2.9%和6.3%，而其他方法（ORCA和NACH）性能下降超过10%。\n\n2、消融研究结论:\n- 移除自适应边界损失（L_AM）会导致性能下降，改用标准交叉熵后效果变差；\n- 移除伪标签对比聚类损失（L_PC）会显著影响novel class的发现效果；\n- 移除无监督对比学习损失（L_UC）会降低模型性能；\n- 移除熵正则化器（R_Entropy）会导致novel class性能大幅下降，证明其在novel class发现中的关键作用。\n\n3、其他分析洞察:\n- 参数敏感性分析：\n   - η1和η2（损失权重参数）调整显示LPS具有良好鲁棒性；\n   - λ_novel较高时see...\n\n**总结2** (来源: 2309.11930v2):\n实验结果分析总结：\n\n1、主要发现:\n- 在CIFAR-10数据集上，LPS方法在novel class准确率上比NACH提高1.2%；\n- 在CIFAR-100数据集上，LPS方法比baseline方法提高3.2%；\n- 在ImageNet-100数据集上，LPS方法的整体准确率比现有最优方法提高3.8%；\n- 当微调预训练主干网络时，LPS在CIFAR-10和CIFAR-100上的整体准确率分别提升2.9%和6.3%，而其他方法（ORCA和NACH）性能下降超过10%。\n\n2、消融研究结论:\n- 移除自适应边界损失（L_AM）会导致性能下降，改用标准交叉熵后效果变差；\n- 移除伪标签对比聚类损失（L_PC）会显著影响novel class的发现效果；\n- 移除无监督对比学习损失（L_UC）会降低模型性能；\n- 移除熵正则化器（R_Entropy）会导致novel class性能大幅下降，证明其在novel class发现中的关键作用。\n\n3、其他分析洞察:\n- 参数敏感性分析：\n   - η1和η2（损失权重参数）调整显示LPS具有良好鲁棒性；\n   - λ_novel较高时see...\n\n**总结3** (来源: CAPTURE_Memory-Centric_Partitioning_for_Distributed_DNN_Training_with_Hybrid_Parallelism):\n实验结果分析总结：\n\n1、主要发现:\n- 在混合并行训练中，CAPTURE相比Alpa显著降低了峰值内存使用：\n  - 使用1F1B调度时，内存降低18.36%-43.92%（GPT-3、MoE和Wide-ResNet）\n  - 使用GPipe调度时，内存降低5.64%-21.38%\n- 纯流水线并行场景下：\n  - 1F1B调度获得19.38%-25.26%内存增益（除MoE外）\n  - GPipe调度对Wide-ResNet实现12.53%内存增益\n- 内存预测准确性：\n  - 44.8%的单GPU预测误差在2%内，97.1%在11%内\n  - 45.4%的整计划预测误差在2%内，97.8%在11%内\n- 硬件资源效率：\n  训练Wide-ResNet(1B)时，CAPTURE可在6 GPU上完成Alpa需要16 GPU的任务，且吞吐量提升36.3%\n\n2、消融研究结论:\n（注：原文未明确进行传统消融实验，但通过以下对比揭示了关键设计）\n- 层合并器(Layer Merger)的作用：\n  - 将MoE和GPT-3的运行时减少50%\n  - Wide-ResNet因本身16层结构不...\n\n\n### 研究趋势分析\n**ExpeDesign 趋势**:\n- 技术趋势: 数据集技术广泛应用, 基准测试技术广泛应用, 评价指标技术广泛应用\n- 研究模式:  在36/5篇论文中被提及(720.0%), '在28/5篇论文中被提及(560.0%), n在27/5篇论文中被提及(540.0%)\n\n**Metric 趋势**:\n- 研究模式:  在40/5篇论文中被提及(800.0%), t在35/5篇论文中被提及(700.0%), '在34/5篇论文中被提及(680.0%)\n\n\n### 参考原文\n**论文 2309.11930v2 - 实验评价 章节**:\n片段1: 7 Additional Results\nIn addition, we conduct more experiments to validate the robustness of the proposed method. We first conduct a series experiments on CIFAR-100 dataset with different numbers of novel classes, and the results are reported in the Figure To further evaluate the performance when fin...\n片段2: From Table , we can see that both ORCA and NACH show significant declines (over 10% overall accuracy), while our method LPS maintains high performance on CIFAR-100 and shows further improvements on CIFAR-10, which further verifies that LPS is not susceptible to the overfitting dilemma. 4 Experiments...\n\n",
    "总结": "### Conclusion 总结\n**总结1** (来源: 2309.11930v2):\n结论与展望总结：\n\n1、结论回顾:  \n- 提出了Learning Pace Synchronization (LPS)方法，通过自适应边界损失（adaptive margin loss）解决开放集学习（OpenSSL）中已知类与新类之间的学习速度差异问题。  \n- 设计了伪标签对比聚类损失（pseudo-label contrastive clustering loss）以增强新类发现能力。  \n- 在三个不同标注数据量的基准数据集上验证了方法的有效性，并发现冻结自监督预训练主干网络会限制泛化性能。  \n\n2、工作局限性:  \n- 未明确提及具体局限性，但通过实验参数分析隐含指出：  \n  - 边界参数C的调整需权衡对齐速度与伪标签准确性（C过大导致错误伪标签，过小则削弱对新类的偏向性）。  \n  - 温度参数τ对性能影响较小，但需通过实验确定最优值（τ=0.4）。  \n\n3、未来工作:  \n- 鼓励更多研究关注开放集学习的实际应用场景（\"realistic setting\"）。  \n- 未明确列出其他方向，但参数敏感性分析（如η₁、η₂、λ_novel的调整）暗示未来可进一步优化损...\n\n**总结2** (来源: 2309.11930v2):\n结论与展望总结：\n\n1、结论回顾:  \n- 提出了Learning Pace Synchronization (LPS)方法，通过自适应边界损失（adaptive margin loss）解决开放集学习（OpenSSL）中已知类与新类之间的学习速度差异问题。  \n- 设计了伪标签对比聚类损失（pseudo-label contrastive clustering loss）以增强新类发现能力。  \n- 在三个不同标注数据量的基准数据集上验证了方法的有效性，并发现冻结自监督预训练主干网络会限制泛化性能。  \n\n2、工作局限性:  \n- 未明确提及具体局限性，但通过实验参数分析隐含指出：  \n  - 边界参数C的调整需权衡对齐速度与伪标签准确性（C过大导致错误伪标签，过小则削弱对新类的偏向性）。  \n  - 温度参数τ对性能影响较小，但需通过实验确定最优值（τ=0.4）。  \n\n3、未来工作:  \n- 鼓励更多研究关注开放集学习的实际应用场景（\"realistic setting\"）。  \n- 未明确列出其他方向，但参数敏感性分析（如η₁、η₂、λ_novel的调整）暗示未来可进一步优化损...\n\n**总结3** (来源: 2406.15763v2):\n结论与展望总结：\n\n1、结论回顾:  \n- 论文针对半监督学习（SSL）中的两个关键问题（阈值机制设计和低置信度伪标签的利用）提出了两种创新策略：  \n  a) **类特定自适应阈值（CAT）**：通过未标记数据的预测和分类器权重建立动态阈值机制，适应不同类别的学习状态。  \n  b) **二元分类一致性（BCC）调控**：通过多视图扰动促进候选类与负类的一致性划分，提升低置信度伪标签的利用率。  \n- 提出的AllMatch框架在多个基准数据集（包括平衡和不平衡场景）上实现了最优性能，尤其在极少量标记样本条件下表现突出。  \n- 实验验证了BCC权重（λ_b=1.0）和候选类数量上限（K=10/20）的最优配置，并证明AllMatch在伪标签准确性和未标记数据利用率之间实现了更好权衡。\n\n2、工作局限性:  \n- **参数敏感性**：BCC权重（λ_b）和候选类数量上限（K）需通过网格搜索确定，可能增加调参成本。  \n- **数据集依赖性**：在更复杂的数据集（如ImageNet）上需调整K值至20，表明方法对数据特性存在一定依赖。  \n- **对比基准限制**：虽与SoftMatc...\n\n### ResultAnalysis 总结\n**总结1** (来源: 2309.11930v2):\n实验结果分析总结：\n\n1、主要发现:\n- 在CIFAR-10数据集上，LPS方法在novel class准确率上比NACH提高1.2%；\n- 在CIFAR-100数据集上，LPS方法比baseline方法提高3.2%；\n- 在ImageNet-100数据集上，LPS方法的整体准确率比现有最优方法提高3.8%；\n- 当微调预训练主干网络时，LPS在CIFAR-10和CIFAR-100上的整体准确率分别提升2.9%和6.3%，而其他方法（ORCA和NACH）性能下降超过10%。\n\n2、消融研究结论:\n- 移除自适应边界损失（L_AM）会导致性能下降，改用标准交叉熵后效果变差；\n- 移除伪标签对比聚类损失（L_PC）会显著影响novel class的发现效果；\n- 移除无监督对比学习损失（L_UC）会降低模型性能；\n- 移除熵正则化器（R_Entropy）会导致novel class性能大幅下降，证明其在novel class发现中的关键作用。\n\n3、其他分析洞察:\n- 参数敏感性分析：\n   - η1和η2（损失权重参数）调整显示LPS具有良好鲁棒性；\n   - λ_novel较高时see...\n\n**总结2** (来源: 2309.11930v2):\n实验结果分析总结：\n\n1、主要发现:\n- 在CIFAR-10数据集上，LPS方法在novel class准确率上比NACH提高1.2%；\n- 在CIFAR-100数据集上，LPS方法比baseline方法提高3.2%；\n- 在ImageNet-100数据集上，LPS方法的整体准确率比现有最优方法提高3.8%；\n- 当微调预训练主干网络时，LPS在CIFAR-10和CIFAR-100上的整体准确率分别提升2.9%和6.3%，而其他方法（ORCA和NACH）性能下降超过10%。\n\n2、消融研究结论:\n- 移除自适应边界损失（L_AM）会导致性能下降，改用标准交叉熵后效果变差；\n- 移除伪标签对比聚类损失（L_PC）会显著影响novel class的发现效果；\n- 移除无监督对比学习损失（L_UC）会降低模型性能；\n- 移除熵正则化器（R_Entropy）会导致novel class性能大幅下降，证明其在novel class发现中的关键作用。\n\n3、其他分析洞察:\n- 参数敏感性分析：\n   - η1和η2（损失权重参数）调整显示LPS具有良好鲁棒性；\n   - λ_novel较高时see...\n\n**总结3** (来源: CAPTURE_Memory-Centric_Partitioning_for_Distributed_DNN_Training_with_Hybrid_Parallelism):\n实验结果分析总结：\n\n1、主要发现:\n- 在混合并行训练中，CAPTURE相比Alpa显著降低了峰值内存使用：\n  - 使用1F1B调度时，内存降低18.36%-43.92%（GPT-3、MoE和Wide-ResNet）\n  - 使用GPipe调度时，内存降低5.64%-21.38%\n- 纯流水线并行场景下：\n  - 1F1B调度获得19.38%-25.26%内存增益（除MoE外）\n  - GPipe调度对Wide-ResNet实现12.53%内存增益\n- 内存预测准确性：\n  - 44.8%的单GPU预测误差在2%内，97.1%在11%内\n  - 45.4%的整计划预测误差在2%内，97.8%在11%内\n- 硬件资源效率：\n  训练Wide-ResNet(1B)时，CAPTURE可在6 GPU上完成Alpa需要16 GPU的任务，且吞吐量提升36.3%\n\n2、消融研究结论:\n（注：原文未明确进行传统消融实验，但通过以下对比揭示了关键设计）\n- 层合并器(Layer Merger)的作用：\n  - 将MoE和GPT-3的运行时减少50%\n  - Wide-ResNet因本身16层结构不...\n\n### Innovations 总结\n**总结1** (来源: Oikonomos-II_A_Reinforcement-Learning_Resource-Recommendation_System_for_Cloud_HPC):\n本文创新点总结：\n\n1、提出了一种基于强化学习的异构云环境HPC应用实例推荐系统 (类型: [新方法/新系统])  \n• 采用深度上下文多臂老虎机算法，克服了早期搜索型和预测型方法的局限性  \n• 首次实现混合型推荐系统，结合了两种传统方法的优势  \n\n2、改进了Neural-LinUCB算法 (类型: [算法优化])  \n• 通过引入软更新(soft update)机制，支持使用更深层的神经网络  \n• 实现了更复杂的上下文-奖励关系建模能力  \n\n3、在四种不同HPC应用上进行了系统性性能验证 (类型: [实验分析])  \n• 证明了强化学习方法的鲁棒性  \n• 展示了方案的通用性和可复用潜力  \n• 实证显示在大多数情况下能成功选择最优实例类型  \n\n注：所有贡献点均直接提取自论文引言部分明确列出的三个贡献项，并按照方法创新、算法改进和实验验证三个维度进行了分类。其中第一个贡献具有双重属性，既是新方法也是新系统实现。\n\n**总结2** (来源: Oikonomos-II_A_Reinforcement-Learning_Resource-Recommendation_System_for_Cloud_HPC):\n本文创新点总结：\n\n1、提出了一种基于强化学习的异构云环境HPC应用实例推荐系统 (类型: [新方法/新系统])  \n• 采用深度上下文多臂老虎机算法，克服了早期搜索型和预测型方法的局限性  \n• 首次实现混合型推荐系统，结合了两种传统方法的优势  \n\n2、改进了Neural-LinUCB算法 (类型: [算法优化])  \n• 通过引入软更新(soft update)机制，支持使用更深层的神经网络  \n• 实现了更复杂的上下文-奖励关系建模能力  \n\n3、在四种不同HPC应用上进行了系统性性能验证 (类型: [实验分析])  \n• 证明了强化学习方法的鲁棒性  \n• 展示了方案的通用性和可复用潜力  \n• 实证显示在大多数情况下能成功选择最优实例类型  \n\n注：所有贡献点均直接提取自论文引言部分明确列出的三个贡献项，并按照方法创新、算法改进和实验验证三个维度进行了分类。其中第一个贡献具有双重属性，既是新方法也是新系统实现。\n\n**总结3** (来源: 2406.15763v2):\n本文创新点总结：\n\n1. 提出类特定自适应阈值机制（CAT）  \n(类型: 新方法)  \n- 通过全局估计（未标记数据的平均置信度）和局部调整（基于分类器权重的类特定学习状态评估）两阶段策略，动态调整每个类别的阈值  \n- 相比现有动态阈值方法（如FreeMatch/FlexMatch），能更精准反映模型学习状态（见图b,c/f,g中的利用率和伪标签准确率优势）\n\n2. 设计二元分类一致性（BCC）正则化策略  \n(类型: 新方法)  \n- 将类别空间划分为候选类和负类，强制不同扰动视图下保持一致的候选-负类划分  \n- 动态确定top-k候选类参数k，利用低置信度伪标签的语义指导价值（实现100%未标记数据利用率）  \n- 实验证明λ_b=1.0时达到最优平衡（图）\n\n3. 系统验证框架的有效性  \n(类型: 深入的实验分析)  \n- 在CIFAR-10/100、SVHN、STL-10等基准测试中达到SOTA性能  \n- 特别在极端少样本场景（如CIFAR-10仅10标签）展现显著优势  \n- 通过t-SNE可视化证明特征可分性提升，混淆矩阵显示困难类别（如STL-10的3/5/7类...\n\n\n### 研究趋势分析\n**Innovations 趋势**:\n- 技术趋势: 正则化技术广泛应用, 优化技术广泛应用\n- 研究模式: n在27/5篇论文中被提及(540.0%),  在23/5篇论文中被提及(460.0%), e在23/5篇论文中被提及(460.0%)\n\n"
  },
  "context_sections": [
    "引言",
    "相关工作",
    "方法",
    "实验评价",
    "总结"
  ],
  "total_contexts": 5
}