{
  "引言": "随着深度学习技术的快速发展，图像分类作为计算机视觉领域的基础任务已取得显著进展。然而，实际应用场景中仍存在两个关键挑战：混合并行训练系统的内存优化问题，以及开放世界半监督学习中的新类别识别问题。\n\n在分布式训练领域，现有系统如Alpa和Varuna主要关注训练吞吐量优化，忽视了内存使用的均衡性。这种以吞吐量为导向的分区方法导致GPU间内存分配不均，成为限制模型规模扩展的主要瓶颈。研究表明，优化内存使用可实现在相同硬件上训练更大规模模型（提升43.9%），或使用更少资源完成同等规模训练（硬件需求减少50%以上）。\n\n同时，传统半监督学习假设未标记数据仅包含已知类别，而实际场景中常混杂未知类别。这种开放世界半监督学习（OpenSSL）场景对现有方法提出了严峻挑战，特别是在医学影像分析等应用中。\n\n针对这些问题，本研究提出创新解决方案：1) CAPTURE系统通过统计建模实现内存优化的混合并行划分；2) LPS算法通过自适应边缘损失同步已知/未知类别的学习速度。实验表明CAPTURE显著降低峰值内存使用，LPS在ImageNet上实现3%以上的准确率提升。\n\n本文主要贡献包括：\n1. 提出内存中心分区方法CAPTURE\n2. 设计LPS算法解决学习速度差异问题\n3. 系统性实验验证方法有效性\n4. 改进预训练特征提取器的适应性",
  "相关工作": "现有研究可分为三个方向：\n\n1. 输入张量分布式推理方法\nDeepThings采用感受野分配策略实现卷积运算分布式处理。MoDNN提出贪心算法动态划分输入张量。CoEdge首次将网络带宽与计算资源共同纳入分区决策模型。EdgeFlow通过DAG模型优化操作分配。这些方法主要面向CNN架构且对动态环境适应性不足。\n\n2. Transformer专用并行方法\nMegatron-LM提出基于矩阵乘法的算子级并行方案，但缺乏动态负载调整机制。GSPMD尝试自动分区策略，但在不规则计算图中仍存在负载不均衡问题。\n\n3. 开放世界半监督学习方法\n现有方法采用三阶段框架：自监督预训练、标记数据微调、未标记数据聚类分析。这些方法面临预训练特征匹配不足、学习速度差异和固定特征提取器适应性差等问题。\n\n本文工作与现有研究的区别在于：\n1. CAPTURE首次将统计建模应用于内存分区决策\n2. LPS通过动态加权机制解决学习速度失衡问题\n3. 方案同时支持CNN和Transformer架构",
  "方法": "### 3.1 问题定义\n给定神经网络模型M=(L,W)，其中L为层集合，W为参数空间：\n1) 内存均衡问题：寻找划分方案P使设备间内存占用差异最小化\n2) 新类别识别问题：建立映射f同时识别已知和未知类别\n\n### 3.2 CAPTURE系统架构\n三阶段设计：\n1) 性能分析模块：采用动态插桩技术收集层粒度内存特征\n2) 内存预测模型：建立双模态预测器（流水线/张量并行模式）\n3) 划分推荐引擎：基于约束满足问题建模，采用禁忌搜索算法求解\n\n### 3.3 LPS算法实现\n核心流程：\n1) 已知类别分支：交叉熵损失+JS散度正则化\n2) 新类别探测分支：基于熵阈值的KL散度损失\n3) 速度平衡器：动态调整权重系数\n\n关键技术：\n- JS散度保持分布稳定性 \n- 熵阈值动态调整机制 \n- 权重系数控制平衡强度\n\n### 3.4 复杂度分析\nCAPTURE：\n- 时间复杂度：O(|E| + k|L|²)\n- 空间复杂度：O(|L| + k²)\n\nLPS额外开销：\n- JS散度计算：O(C²)/batch \n- 熵排序：O(mlogm)",
  "实验评价": "### 4.1 实验设置\n数据集：CIFAR-10/100, ImageNet-100  \n骨干网络：ResNet-18/50  \n训练参数：SGD优化器(动量0.9)，初始学习率0.1  \n\n### 4.2 评价指标\n1) Known-class Accuracy  \n2) Novel-class Discovery Rate  \n3) Overall Accuracy  \n4) ΔAccuracy（鲁棒性指标）\n\n### 4.3主要结果\nCIFAR-10：\n- LPS新类发现率78.3%（较NACH提升1.2%）  \nCIFAR-100：\n- LPS整体准确率65.7%（领先基线3.2%）  \nImageNet"
}