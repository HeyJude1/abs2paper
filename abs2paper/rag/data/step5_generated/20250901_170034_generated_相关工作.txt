【相关工作】
================================================================================
本节系统梳理分布式训练优化和开放世界半监督学习的研究进展，明确本工作的创新定位。

2.1 分布式训练优化
现有工作可分为两类技术路线：
(1) 数据并行方法：如DeepThings采用感受野划分策略，MoDNN提出贪心分区算法。这些方法虽在CNN上有效，但缺乏对Transformer等架构的支持。
(2) 模型并行策略：以Megatron-LM为代表的算子级并行方案受限于单层计算加速，难以实现跨层优化。

2.2 开放世界半监督学习
当前研究方法主要包括：
(1) 传统SSL扩展：FixMatch等方法假设封闭世界场景
(2) 自监督增强：SimCLR等引入对比学习但仍缺乏新类别识别机制
(3) 联合学习方法：DS3L尝试结合SSL与开放集识别

研究缺口分析揭示三个关键问题：
1. 缺乏支持多架构的通用分区策略
2. 现有方法未能有效平衡新旧类别学习速度
3. 固定特征表示限制模型适应性

本文的创新性体现在：
• CAPTURE框架实现跨架构内存优化
• LPS算法通过动态加权解决学习速度失衡
• 可微调特征提取器增强适应性
