{
  "引言": "近年来，深度学习在计算机视觉领域取得了突破性进展，特别是卷积神经网络（CNN）和Transformer架构在ImageNet等基准数据集上展现出卓越性能。然而，模型规模的指数级增长使得传统集中式训练模式面临严峻的计算资源挑战。分布式训练技术，尤其是混合并行（Hybrid Parallelism）策略，通过协同数据并行、模型并行和流水线并行的优势，成为解决这一问题的关键途径。尽管现有系统如Alpa和Varuna已初步验证了混合并行的可行性，但这些系统过度关注训练吞吐量优化，忽视了内存分配的均衡性问题。\n\n当前混合并行系统面临的核心挑战在于：现有分区算法以吞吐量最大化为单一优化目标，导致GPU间内存使用存在显著不均衡现象。这种不均衡性具体表现为：(1)可训练模型规模受限，无法充分利用硬件内存资源；(2)部分GPU因内存不足而闲置，造成计算资源浪费。特别是在流水线并行与数据/张量并行组合场景下，不同神经网络层的内存需求差异会随分区方案变化而放大，形成系统性瓶颈。其根本原因在于现有方法缺乏对内存使用模式的精确建模能力。\n\n解决上述问题面临三重技术挑战：首先，混合并行系统中的内存使用具有动态复合特征——流水线阶段需存储多微批次激活值，而数据/张量并行阶段则受参数分片策略影响。其次，现有方法难以准确建模层间依赖关系，特别是不同网络层（如卷积层与全连接层）的异构内存访问模式。第三，硬件异构性（如GPU型号差异）进一步增加了分区方案的复杂度。\n\n本研究提出CAPTURE框架的创新动机源于理论与实践的双重需求：理论上需要建立融合\"吞吐量优化\"与\"内存优化\"的统一设计范式；实践上则追求通过高效内存管理实现显著性能提升（实验显示可支持43.9%的模型规模扩展或2倍资源节约）。这些改进对于降低大模型训练成本具有重要经济价值。\n\n本文的核心贡献包括：\n1. 提出首个面向混合并行训练的内存中心分区框架CAPTURE\n2. 开发基于统计学的多维度内存预测模型\n3. 在真实场景验证框架有效性\n4. 开源完整实现促进领域发展\n\n论文结构如下：第2节综述相关工作；第3节形式化问题定义；第4节详述方法设计；第5节展示实验结果；第6节讨论实际应用；第7节总结展望。",
  "相关工作": "本节从技术路线演进角度系统梳理混合并行训练的研究进展：\n\n1. 分布式推理优化\n早期研究聚焦输入张量的分布式处理。DeepThings[1]提出感受野分配理论奠定基础；MoDNN[2]引入贪心算法实现动态负载均衡；CoEdge[3]进一步扩展为多维约束优化问题；EdgeFlow[4]则基于DAG模型重构分区策略。这类方法存在架构适应性差（仅适用于CNN）和动态响应不足的缺陷。\n\n2. Transformer并行技术\nMegatron-LM[5]开创性地提出矩阵乘法并行方案，但缺乏跨层优化能力。近期Alpa/Varuna[6]构建的混合并行系统暴露出内存失衡问题。\n\n3. 自动调优技术\n历经三个阶段发展：(1)基于词法标记的浅层分析；(2)LLVM IR表示学习[7]；(3)现代搜索式调优（如ActiveHarmony）。现有方法普遍面临收敛速度慢和内存预测不准的瓶颈。\n\n当前研究存在三个共性局限：\n(1) 单维度优化导致资源分配失衡\n(2) 动态环境适应能力不足  \n(3) 跨平台通用性有限\n\n相较已有工作，CAPTURE的创新性体现在：\n1. 建立计算-通信-存储的多维统一模型\n2. 开发轻量级动态预测机制\n3. 实现吞吐量与内存优化的协同决策",
  "方法": "### 3.1 框架概述\nCAPTURE采用三阶段处理流程：\n1. 性能分析：轻量级采集层级内存特征\n2. 统计预测：建立外推模型评估配置方案  \n3. 配置推荐：生成帕累托最优解集\n\n### 3.2 问题形式化\n给定L层神经网络和N个异构GPU，寻求最优配置C=(P,D,T)满足：\nmin(max(M(g_i))-min(M(g_j)))\n约束条件：\n1. 计算依赖保持\n2. 通信带宽限制  \n3. 设备容量约束\n\n### 3.3 核心模块\n#### 3.3.1 分析模块\n实施短时运行采集：\n- 独立内存(M_i)\n- 增量内存(M_a)  \n-"
}