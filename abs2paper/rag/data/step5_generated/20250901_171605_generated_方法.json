{
  "方法": "### 3.1 框架概述\nMIREncoder采用三级处理流程：（1）多模态解析层将LLVM IR转换为包含语法节点、控制流边和数据流边的异构图；（2）分层编码层通过类型敏感的图注意力网络实现特征融合；（3）任务适配层采用LoRA技术进行参数高效微调。\n\n### 3.2 异构图构建\n给定LLVM IR模块M，定义有向图G=(V,E)其中：\n- 节点集V包含指令（I）、基本块（B）、函数（F）三类实体\n- 边集E分为语法边E_syn（如AST父子关系）、控制边E_cfg（基本块跳转）、数据边E_data（值依赖）\n\n### 3.3 HGAT编码器\n采用分层注意力机制：\n```\n节点级：h_i^(l+1) = σ(∑_(j∈N_i) α_ij^(l) W_φ(e_ij) h_j^(l))\n边型级：α_ij = softmax(LeakyReLU(a^T[Wh_i||Wh_j]))\n```\n其中φ(e_ij)∈{syn,cfg,data}标识边类型，W_φ为类型特定参数矩阵。\n\n### 3.4 预训练任务\n设计两类目标函数：\n- 跨模态对齐损失：L_cma = E[||h_ast - h_cfg||₂²]\n- 性能预测掩码：L_ppm = BCE(f(h_masked), ΔIPC)"
}