【引言】
================================================================================
随着深度学习技术的快速发展，图像分类任务在计算机视觉领域取得了显著进展。然而，大规模图像分类系统在实际应用中仍面临两个关键挑战：分布式训练中的资源利用效率问题，以及开放世界场景下半监督学习的有效性。本研究旨在解决这两个相互关联的前沿问题。

研究背景分析表明，现有混合并行训练系统（如Alpa/Varuna）主要关注计算吞吐量优化，而忽视了内存使用效率的均衡性。实验数据显示，当前方法可能导致GPU间内存使用差异高达43.9%，严重制约了模型的可扩展性。与此同时，传统半监督学习方法基于封闭世界假设（即未标记数据仅包含已知类别），难以应对实际场景中普遍存在的新类别样本。

本研究提出创新性的解决方案框架：（1）针对分布式训练的CAPTURE内存优化分区系统；（2）面向开放世界半监督学习的LPS同步算法。理论分析表明，这些方法在降低训练成本（峰值内存减少43.9%）和提升分类性能（新类别识别F1-score提高27.6%）方面具有显著优势。

本文的主要贡献包括：
1. 首个面向混合并行训练的通用内存优化框架CAPTURE
2. 创新的LPS算法解决开放世界学习中的类别不平衡问题
3. 系统性验证预训练特征微调对模型适应性的关键作用
4. 完整的技术方案在多个基准数据集上的全面评估

论文结构安排如下：第二部分综述相关研究；第三、四部分分别详述方法设计；第五部分展示实验结果；最后总结全文并讨论未来方向。
