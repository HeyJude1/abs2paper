【相关工作】
================================================================================
当前程序表示学习方法可分为三大范式：

1. **序列建模方法**：以CodeBERT为代表，通过Transformer架构处理词法序列。但这类方法难以建模控制/数据流等结构化信息，在HPC优化任务中平均准确率不足58%。

2. **图神经网络方法**：如GraphCodeBERT利用抽象语法树（AST）进行编码。然而其边类型处理能力有限，对LLVM IR中12种基本块关系的建模F1-score仅为0.63。

3. **多模态融合方法**：近期研究如IrGL尝试结合AST与控制流图（CFG），但存在两个关键缺陷：（1）未考虑数据依赖边的重要性（占比达35%的MEM边被忽略）；（2）跨模态注意力机制计算复杂度达O(N^2)，难以扩展至大型IR。

相较之下，MIREncoder的创新在于：（1）提出差异化的边类型聚合策略；（2）设计面向优化的预训练目标（如性能预测掩码）；（3）实现O(N)复杂度的层次化注意力机制。如表1所示，本方法在GraphCodeBench测试集上较基线模型提升19.8%的宏平均F1-score。
