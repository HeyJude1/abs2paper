{
  "section_name": "方法",
  "context": "# 生成论文方法部分的参考资料\n\n### Methodology 总结\n**总结1** (来源: 3656019.3676895):\n方法概述：\n1、方法名称: MIREncoder\n2、核心思想: 通过多模态自监督预训练方法，将LLVM IR（中间表示）同时建模为词序列和依赖图两种模态，以提取语法、语义和结构特征，用于高性能计算（HPC）的性能优化任务。\n\n3、主要流程/组件\n组件/步骤一: IR词序列处理\n- 功能：将IR指令拆分为子词单元，通过训练的WordPiece分词器转换为数值化序列（类似BERT处理方式）\n- 关键点：采用64长度限制的语句级编码，包含特殊标记[CLS]/[SEP]，支持Masked Language Modeling任务\n\n组件/步骤二: 依赖图生成\n- 功能：使用PROGRAML工具将IR转换为包含数据流、控制流和调用流的多图结构\n- 关键点：节点特征为IR语句，通过分词器转换为数值特征供图神经网络处理\n\n组件/步骤三: 多模态预训练任务\n1) 掩码语言建模(MLM)：\n- 随机掩码15%IR词序列，通过Transformer层预测被掩码内容\n- 采用80-10-10的掩码策略避免模型对[MASK]标记过拟合\n\n2) 图自编码(GAE)：\n- 使用GNN层编码多图为低维表示，并重建原...\n\n**总结2** (来源: 3656019.3676895):\n方法概述：\n1、方法名称: MIREncoder\n2、核心思想: 通过多模态自监督预训练方法，将LLVM IR（中间表示）同时建模为词序列和依赖图两种模态，以提取语法、语义和结构特征，用于高性能计算（HPC）的性能优化任务。\n\n3、主要流程/组件\n组件/步骤一: IR词序列处理\n- 功能：将IR指令拆分为子词单元，通过训练的WordPiece分词器转换为数值化序列（类似BERT处理方式）\n- 关键点：采用64长度限制的语句级编码，包含特殊标记[CLS]/[SEP]，支持Masked Language Modeling任务\n\n组件/步骤二: 依赖图生成\n- 功能：使用PROGRAML工具将IR转换为包含数据流、控制流和调用流的多图结构\n- 关键点：节点特征为IR语句，通过分词器转换为数值特征供图神经网络处理\n\n组件/步骤三: 多模态预训练任务\n1) 掩码语言建模(MLM)：\n- 随机掩码15%IR词序列，通过Transformer层预测被掩码内容\n- 采用80-10-10的掩码策略避免模型对[MASK]标记过拟合\n\n2) 图自编码(GAE)：\n- 使用GNN层编码多图为低维表示，并重建原...\n\n**总结3** (来源: 3650200.3656600):\n方法概述：\n1、方法名称: DAWN (Distance Assessment algorithm With matrix operations on Networks)\n2、核心思想: 通过优化布尔矩阵运算来加速无权图中的最短路径计算，利用矩阵乘法的部分结果选择性跳过冗余边访问，从而减少计算量。其核心直觉是：仅关注对最短路径问题有实际影响的矩阵行列，并通过稀疏性优化进一步提升性能。\n\n3、主要流程/组件\n组件/步骤一: BOVM (Boolean Vector-Matrix Operation)\n- 功能：将传统向量-矩阵乘法转化为布尔运算，通过压缩非零元素索引减少计算量。当首次发现路径时立即终止计算（利用Theorem 3.2保证首次发现的路径即最短路径），并跳过后续冗余计算。\n\n组件/步骤二: SOVM (Sparse Optimized Boolean Vector-Matrix Operation)\n- 功能：针对稀疏图的扩展优化，结合图遍历与矩阵运算。通过限制操作范围于邻居节点集，并排除已确定最短路径的节点（利用CSR矩阵格式和动态更新的布尔数组），将时间复杂度降至O(E_...\n\n\n### 研究趋势分析\n**Methodology 趋势**:\n- 技术趋势: Transformer技术广泛应用, 多模态技术广泛应用, 自监督技术广泛应用\n- 研究模式:  在41/5篇论文中被提及(820.0%), '在34/5篇论文中被提及(680.0%), o在21/5篇论文中被提及(420.0%)\n\n\n### 参考原文\n**论文 3656019.3676895 - 方法 章节**:\n片段1: 3 MIREncoder\nMost source-code based performance optimization tasks in HPC usually involve compilable languages such as C, C++, CUDA, and so on. A large number of these languages can be compiled and optimized using the LLVM infrastructure. LLVM IRs are a portable, high-level assembly language that ca...\n片段2: It is fairly simple to extract IRs from source code such as C, C++. IRs generated from source code are usually devoid of most stylistic choices and redundant code. This is why we choose to work with IRs for performance optimizations. Figure shows a high-level overview of our approach. For the first ...\n\n\n### 写作要求\n1. 基于以上参考资料生成论文的方法部分\n2. 保持学术论文的严谨性和专业性\n3. 确保内容逻辑清晰，表达准确\n4. 字数控制在800-1200字之间\n5. 使用规范的学术写作格式\n",
  "context_length": 2563
}