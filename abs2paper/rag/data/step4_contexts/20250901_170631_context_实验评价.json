{
  "section_name": "实验评价",
  "context": "# 生成论文实验评价部分的参考资料\n\n### ExpeDesign 总结\n**总结1** (来源: 2309.11930v2):\n### 实验设计总结：\n\n1. **核心目标**:  \n   - 验证提出的LPS方法在开放集半监督学习（OpenSSL）场景下的鲁棒性和有效性。  \n   - 比较LPS与现有方法（SSL、OpenSSL、NCD等）在已知类和新类识别上的性能差异。  \n   - 分析LPS在微调预训练骨干网络时的抗过拟合能力。\n\n2. **数据集**:  \n   - **CIFAR-10/100**：标准图像分类数据集，分别包含10类和100类。实验中随机选择50%的类作为已知类（其中10%或50%数据有标签），其余为未标记的新类。  \n   - **ImageNet-100**：从ImageNet中抽取的100类子集，用于公平对比现有工作，实验设置与CIFAR类似（50%已知类+50%新类）。  \n\n3. **关键设置**:  \n   - **骨干网络**：CIFAR使用ResNet-18，ImageNet使用ResNet-50；均通过SimCLR预训练并固定前三层块。  \n   - **训练参数**：  \n     - CIFAR：SGD优化器（动量0.9，权重衰减0.0005），200 epo...\n\n**总结2** (来源: 2309.11930v2):\n### 实验设计总结：\n\n1. **核心目标**:  \n   - 验证提出的LPS方法在开放集半监督学习（OpenSSL）场景下的鲁棒性和有效性。  \n   - 比较LPS与现有方法（SSL、OpenSSL、NCD等）在已知类和新类识别上的性能差异。  \n   - 分析LPS在微调预训练骨干网络时的抗过拟合能力。\n\n2. **数据集**:  \n   - **CIFAR-10/100**：标准图像分类数据集，分别包含10类和100类。实验中随机选择50%的类作为已知类（其中10%或50%数据有标签），其余为未标记的新类。  \n   - **ImageNet-100**：从ImageNet中抽取的100类子集，用于公平对比现有工作，实验设置与CIFAR类似（50%已知类+50%新类）。  \n\n3. **关键设置**:  \n   - **骨干网络**：CIFAR使用ResNet-18，ImageNet使用ResNet-50；均通过SimCLR预训练并固定前三层块。  \n   - **训练参数**：  \n     - CIFAR：SGD优化器（动量0.9，权重衰减0.0005），200 epo...\n\n**总结3** (来源: 3688609):\n### 实验设计总结：\n\n#### 1. 核心目标:\n- **验证模型压缩技术的有效性**：通过权重剪枝（weight pruning）、通道剪枝（channel pruning）和数据量化（float16/int8）三种方法，评估其对模型精度和推理性能的影响。\n- **比较不同卷积算法的性能**：在CPU和GPU上测试直接卷积（direct）、GEMM和空间打包卷积（spatial pack）三种算法的效率，包括密集（dense）和稀疏（sparse）版本。\n- **评估跨硬件平台的适应性**：分析模型在Intel CPU、Arm CPU（HiKey 970）、Arm GPU（HiKey 970）和Nvidia GPU（Xavier）上的表现差异。\n\n#### 2. 数据集:\n- **CIFAR-10**：小型图像分类数据集，包含10类60,000张32x32图像。实验中训练了ResNet18、MobileNet V1/V2和VGG-16模型。\n- **ImageNet**：大规模图像分类数据集，包含1,000类约120万张图像。实验中使用了预训练的DenseNet161、Effic...\n\n### Baseline 总结\n**总结1** (来源: 3577193.3593714):\nBaseline选取总结：\n\n1、对比方法:\n- Reuse Distance Analysis (重用距离分析)\n- IR2Vec\n- Baghdadi et al.'s Polyhedral Performance Model (Baghdadi等人的多面体性能模型)\n\n2、选取理由: \n作者选择这些Baseline主要基于以下三个维度：\n(1) 技术路线代表性：覆盖传统分析（重用距离分析）、中间表示学习（IR2Vec）和现代多面体优化（Baghdadi模型）三种典型技术路径；\n(2) 先进性考量：Baghdadi模型是当前多面体程序优化的SOTA方法，IR2Vec是基于LLVM IR的最新嵌入方法；\n(3) 对比完整性：重用距离分析作为经典缓存行为模拟方法，提供传统性能分析的基准参照。三者共同构成从传统到现代、从模拟到学习的完整技术谱系对比。\n\n特别值得注意的是，作者对每个Baseline都进行了适应性改造以确保可比性：对重用距离分析限制模拟迭代次数（500次），对Baghdadi模型移除最后的线性预测层，这种处理体现了对比实验的严谨性。\n\n**总结2** (来源: 3577193.3593714):\nBaseline选取总结：\n\n1、对比方法:\n- Reuse Distance Analysis (重用距离分析)\n- IR2Vec\n- Baghdadi et al.'s Polyhedral Performance Model (Baghdadi等人的多面体性能模型)\n\n2、选取理由: \n作者选择这些Baseline主要基于以下三个维度：\n(1) 技术路线代表性：覆盖传统分析（重用距离分析）、中间表示学习（IR2Vec）和现代多面体优化（Baghdadi模型）三种典型技术路径；\n(2) 先进性考量：Baghdadi模型是当前多面体程序优化的SOTA方法，IR2Vec是基于LLVM IR的最新嵌入方法；\n(3) 对比完整性：重用距离分析作为经典缓存行为模拟方法，提供传统性能分析的基准参照。三者共同构成从传统到现代、从模拟到学习的完整技术谱系对比。\n\n特别值得注意的是，作者对每个Baseline都进行了适应性改造以确保可比性：对重用距离分析限制模拟迭代次数（500次），对Baghdadi模型移除最后的线性预测层，这种处理体现了对比实验的严谨性。\n\n**总结3** (来源: HPC_Application_Parameter_Autotuning_on_Edge_Devices_A_Bandit_Learning_Approach):\n### Baseline选取总结：\n\n1. **对比方法**:  \n   - BLISS（Bayesian Learning-based Iterative Software System）\n\n2. **选取理由**:  \n   - **SOTA代表性**：BLISS是当前最先进的（SOTA）基于机器学习的优化方法，采用贝叶斯优化（BO）来减少调优开销，并通过构建多样化的简化模型池加速收敛。选择它能够直接对比LASP与前沿方法的性能差异。  \n   - **技术路线对比**：BLISS依赖复杂的代理模型预测和计算密集型优化，而LASP专注于轻量级设计（适合资源受限的边缘设备）。这种对比凸显了两种技术路线的优劣（如BLISS的精度优势 vs. LASP的资源效率）。  \n   - **实验验证需求**：作者通过分析BLISS与LASP在CPU/内存占用上的差异（在MAXN和5W两种功耗模式下），证明LASP更适合边缘场景的动态性需求，从而强化了论文的贡献——轻量化自适应调优的实用性。  \n\n**补充说明**：  \n论文虽未明确列出其他经典基线（如随机搜索、遗传算法等），但通过强调与BLI...\n\n### Metric 总结\n**总结1** (来源: 3688609):\n### 度量指标总结  \n\n#### 1、评估指标:  \n- **Top-1 Accuracy**：衡量模型在分类任务中的正确率，即预测结果中最高概率的类别是否为真实类别。  \n- **Inference Time**：衡量模型在特定硬件（CPU/GPU）上执行单次推理的耗时（中位数），反映计算效率。  \n- **Compression Ratio**：量化模型压缩程度（如剪枝率95%表示保留5%的权重），用于评估压缩技术的激进程度。  \n- **Expected Speedup vs. Achieved Speedup**：对比理论加速比（基于压缩比）与实际加速比，衡量压缩技术的实际优化效果。  \n- **Accuracy Drop**：记录压缩技术（如剪枝、量化）导致的精度损失，用于权衡精度与效率。  \n\n#### 2、选取理由:  \n- **全面性覆盖**：  \n  - **Top-1 Accuracy**和**Accuracy Drop**直接反映模型的核心性能（分类能力）及压缩对性能的影响。  \n  - **Inference Time**是硬件部署的关键指标，尤其针对边缘设...\n\n**总结2** (来源: 3688609):\n### 度量指标总结  \n\n#### 1、评估指标:  \n- **Top-1 Accuracy**：衡量模型在分类任务中的正确率，即预测结果中最高概率的类别是否为真实类别。  \n- **Inference Time**：衡量模型在特定硬件（CPU/GPU）上执行单次推理的耗时（中位数），反映计算效率。  \n- **Compression Ratio**：量化模型压缩程度（如剪枝率95%表示保留5%的权重），用于评估压缩技术的激进程度。  \n- **Expected Speedup vs. Achieved Speedup**：对比理论加速比（基于压缩比）与实际加速比，衡量压缩技术的实际优化效果。  \n- **Accuracy Drop**：记录压缩技术（如剪枝、量化）导致的精度损失，用于权衡精度与效率。  \n\n#### 2、选取理由:  \n- **全面性覆盖**：  \n  - **Top-1 Accuracy**和**Accuracy Drop**直接反映模型的核心性能（分类能力）及压缩对性能的影响。  \n  - **Inference Time**是硬件部署的关键指标，尤其针对边缘设...\n\n**总结3** (来源: 3577193.3593731):\n根据论文内容，以下是度量指标选取策略的总结：\n\n---\n\n### **度量指标总结**\n\n#### 1. **评估指标**  \n**指标1 名称**：Infinity-norm backward error (𝜂∞(𝑥))  \n- **说明其衡量方面**：衡量求解线性系统𝐴𝑥=𝑏的数值稳定性，通过计算残差的无穷范数（∥𝑏−𝐴𝑥∥∞）与系统矩阵和解的范数（∥𝐴∥∞∥𝑥∥∞ + ∥𝑏∥∞）的比值，反映解的相对误差。  \n\n**指标2 名称**：Number of modifications  \n- **说明其衡量方面**：统计算法对矩阵𝐴的修改次数（如通过SVD调整奇异值），反映算法为保持数值稳定性所需的干预程度。  \n\n**指标3 名称**：Iterative refinement steps  \n- **说明其衡量方面**：记录迭代精炼（iterative refinement）的迭代次数（上限为30），用于评估算法收敛到高精度解的效率。  \n\n**指标4 名称**：Condition number (𝜅2(𝐴))  \n- **说明其衡量方面**：通过矩阵的谱条件数（最大与最小奇异值之...\n\n### ResultAnalysis 总结\n**总结1** (来源: 3577193.3593714):\n实验结果分析总结：\n\n1、主要发现:  \n- 与基线模型（如基于重用距离分析的模型、IR2Vec和Baghdadi等人的多面体性能模型）相比，本文提出的性能嵌入模型在所有内存相关性能指标（如内存带宽利用率、数据局部性）上均表现出更低的局部变异度（local variation），表明其相似性搜索更精准。  \n- 在案例研究中，基于嵌入的迁移调优（transfer tuning）在多数应用中将运行时性能优化至参考优化的5%以内，同时将搜索复杂度降低4个数量级（例如，Tiramisu自动调度器的MCTS需测试大量配置，而迁移调优仅需局部搜索）。  \n- 在稀疏矩阵乘法（SpMM）的动态调度任务中，迁移调优在10个测试基准中正确选择了8个最优调度策略，且在某些用例中显著优于Intel MKL库。\n\n2、消融研究结论:  \n- **动态与静态特征的作用**：  \n  - 仅使用动态特征（如性能计数器数据）足以推理内存带宽优化，但静态特征（如数组访问模式、步长）对理解数据局部性和I/O复杂度至关重要。  \n  - 节点嵌入分析显示，静态特征（如访问步长和数组大小）能生成有意义的嵌入，反映实际L2...\n\n**总结2** (来源: 3577193.3593714):\n实验结果分析总结：\n\n1、主要发现:  \n- 与基线模型（如基于重用距离分析的模型、IR2Vec和Baghdadi等人的多面体性能模型）相比，本文提出的性能嵌入模型在所有内存相关性能指标（如内存带宽利用率、数据局部性）上均表现出更低的局部变异度（local variation），表明其相似性搜索更精准。  \n- 在案例研究中，基于嵌入的迁移调优（transfer tuning）在多数应用中将运行时性能优化至参考优化的5%以内，同时将搜索复杂度降低4个数量级（例如，Tiramisu自动调度器的MCTS需测试大量配置，而迁移调优仅需局部搜索）。  \n- 在稀疏矩阵乘法（SpMM）的动态调度任务中，迁移调优在10个测试基准中正确选择了8个最优调度策略，且在某些用例中显著优于Intel MKL库。\n\n2、消融研究结论:  \n- **动态与静态特征的作用**：  \n  - 仅使用动态特征（如性能计数器数据）足以推理内存带宽优化，但静态特征（如数组访问模式、步长）对理解数据局部性和I/O复杂度至关重要。  \n  - 节点嵌入分析显示，静态特征（如访问步长和数组大小）能生成有意义的嵌入，反映实际L2...\n\n**总结3** (来源: Retrospection_on_the_Performance_Analysis_Tools_for_Large-Scale_HPC_Programs):\n实验结果分析总结：\n\n1、主要发现:\n- 数据收集方面：采样工具（如HPCToolkit）在收集所有类型函数事件时（不考虑函数参数）比插桩工具（如TAU-P和Scalasca-P）具有更低的时间开销。但对于MPI通信事件，插桩工具（TAU-T和Scalasca-T）由于能收集丰富的参数信息，更适合且时间开销可忽略。\n- 存储开销方面：插桩工具由于高频事件数据收集导致存储开销更高，与函数调用次数成正比；而采样工具的存储开销与样本数成正比。\n- 可视化分析方面：现有工具（如HPCToolkit和TAU）的跟踪可视化在16进程规模下已难以解读；Scalasca通过提取关键指标（如延迟发送/接收问题）提供更直观的性能问题诊断。\n- 热点分析方面：HPCToolkit的调用栈树形视图最直观，TAU的扁平视图可接受，而Scalasca的热点展示方式不直观且难以识别关键代码区域。\n- 可扩展性分析方面：HPCToolkit通过自定义可扩展性损失度量提供上下文洞察，但难以定位根本原因；TAU通过实测与理想加速比对比展示差距，但缺乏优化指导。\n\n2、消融研究结论:\n- 数据收集方法对比研究表明：计算事件...\n\n\n### 研究趋势分析\n**ExpeDesign 趋势**:\n- 技术趋势: 数据集技术广泛应用, 评价指标技术广泛应用, 实验设置技术广泛应用\n- 研究模式:  在40/5篇论文中被提及(800.0%), n在37/5篇论文中被提及(740.0%), '在34/5篇论文中被提及(680.0%)\n\n**Metric 趋势**:\n- 研究模式:  在58/5篇论文中被提及(1160.0%), '在46/5篇论文中被提及(920.0%), i在37/5篇论文中被提及(740.0%)\n\n\n### 参考原文\n**论文 2309.11930v2 - 实验评价 章节**:\n片段1: 7 Additional Results\nIn addition, we conduct more experiments to validate the robustness of the proposed method. We first conduct a series experiments on CIFAR-100 dataset with different numbers of novel classes, and the results are reported in the Figure To further evaluate the performance when fin...\n片段2: From Table , we can see that both ORCA and NACH show significant declines (over 10% overall accuracy), while our method LPS maintains high performance on CIFAR-100 and shows further improvements on CIFAR-10, which further verifies that LPS is not susceptible to the overfitting dilemma. 4 Experiments...\n\n\n### 写作要求\n1. 基于以上参考资料生成论文的实验评价部分\n2. 保持学术论文的严谨性和专业性\n3. 确保内容逻辑清晰，表达准确\n4. 字数控制在800-1200字之间\n5. 使用规范的学术写作格式\n",
  "context_length": 7574
}