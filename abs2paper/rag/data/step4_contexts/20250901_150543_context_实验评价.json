{
  "section_name": "实验评价",
  "context": "# 生成论文实验评价部分的参考资料\n\n### ExpeDesign 总结\n**总结1** (来源: 2309.11930v2):\n### 实验设计总结：\n\n1. **核心目标**:  \n   - 验证提出的LPS方法在开放集半监督学习（OpenSSL）场景下的鲁棒性和有效性。  \n   - 比较LPS与现有方法（SSL、OpenSSL、NCD等）在已知类和新类识别上的性能差异。  \n   - 分析LPS在微调预训练骨干网络时的抗过拟合能力。\n\n2. **数据集**:  \n   - **CIFAR-10/100**：标准图像分类数据集，分别包含10类和100类。实验中随机选择50%的类作为已知类（其中10%或50%数据有标签），其余为未标记的新类。  \n   - **ImageNet-100**：从ImageNet中抽取的100类子集，用于公平对比现有工作，实验设置与CIFAR类似（50%已知类+50%新类）。  \n\n3. **关键设置**:  \n   - **骨干网络**：CIFAR使用ResNet-18，ImageNet使用ResNet-50；均通过SimCLR预训练并固定前三层块。  \n   - **训练参数**：  \n     - CIFAR：SGD优化器（动量0.9，权重衰减0.0005），200 epo...\n\n**总结2** (来源: 3688609):\n### 实验设计总结：\n\n#### 1. 核心目标:\n- **验证模型压缩技术的有效性**：通过权重剪枝（weight pruning）、通道剪枝（channel pruning）和数据量化（float16/int8）三种方法，评估其对模型精度和推理性能的影响。\n- **比较不同卷积算法的性能**：在CPU和GPU上测试直接卷积（direct）、GEMM和空间打包卷积（spatial pack）三种算法的效率，包括密集（dense）和稀疏（sparse）版本。\n- **评估跨硬件平台的适应性**：分析模型在Intel CPU、Arm CPU（HiKey 970）、Arm GPU（HiKey 970）和Nvidia GPU（Xavier）上的表现差异。\n\n#### 2. 数据集:\n- **CIFAR-10**：小型图像分类数据集，包含10类60,000张32x32图像。实验中训练了ResNet18、MobileNet V1/V2和VGG-16模型。\n- **ImageNet**：大规模图像分类数据集，包含1,000类约120万张图像。实验中使用了预训练的DenseNet161、Effic...\n\n**总结3** (来源: 3676847):\n### 实验设计总结：\n\n1. **核心目标**:\n   - 验证**长行感知分区（LRA）**和**冗余计算优化（RC）**对多GPU稀疏矩阵向量乘法（SpMV）性能的影响。\n   - 比较提出的算法（LRA、LRA+RC）与现有方法（如pCSR-SpMV、非零值分区）的性能差异。\n   - 评估优化后的SpMV算法在共轭梯度法（CG）迭代求解器中的实际应用效果。\n\n2. **数据集**:\n   - **SuiteSparse Matrix Collection**中的24个大规模稀疏矩阵，特点如下：\n     - 所有矩阵的非零元（NNZ）数量均超过2000万。\n     - 矩阵的行数、NNZ总数、每行平均NNZ数（Ave.）、每行最小/最大NNZ数（Min./Max.）差异显著，涵盖规则和不规则数据分布。\n     - 前5个矩阵的每行平均NNZ较少且无长行，其余矩阵分布不规则且含少量长行。\n\n3. **关键设置**:\n   - **硬件平台**：\n     - **P1-2GPU**: 2×GeForce RTX 3090（NVLink互联）。\n     - **P2-2GP...\n\n### Baseline 总结\n**总结1** (来源: 3688609):\n### Baseline选取总结：\n\n1. **对比方法**:\n   - **ResNet18**\n   - **MobileNet V1**\n   - **MobileNet V2**\n   - **VGG-16** (CIFAR-10数据集)\n   - **DenseNet161**\n   - **EfficientNetB0**\n   - **ResNet50** (ImageNet数据集)\n\n2. **选取理由**:\n   - **技术路线覆盖性**: 选择的模型涵盖了不同的神经网络架构设计路线（如残差连接、深度可分离卷积、密集连接等），能够代表主流的图像分类模型技术。\n     - *经典大型模型*: ResNet18/VGG-16（CIFAR-10）和ResNet50/DenseNet161（ImageNet）作为参数较多的基准。\n     - *轻量化模型*: MobileNet V1/V2和EfficientNetB0作为资源高效型设计的代表。\n   - **SOTA与经典结合**: \n     - 包含长期广泛验证的经典架构（如VGG、ResNet）\n     - 也...\n\n**总结2** (来源: 3703352):\nBaseline选取总结：  \n1、对比方法:  \n- cuSPARSE  \n- AC-SpGEMM  \n- spECK  \n- TileSpGEMM  \n\n2、选取理由:  \n论文选择的Baseline涵盖了当前SpGEMM（稀疏矩阵-矩阵乘法）领域的代表性方法，具体依据如下：  \n- **技术路线覆盖性**：所选方法代表了不同的优化技术路径（如cuSPARSE为厂商库标准实现，AC-SpGEMM和spECK关注负载均衡与合并策略，TileSpGEMM采用分块计算）。  \n- **SOTA对比需求**：作者明确指出这些方法是\"state-of-the-art\"（6.3节），旨在验证所提方法相对于当前最优技术的性能优势。例如，spECK和TileSpGEMM在多数矩阵上能稳定达到40 GFlops以上性能。  \n- **实际应用广泛性**：cuSPARSE作为NVIDIA官方库被广泛使用，具有工业界基准意义；其他方法（如AC-SpGEMM）在学术研究中常被引用，覆盖理论优化前沿。  \n- **异构计算相关性**：部分Baseline（如TileSpGEMM）的设计思想与论文的异构协作目...\n\n**总结3** (来源: 2309.11930v2):\n根据论文内容，以下是Baseline选取策略的总结：\n\n---\n\n**Baseline选取总结：**\n\n1. **对比方法:**  \n   - **NCD方法**:  \n     - DTC  \n     - RankStats  \n     - GCD  \n   - **SSL与Open-set SSL方法**:  \n     - FixMatch  \n     - DS³L  \n   - **OpenSSL方法**:  \n     - ORCA  \n     - NACH  \n     - OpenNCD  \n   - **自监督预训练模型**:  \n     - SimCLR（基于K-means聚类）  \n\n2. **选取理由:**  \n   - **技术路线覆盖性**: 作者选择了代表不同技术路线的基线方法，包括：  \n     1. **NCD方法**（DTC、RankStats、GCD）：专注于无标签数据中仅包含新类别的场景，用于对比传统新类发现任务的性能。  \n     2. **SSL与Open-set SSL方法**（FixMatch、DS³L）：体现半监督学习和开放...\n\n### Metric 总结\n**总结1** (来源: 3689341):\n### 度量指标总结  \n\n#### 1. **评估指标**  \n- **BFS Throughput (GTEPS)**：衡量系统在单位时间内处理的图遍历边数（Giga Traversed Edges Per Second），用于评估广度优先搜索（BFS）的计算效率。  \n- **Construction Time**：图分区和存储格式构建的耗时，反映预处理阶段的性能。  \n- **Memory Footprint**：不同稀疏存储格式的内存占用，衡量存储优化效果（如节省内存百分比）。  \n- **Runtime Speedup**：相对于基线方法的运行时间加速比，体现计算阶段的性能提升。  \n- **Scalability (Normalized GTEPS)**：通过增加计算节点时的性能变化（以单节点为基线），评估系统扩展性。  \n- **Preprocessing Overhead**：排序和顶点重索引的预处理时间成本，衡量一次性开销的可接受性。  \n- **Hyperparameter Sensitivity (Thr)**：压缩阈值对性能的影响（如性能差距百分比），验证参数...\n\n**总结2** (来源: 3688609):\n### 度量指标总结  \n\n#### 1、评估指标:  \n- **Top-1 Accuracy**：衡量模型在分类任务中的正确率，即预测结果中最高概率的类别是否为真实类别。  \n- **Inference Time**：衡量模型在特定硬件（CPU/GPU）上执行单次推理的耗时（中位数），反映计算效率。  \n- **Compression Ratio**：量化模型压缩程度（如剪枝率95%表示保留5%的权重），用于评估压缩技术的激进程度。  \n- **Expected Speedup vs. Achieved Speedup**：对比理论加速比（基于压缩比）与实际加速比，衡量压缩技术的实际优化效果。  \n- **Accuracy Drop**：记录压缩技术（如剪枝、量化）导致的精度损失，用于权衡精度与效率。  \n\n#### 2、选取理由:  \n- **全面性覆盖**：  \n  - **Top-1 Accuracy**和**Accuracy Drop**直接反映模型的核心性能（分类能力）及压缩对性能的影响。  \n  - **Inference Time**是硬件部署的关键指标，尤其针对边缘设...\n\n**总结3** (来源: 2309.11930v2):\n### 度量指标总结：\n\n1. **评估指标**:\n   - **Overall Accuracy (整体准确率)**: 衡量模型在所有类别（包括已知类和未知类）上的综合分类性能。\n   - **Seen Class Accuracy (已知类准确率)**: 衡量模型在已知类别上的分类性能，计算方式与标准分类任务相同。\n   - **Novel Class Accuracy (未知类准确率)**: 衡量模型在未知类别上的分类性能，通过匈牙利算法解决最优预测-目标类分配问题后计算。\n   - **Normalized Mutual Information (NMI, 归一化互信息)**: 评估聚类质量，衡量模型对未知类的聚类效果与真实分布的匹配程度。\n   - **KL Divergence (KL散度)**: 分析估计的类别分布与先验分布之间的差异，验证模型对类别分布的估计能力。\n\n2. **选取理由**:\n   - **全面性**：  \n     选择整体准确率、已知类准确率和未知类准确率是为了全面评估模型在开放集半监督学习（OpenSSL）任务中的性能。这三项指标分别覆盖了模型对已...\n\n### ResultAnalysis 总结\n**总结1** (来源: 3577193.3593714):\n实验结果分析总结：\n\n1、主要发现:  \n- 与基线模型（如基于重用距离分析的模型、IR2Vec和Baghdadi等人的多面体性能模型）相比，本文提出的性能嵌入模型在所有内存相关性能指标（如内存带宽利用率、数据局部性）上均表现出更低的局部变异度（local variation），表明其相似性搜索更精准。  \n- 在案例研究中，基于嵌入的迁移调优（transfer tuning）在多数应用中将运行时性能优化至参考优化的5%以内，同时将搜索复杂度降低4个数量级（例如，Tiramisu自动调度器的MCTS需测试大量配置，而迁移调优仅需局部搜索）。  \n- 在稀疏矩阵乘法（SpMM）的动态调度任务中，迁移调优在10个测试基准中正确选择了8个最优调度策略，且在某些用例中显著优于Intel MKL库。\n\n2、消融研究结论:  \n- **动态与静态特征的作用**：  \n  - 仅使用动态特征（如性能计数器数据）足以推理内存带宽优化，但静态特征（如数组访问模式、步长）对理解数据局部性和I/O复杂度至关重要。  \n  - 节点嵌入分析显示，静态特征（如访问步长和数组大小）能生成有意义的嵌入，反映实际L2...\n\n**总结2** (来源: 2309.11930v2):\n实验结果分析总结：\n\n1、主要发现:\n- 在CIFAR-10数据集上，LPS方法在novel class准确率上比NACH提高1.2%；\n- 在CIFAR-100数据集上，LPS方法比baseline方法提高3.2%；\n- 在ImageNet-100数据集上，LPS方法的整体准确率比现有最优方法提高3.8%；\n- 当微调预训练主干网络时，LPS在CIFAR-10和CIFAR-100上的整体准确率分别提升2.9%和6.3%，而其他方法（ORCA和NACH）性能下降超过10%。\n\n2、消融研究结论:\n- 移除自适应边界损失（L_AM）会导致性能下降，改用标准交叉熵后效果变差；\n- 移除伪标签对比聚类损失（L_PC）会显著影响novel class的发现效果；\n- 移除无监督对比学习损失（L_UC）会降低模型性能；\n- 移除熵正则化器（R_Entropy）会导致novel class性能大幅下降，证明其在novel class发现中的关键作用。\n\n3、其他分析洞察:\n- 参数敏感性分析：\n   - η1和η2（损失权重参数）调整显示LPS具有良好鲁棒性；\n   - λ_novel较高时see...\n\n**总结3** (来源: 3688609):\n实验结果分析总结：\n\n1、主要发现:  \n- **CIFAR-10**：  \n  - **权重剪枝（Weight Pruning）**：所有模型在剪枝率95%前均能保持准确率，99%时出现显著下降（MobileNetV1/V2下降更明显）。  \n  - **通道剪枝（Channel Pruning）**：准确率下降更早（MobileNet在50%、VGG-16/ResNet18在80%时出现拐点），且下降幅度更大（最低至10%）。  \n  - **量化**：float16几乎无精度损失；int8未校准时精度显著下降（MobileNetV1/V2降至10.0%/16.4%），校准后恢复至损失1.7%以内。  \n  - **推理性能**：  \n    - **CPU（未调优）**：i7上int8最快（3/4模型），HiKey上权重剪枝最快（3/4模型）；实际加速仅为理论预期的11.5%-21.8%（权重剪枝）和77.9%-83.9%（通道剪枝）。  \n    - **GPU（未调优）**：HiKey GPU比CPU慢7倍；空间打包（spatial pack）在剪枝模型中表现最佳，但加速有限...\n\n\n### 研究趋势分析\n**ExpeDesign 趋势**:\n- 技术趋势: 数据集技术广泛应用\n- 研究模式: 并行计算 (Parallel Computing)在3/5篇论文中被提及(60.0%), 代码生成 (Code Generation)在2/5篇论文中被提及(40.0%), 自动调优 (Autotuning)在2/5篇论文中被提及(40.0%)\n\n**Metric 趋势**:\n- 技术趋势: 准确率技术广泛应用\n- 研究模式: 图论 (Graph Theory)在3/5篇论文中被提及(60.0%), 代码生成 (Code Generation)在3/5篇论文中被提及(60.0%), 自动调优 (Autotuning)在3/5篇论文中被提及(60.0%)\n\n\n### 写作要求\n1. 基于以上参考资料生成论文的实验评价部分\n2. 保持学术论文的严谨性和专业性\n3. 确保内容逻辑清晰，表达准确\n4. 字数控制在800-1200字之间\n5. 使用规范的学术写作格式\n",
  "context_length": 6894
}