{
  "section_name": "实验评价",
  "context": "# 生成论文实验评价部分的参考资料\n\n### ExpeDesign 总结\n**总结1** (来源: 2309.11930v2):\n### 实验设计总结：\n\n1. **核心目标**:  \n   - 验证提出的LPS方法在开放集半监督学习（OpenSSL）场景下的鲁棒性和有效性。  \n   - 比较LPS与现有方法（SSL、OpenSSL、NCD等）在已知类和新类识别上的性能差异。  \n   - 分析LPS在微调预训练骨干网络时的抗过拟合能力。\n\n2. **数据集**:  \n   - **CIFAR-10/100**：标准图像分类数据集，分别包含10类和100类。实验中随机选择50%的类作为已知类（其中10%或50%数据有标签），其余为未标记的新类。  \n   - **ImageNet-100**：从ImageNet中抽取的100类子集，用于公平对比现有工作，实验设置与CIFAR类似（50%已知类+50%新类）。  \n\n3. **关键设置**:  \n   - **骨干网络**：CIFAR使用ResNet-18，ImageNet使用ResNet-50；均通过SimCLR预训练并固定前三层块。  \n   - **训练参数**：  \n     - CIFAR：SGD优化器（动量0.9，权重衰减0.0005），200 epo...\n\n**总结2** (来源: 2309.11930v2):\n### 实验设计总结：\n\n1. **核心目标**:  \n   - 验证提出的LPS方法在开放集半监督学习（OpenSSL）场景下的鲁棒性和有效性。  \n   - 比较LPS与现有方法（SSL、OpenSSL、NCD等）在已知类和新类识别上的性能差异。  \n   - 分析LPS在微调预训练骨干网络时的抗过拟合能力。\n\n2. **数据集**:  \n   - **CIFAR-10/100**：标准图像分类数据集，分别包含10类和100类。实验中随机选择50%的类作为已知类（其中10%或50%数据有标签），其余为未标记的新类。  \n   - **ImageNet-100**：从ImageNet中抽取的100类子集，用于公平对比现有工作，实验设置与CIFAR类似（50%已知类+50%新类）。  \n\n3. **关键设置**:  \n   - **骨干网络**：CIFAR使用ResNet-18，ImageNet使用ResNet-50；均通过SimCLR预训练并固定前三层块。  \n   - **训练参数**：  \n     - CIFAR：SGD优化器（动量0.9，权重衰减0.0005），200 epo...\n\n**总结3** (来源: 3688609):\n### 实验设计总结：\n\n#### 1. 核心目标:\n- **验证模型压缩技术的有效性**：通过权重剪枝（weight pruning）、通道剪枝（channel pruning）和数据量化（float16/int8）三种方法，评估其对模型精度和推理性能的影响。\n- **比较不同卷积算法的性能**：在CPU和GPU上测试直接卷积（direct）、GEMM和空间打包卷积（spatial pack）三种算法的效率，包括密集（dense）和稀疏（sparse）版本。\n- **评估跨硬件平台的适应性**：分析模型在Intel CPU、Arm CPU（HiKey 970）、Arm GPU（HiKey 970）和Nvidia GPU（Xavier）上的表现差异。\n\n#### 2. 数据集:\n- **CIFAR-10**：小型图像分类数据集，包含10类60,000张32x32图像。实验中训练了ResNet18、MobileNet V1/V2和VGG-16模型。\n- **ImageNet**：大规模图像分类数据集，包含1,000类约120万张图像。实验中使用了预训练的DenseNet161、Effic...\n\n### Baseline 总结\n**总结1** (来源: 3688609):\n### Baseline选取总结：\n\n1. **对比方法**:\n   - **ResNet18**\n   - **MobileNet V1**\n   - **MobileNet V2**\n   - **VGG-16** (CIFAR-10数据集)\n   - **DenseNet161**\n   - **EfficientNetB0**\n   - **ResNet50** (ImageNet数据集)\n\n2. **选取理由**:\n   - **技术路线覆盖性**: 选择的模型涵盖了不同的神经网络架构设计路线（如残差连接、深度可分离卷积、密集连接等），能够代表主流的图像分类模型技术。\n     - *经典大型模型*: ResNet18/VGG-16（CIFAR-10）和ResNet50/DenseNet161（ImageNet）作为参数较多的基准。\n     - *轻量化模型*: MobileNet V1/V2和EfficientNetB0作为资源高效型设计的代表。\n   - **SOTA与经典结合**: \n     - 包含长期广泛验证的经典架构（如VGG、ResNet）\n     - 也...\n\n**总结2** (来源: 3688609):\n### Baseline选取总结：\n\n1. **对比方法**:\n   - **ResNet18**\n   - **MobileNet V1**\n   - **MobileNet V2**\n   - **VGG-16** (CIFAR-10数据集)\n   - **DenseNet161**\n   - **EfficientNetB0**\n   - **ResNet50** (ImageNet数据集)\n\n2. **选取理由**:\n   - **技术路线覆盖性**: 选择的模型涵盖了不同的神经网络架构设计路线（如残差连接、深度可分离卷积、密集连接等），能够代表主流的图像分类模型技术。\n     - *经典大型模型*: ResNet18/VGG-16（CIFAR-10）和ResNet50/DenseNet161（ImageNet）作为参数较多的基准。\n     - *轻量化模型*: MobileNet V1/V2和EfficientNetB0作为资源高效型设计的代表。\n   - **SOTA与经典结合**: \n     - 包含长期广泛验证的经典架构（如VGG、ResNet）\n     - 也...\n\n**总结3** (来源: 3703352):\nBaseline选取总结：  \n1、对比方法:  \n- cuSPARSE  \n- AC-SpGEMM  \n- spECK  \n- TileSpGEMM  \n\n2、选取理由:  \n论文选择的Baseline涵盖了当前SpGEMM（稀疏矩阵-矩阵乘法）领域的代表性方法，具体依据如下：  \n- **技术路线覆盖性**：所选方法代表了不同的优化技术路径（如cuSPARSE为厂商库标准实现，AC-SpGEMM和spECK关注负载均衡与合并策略，TileSpGEMM采用分块计算）。  \n- **SOTA对比需求**：作者明确指出这些方法是\"state-of-the-art\"（6.3节），旨在验证所提方法相对于当前最优技术的性能优势。例如，spECK和TileSpGEMM在多数矩阵上能稳定达到40 GFlops以上性能。  \n- **实际应用广泛性**：cuSPARSE作为NVIDIA官方库被广泛使用，具有工业界基准意义；其他方法（如AC-SpGEMM）在学术研究中常被引用，覆盖理论优化前沿。  \n- **异构计算相关性**：部分Baseline（如TileSpGEMM）的设计思想与论文的异构协作目...\n\n### Metric 总结\n**总结1** (来源: 3689341):\n### 度量指标总结  \n\n#### 1. **评估指标**  \n- **BFS Throughput (GTEPS)**：衡量系统在单位时间内处理的图遍历边数（Giga Traversed Edges Per Second），用于评估广度优先搜索（BFS）的计算效率。  \n- **Construction Time**：图分区和存储格式构建的耗时，反映预处理阶段的性能。  \n- **Memory Footprint**：不同稀疏存储格式的内存占用，衡量存储优化效果（如节省内存百分比）。  \n- **Runtime Speedup**：相对于基线方法的运行时间加速比，体现计算阶段的性能提升。  \n- **Scalability (Normalized GTEPS)**：通过增加计算节点时的性能变化（以单节点为基线），评估系统扩展性。  \n- **Preprocessing Overhead**：排序和顶点重索引的预处理时间成本，衡量一次性开销的可接受性。  \n- **Hyperparameter Sensitivity (Thr)**：压缩阈值对性能的影响（如性能差距百分比），验证参数...\n\n**总结2** (来源: 3689341):\n### 度量指标总结  \n\n#### 1. **评估指标**  \n- **BFS Throughput (GTEPS)**：衡量系统在单位时间内处理的图遍历边数（Giga Traversed Edges Per Second），用于评估广度优先搜索（BFS）的计算效率。  \n- **Construction Time**：图分区和存储格式构建的耗时，反映预处理阶段的性能。  \n- **Memory Footprint**：不同稀疏存储格式的内存占用，衡量存储优化效果（如节省内存百分比）。  \n- **Runtime Speedup**：相对于基线方法的运行时间加速比，体现计算阶段的性能提升。  \n- **Scalability (Normalized GTEPS)**：通过增加计算节点时的性能变化（以单节点为基线），评估系统扩展性。  \n- **Preprocessing Overhead**：排序和顶点重索引的预处理时间成本，衡量一次性开销的可接受性。  \n- **Hyperparameter Sensitivity (Thr)**：压缩阈值对性能的影响（如性能差距百分比），验证参数...\n\n**总结3** (来源: 3688609):\n### 度量指标总结  \n\n#### 1、评估指标:  \n- **Top-1 Accuracy**：衡量模型在分类任务中的正确率，即预测结果中最高概率的类别是否为真实类别。  \n- **Inference Time**：衡量模型在特定硬件（CPU/GPU）上执行单次推理的耗时（中位数），反映计算效率。  \n- **Compression Ratio**：量化模型压缩程度（如剪枝率95%表示保留5%的权重），用于评估压缩技术的激进程度。  \n- **Expected Speedup vs. Achieved Speedup**：对比理论加速比（基于压缩比）与实际加速比，衡量压缩技术的实际优化效果。  \n- **Accuracy Drop**：记录压缩技术（如剪枝、量化）导致的精度损失，用于权衡精度与效率。  \n\n#### 2、选取理由:  \n- **全面性覆盖**：  \n  - **Top-1 Accuracy**和**Accuracy Drop**直接反映模型的核心性能（分类能力）及压缩对性能的影响。  \n  - **Inference Time**是硬件部署的关键指标，尤其针对边缘设...\n\n### ResultAnalysis 总结\n**总结1** (来源: 3577193.3593714):\n实验结果分析总结：\n\n1、主要发现:  \n- 与基线模型（如基于重用距离分析的模型、IR2Vec和Baghdadi等人的多面体性能模型）相比，本文提出的性能嵌入模型在所有内存相关性能指标（如内存带宽利用率、数据局部性）上均表现出更低的局部变异度（local variation），表明其相似性搜索更精准。  \n- 在案例研究中，基于嵌入的迁移调优（transfer tuning）在多数应用中将运行时性能优化至参考优化的5%以内，同时将搜索复杂度降低4个数量级（例如，Tiramisu自动调度器的MCTS需测试大量配置，而迁移调优仅需局部搜索）。  \n- 在稀疏矩阵乘法（SpMM）的动态调度任务中，迁移调优在10个测试基准中正确选择了8个最优调度策略，且在某些用例中显著优于Intel MKL库。\n\n2、消融研究结论:  \n- **动态与静态特征的作用**：  \n  - 仅使用动态特征（如性能计数器数据）足以推理内存带宽优化，但静态特征（如数组访问模式、步长）对理解数据局部性和I/O复杂度至关重要。  \n  - 节点嵌入分析显示，静态特征（如访问步长和数组大小）能生成有意义的嵌入，反映实际L2...\n\n**总结2** (来源: 3577193.3593714):\n实验结果分析总结：\n\n1、主要发现:  \n- 与基线模型（如基于重用距离分析的模型、IR2Vec和Baghdadi等人的多面体性能模型）相比，本文提出的性能嵌入模型在所有内存相关性能指标（如内存带宽利用率、数据局部性）上均表现出更低的局部变异度（local variation），表明其相似性搜索更精准。  \n- 在案例研究中，基于嵌入的迁移调优（transfer tuning）在多数应用中将运行时性能优化至参考优化的5%以内，同时将搜索复杂度降低4个数量级（例如，Tiramisu自动调度器的MCTS需测试大量配置，而迁移调优仅需局部搜索）。  \n- 在稀疏矩阵乘法（SpMM）的动态调度任务中，迁移调优在10个测试基准中正确选择了8个最优调度策略，且在某些用例中显著优于Intel MKL库。\n\n2、消融研究结论:  \n- **动态与静态特征的作用**：  \n  - 仅使用动态特征（如性能计数器数据）足以推理内存带宽优化，但静态特征（如数组访问模式、步长）对理解数据局部性和I/O复杂度至关重要。  \n  - 节点嵌入分析显示，静态特征（如访问步长和数组大小）能生成有意义的嵌入，反映实际L2...\n\n**总结3** (来源: 2309.11930v2):\n实验结果分析总结：\n\n1、主要发现:\n- 在CIFAR-10数据集上，LPS方法在novel class准确率上比NACH提高1.2%；\n- 在CIFAR-100数据集上，LPS方法比baseline方法提高3.2%；\n- 在ImageNet-100数据集上，LPS方法的整体准确率比现有最优方法提高3.8%；\n- 当微调预训练主干网络时，LPS在CIFAR-10和CIFAR-100上的整体准确率分别提升2.9%和6.3%，而其他方法（ORCA和NACH）性能下降超过10%。\n\n2、消融研究结论:\n- 移除自适应边界损失（L_AM）会导致性能下降，改用标准交叉熵后效果变差；\n- 移除伪标签对比聚类损失（L_PC）会显著影响novel class的发现效果；\n- 移除无监督对比学习损失（L_UC）会降低模型性能；\n- 移除熵正则化器（R_Entropy）会导致novel class性能大幅下降，证明其在novel class发现中的关键作用。\n\n3、其他分析洞察:\n- 参数敏感性分析：\n   - η1和η2（损失权重参数）调整显示LPS具有良好鲁棒性；\n   - λ_novel较高时see...\n\n\n### 研究趋势分析\n**ExpeDesign 趋势**:\n- 技术趋势: 数据集技术广泛应用, 评价指标技术广泛应用, 实验设置技术广泛应用\n- 研究模式:  在42/5篇论文中被提及(840.0%), n在35/5篇论文中被提及(700.0%), '在34/5篇论文中被提及(680.0%)\n\n**Metric 趋势**:\n- 技术趋势: 准确率技术广泛应用\n- 研究模式:  在39/5篇论文中被提及(780.0%), '在32/5篇论文中被提及(640.0%), n在29/5篇论文中被提及(580.0%)\n\n\n### 参考原文\n**论文 2309.11930v2 - 实验评价 章节**:\n片段1: 7 Additional Results\nIn addition, we conduct more experiments to validate the robustness of the proposed method. We first conduct a series experiments on CIFAR-100 dataset with different numbers of novel classes, and the results are reported in the Figure To further evaluate the performance when fin...\n片段2: From Table , we can see that both ORCA and NACH show significant declines (over 10% overall accuracy), while our method LPS maintains high performance on CIFAR-100 and shows further improvements on CIFAR-10, which further verifies that LPS is not susceptible to the overfitting dilemma. 4 Experiments...\n\n\n### 写作要求\n1. 基于以上参考资料生成论文的实验评价部分\n2. 保持学术论文的严谨性和专业性\n3. 确保内容逻辑清晰，表达准确\n4. 字数控制在800-1200字之间\n5. 使用规范的学术写作格式\n",
  "context_length": 7479
}