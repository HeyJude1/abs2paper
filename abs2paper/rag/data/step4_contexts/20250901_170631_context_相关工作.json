{
  "section_name": "相关工作",
  "context": "# 生成论文相关工作部分的参考资料\n\n### RelatedWork 总结\n**总结1** (来源: 3656019.3676895):\n相关工作总结：\n\n1、现有方法一：基于词法标记的代码表示方法\n核心思想: 早期研究主要依赖源代码的词法标记（lexical tokens）进行代码表示，通过解析代码的文本特征来支持优化决策。\n主要局限性: 无法有效捕捉代码的语义信息，导致对程序行为的理解存在本质性缺陷。\n\n2、现有方法二：基于LLVM IR的表示学习方法\n核心思想: 新一代方法利用LLVM中间表示（IR）提取代码语义特征，为深度学习模型提供结构化程序信息。\n主要局限性: 需要为每个独立任务设计复杂的图神经网络（GNN）建模，缺乏可迁移的通用表示能力。\n\n3、现有方法三：非神经网络的机器学习方法\n核心思想: 采用传统机器学习（如贝叶斯优化）进行参数自动调优，典型应用包括OpenMP调优和在线调优任务。\n主要局限性: \n- 严重依赖领域特定知识，泛化能力差\n- 需要多次执行目标代码来评估参数性能\n- 计算开销仍然显著\n\n4、现有方法四：基于搜索的自动调优技术\n核心思想: 使用爬山算法、随机搜索、Nelder-Mead等搜索空间优化技术替代暴力搜索，代表工作包括ActiveHarmony和OpenTuner。\n主要局限性:\n...\n\n**总结2** (来源: 3656019.3676895):\n相关工作总结：\n\n1、现有方法一：基于词法标记的代码表示方法\n核心思想: 早期研究主要依赖源代码的词法标记（lexical tokens）进行代码表示，通过解析代码的文本特征来支持优化决策。\n主要局限性: 无法有效捕捉代码的语义信息，导致对程序行为的理解存在本质性缺陷。\n\n2、现有方法二：基于LLVM IR的表示学习方法\n核心思想: 新一代方法利用LLVM中间表示（IR）提取代码语义特征，为深度学习模型提供结构化程序信息。\n主要局限性: 需要为每个独立任务设计复杂的图神经网络（GNN）建模，缺乏可迁移的通用表示能力。\n\n3、现有方法三：非神经网络的机器学习方法\n核心思想: 采用传统机器学习（如贝叶斯优化）进行参数自动调优，典型应用包括OpenMP调优和在线调优任务。\n主要局限性: \n- 严重依赖领域特定知识，泛化能力差\n- 需要多次执行目标代码来评估参数性能\n- 计算开销仍然显著\n\n4、现有方法四：基于搜索的自动调优技术\n核心思想: 使用爬山算法、随机搜索、Nelder-Mead等搜索空间优化技术替代暴力搜索，代表工作包括ActiveHarmony和OpenTuner。\n主要局限性:\n...\n\n**总结3** (来源: 2309.11930v2):\n相关工作总结：\n\n1、现有方法一：半监督学习（Semi-Supervised Learning, SSL）\n核心思想: \n- 伪标签技术（Pseudo-labeling）：将模型对无标签样本的预测转换为软标签或硬标签，作为目标标签使用。\n- 一致性正则化（Consistency Regularization）：确保模型在扰动样本上的输出保持高度一致。\n- 对比学习应用：如TCL通过最大化同一样本不同视图间的一致性，同时最小化不同样本间的一致性，以增强表示学习。\n\n主要局限性: \n- 现有方法通常假设有标签和无标签数据来自相同的类别分布，而现实场景中无标签数据可能包含新类别（即分布不匹配问题）。\n- 传统SSL方法未充分考虑新类别样本的聚类需求。\n\n2、现有方法二：新类别发现（Novel Class Discovery, NCD）\n核心思想: \n- 采用多阶段训练策略：先从有标签数据中捕获高层语义信息，再迁移到无标签数据（假设无标签数据仅含新类别）。\n- 通过目标函数最小化类内样本距离。\n\n主要局限性: \n- 强假设无标签数据仅包含新类别，而实际场景中无标签数据往往同时包含已知类别和新类...\n\n### Challenges 总结\n**总结1** (来源: 3701997):\n核心挑战总结：\n\n挑战一：边缘设备内存约束下的模型分布式执行优化  \n分析:  \n1. 问题本质：边缘设备（如智能摄像头、门锁等）内存容量有限，而分布式推理涉及中间张量存储、算子参数复制等内存开销源  \n2.技术瓶颈：  \n- 模型DAG结构中算子执行顺序影响中间张量生命周期，导致内存开销动态变化（PC完全问题，搜索空间随算子数量指数增长）  \n- 现有方法（如HMCOS）仅针对单GPU优化，缺乏分布式场景下的内存约束考量  \n3.数据特征：卷积算子等大参数量操作加剧内存压力（如特征图高度/输出通道维度的分区会产生不同内存占用模式）\n\n挑战二：多维度模型划分的延迟最小化问题  \n分析:  \n1. 复杂性根源：  \n- 混合划分策略需同时考虑水平/垂直划分及算子间依赖关系  \n- 分区决策涉及维度选择（如cout/fmh）、分区数量、比例等多变量耦合  \n2. 现有技术缺陷：  \n- 粗粒度近似方法（如线性规划转化）引入误差  \n- 单算子独立优化无法保证全局最优（相邻算子分区存在级联影响）  \n3. 性能权衡：并行计算降低时延但可能增加数据同步开销（如卷积核分区导致输入张量重复存储）\n...\n\n**总结2** (来源: 3701997):\n核心挑战总结：\n\n挑战一：边缘设备内存约束下的模型分布式执行优化  \n分析:  \n1. 问题本质：边缘设备（如智能摄像头、门锁等）内存容量有限，而分布式推理涉及中间张量存储、算子参数复制等内存开销源  \n2.技术瓶颈：  \n- 模型DAG结构中算子执行顺序影响中间张量生命周期，导致内存开销动态变化（PC完全问题，搜索空间随算子数量指数增长）  \n- 现有方法（如HMCOS）仅针对单GPU优化，缺乏分布式场景下的内存约束考量  \n3.数据特征：卷积算子等大参数量操作加剧内存压力（如特征图高度/输出通道维度的分区会产生不同内存占用模式）\n\n挑战二：多维度模型划分的延迟最小化问题  \n分析:  \n1. 复杂性根源：  \n- 混合划分策略需同时考虑水平/垂直划分及算子间依赖关系  \n- 分区决策涉及维度选择（如cout/fmh）、分区数量、比例等多变量耦合  \n2. 现有技术缺陷：  \n- 粗粒度近似方法（如线性规划转化）引入误差  \n- 单算子独立优化无法保证全局最优（相邻算子分区存在级联影响）  \n3. 性能权衡：并行计算降低时延但可能增加数据同步开销（如卷积核分区导致输入张量重复存储）\n...\n\n**总结3** (来源: 2309.17288v3):\n核心挑战总结：\n\n挑战一：多领域异构信息整合的复杂性  \n分析: 论文指出在创造性产业等实际场景中，需要综合来自不同领域的异构信息（如小说创作需整合情节规划、角色开发等多专业知识）。这一挑战源于问题本身的复杂性——不同领域知识体系存在语义鸿沟，且传统LLM缺乏跨域知识协同机制。现有技术瓶颈表现为静态多智能体框架（如MetaGPT）依赖预定义角色，难以动态适应跨域任务的知识重组需求。\n\n挑战二：动态智能体协作的可扩展性限制  \n分析: 现有多智能体系统（如BabyAGI、Camel）面临两大根源性问题：(1) 需人工指定固定角色和通信顺序，导致系统灵活性不足；(2) 缺乏自主生成与优化能力，如Camel不支持工具调用。这些限制源于现有技术对\"预设架构\"的依赖，使得系统无法根据任务复杂度自动调整团队结构（如自动增删专家角色），从而制约了在软件开发等长周期任务中的适应性。\n\n挑战三：自我优化与协作可靠性的平衡  \n分析: 作者发现当前自动生成智能体方法（如SSP、AgentVerse）存在可靠性缺陷：生成的执行计划缺乏验证机制，且智能体间协作易出现信息不一致。这一挑战兼具技术和数据特性：(1...\n\n### Baseline 总结\n**总结1** (来源: 3577193.3593714):\nBaseline选取总结：\n\n1、对比方法:\n- Reuse Distance Analysis (重用距离分析)\n- IR2Vec\n- Baghdadi et al.'s Polyhedral Performance Model (Baghdadi等人的多面体性能模型)\n\n2、选取理由: \n作者选择这些Baseline主要基于以下三个维度：\n(1) 技术路线代表性：覆盖传统分析（重用距离分析）、中间表示学习（IR2Vec）和现代多面体优化（Baghdadi模型）三种典型技术路径；\n(2) 先进性考量：Baghdadi模型是当前多面体程序优化的SOTA方法，IR2Vec是基于LLVM IR的最新嵌入方法；\n(3) 对比完整性：重用距离分析作为经典缓存行为模拟方法，提供传统性能分析的基准参照。三者共同构成从传统到现代、从模拟到学习的完整技术谱系对比。\n\n特别值得注意的是，作者对每个Baseline都进行了适应性改造以确保可比性：对重用距离分析限制模拟迭代次数（500次），对Baghdadi模型移除最后的线性预测层，这种处理体现了对比实验的严谨性。\n\n**总结2** (来源: 3577193.3593714):\nBaseline选取总结：\n\n1、对比方法:\n- Reuse Distance Analysis (重用距离分析)\n- IR2Vec\n- Baghdadi et al.'s Polyhedral Performance Model (Baghdadi等人的多面体性能模型)\n\n2、选取理由: \n作者选择这些Baseline主要基于以下三个维度：\n(1) 技术路线代表性：覆盖传统分析（重用距离分析）、中间表示学习（IR2Vec）和现代多面体优化（Baghdadi模型）三种典型技术路径；\n(2) 先进性考量：Baghdadi模型是当前多面体程序优化的SOTA方法，IR2Vec是基于LLVM IR的最新嵌入方法；\n(3) 对比完整性：重用距离分析作为经典缓存行为模拟方法，提供传统性能分析的基准参照。三者共同构成从传统到现代、从模拟到学习的完整技术谱系对比。\n\n特别值得注意的是，作者对每个Baseline都进行了适应性改造以确保可比性：对重用距离分析限制模拟迭代次数（500次），对Baghdadi模型移除最后的线性预测层，这种处理体现了对比实验的严谨性。\n\n**总结3** (来源: HPC_Application_Parameter_Autotuning_on_Edge_Devices_A_Bandit_Learning_Approach):\n### Baseline选取总结：\n\n1. **对比方法**:  \n   - BLISS（Bayesian Learning-based Iterative Software System）\n\n2. **选取理由**:  \n   - **SOTA代表性**：BLISS是当前最先进的（SOTA）基于机器学习的优化方法，采用贝叶斯优化（BO）来减少调优开销，并通过构建多样化的简化模型池加速收敛。选择它能够直接对比LASP与前沿方法的性能差异。  \n   - **技术路线对比**：BLISS依赖复杂的代理模型预测和计算密集型优化，而LASP专注于轻量级设计（适合资源受限的边缘设备）。这种对比凸显了两种技术路线的优劣（如BLISS的精度优势 vs. LASP的资源效率）。  \n   - **实验验证需求**：作者通过分析BLISS与LASP在CPU/内存占用上的差异（在MAXN和5W两种功耗模式下），证明LASP更适合边缘场景的动态性需求，从而强化了论文的贡献——轻量化自适应调优的实用性。  \n\n**补充说明**：  \n论文虽未明确列出其他经典基线（如随机搜索、遗传算法等），但通过强调与BLI...\n\n\n### 研究趋势分析\n**Challenges 趋势**:\n- 研究模式:  在39/5篇论文中被提及(780.0%), '在32/5篇论文中被提及(640.0%), n在31/5篇论文中被提及(620.0%)\n\n\n### 写作要求\n1. 基于以上参考资料生成论文的相关工作部分\n2. 保持学术论文的严谨性和专业性\n3. 确保内容逻辑清晰，表达准确\n4. 字数控制在800-1200字之间\n5. 使用规范的学术写作格式\n",
  "context_length": 5101
}