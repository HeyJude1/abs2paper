{
  "title": "基于RAG的论文生成",
  "user_requirement": "测试完整的统计信息功能",
  "sections": {
    "引言": "半监督学习（Semi-supervised Learning, SSL）作为机器学习领域的重要研究方向，旨在通过有效利用大量未标注数据和少量标注数据来提升模型性能。随着深度学习在计算机视觉、自然语言处理等领域的广泛应用，SSL因其能够显著降低数据标注成本而受到持续关注。现有研究表明，伪标签技术（Pseudo-labeling）作为SSL的核心方法之一，其性能高度依赖于阈值策略的设计。然而，当前主流的伪标签方法在未标注数据利用率和学习状态估计准确性方面仍存在显著局限，这直接制约了SSL模型在真实场景中的应用效果。\n\n当前SSL研究面临的核心挑战在于如何平衡伪标签质量与数量之间的关系。FixMatch等经典方法采用高固定阈值策略（如0.95）以确保伪标签质量，但实验数据显示超过50%的低置信度样本被错误丢弃，其中实际正确的伪标签占比可观。动态阈值方法（如FlexMatch、FreeMatch）虽能部分缓解这一问题，但其学习状态估计易受数据采样偏差和类间相似性干扰，导致模型在类别不平衡或特征重叠场景下表现欠佳。更关键的是，现有方法普遍忽视低置信度伪标签中蕴含的语义信息价值，造成宝贵数据资源的浪费。\n\n针对上述问题，本研究提出AllMatch框架的创新性解决方案：通过类特定自适应阈值机制（Class-specific Adaptive Threshold, CAT）和二元分类一致性约束（Binary Classification Consistency, BCC），实现对所有未标记数据的充分利用。本文的主要贡献包括：\n1. 提出首个同时整合全局学习状态和类别特异性评估的动态阈值机制CAT；\n2. 设计BCC正则化策略实现100%未标记数据利用率；\n3. 在CIFAR-10/100、SVHN等基准测试中验证方法的优越性。\n\n论文后续结构安排如下：第二节系统回顾相关研究工作；第三节详细阐述AllMatch的方法设计；第四节介绍实验设置与结果分析；第五节讨论方法的局限性与未来方向；第六节总结全文贡献。",
    "相关工作": "半监督学习领域的研究工作主要围绕伪标签技术和一致性正则化两大核心方法展开。本部分将从方法分类、技术演进和研究缺口三个维度系统梳理现有工作。\n\n在伪标签技术方面，现有方法可分为静态阈值和动态阈值两大类。FixMatch作为静态阈值的代表性工作，通过固定高置信度阈值筛选伪标签。为解决其样本利用率低的问题，FlexMatch引入课程学习思想提出类特定动态阈值，而FreeMatch则利用未标记数据的平均置信度作为全局阈值参考。这些方法普遍存在两个局限：一是缺乏对类别间学习差异的细粒度建模；二是未能有效利用被过滤样本的潜在信息。\n\n一致性正则化方法主要关注模型对输入扰动的鲁棒性。从早期Π-model到FixMatch的强弱增强组合策略，再到CoMatch等对比学习方法的发展，该方向逐步完善了特征空间约束机制。然而这类方法仍存在语义级监督信号利用不足的问题。\n\n近期研究开始尝试整合多种技术优势。FullMatch通过比较强弱增强预测识别负类，而本文提出的AllMatch进一步引入类特定自适应阈值和二元分类一致性约束，实现了更全面的学习状态评估。\n\n现有工作存在三个关键研究缺口：\n1. 动态阈值方法多依赖单指标评估学习状态；\n2. 低置信度样本处理方式粗放；\n3. 缺乏对开放世界场景的系统支持。\n本文提出的AllMatch框架针对这些问题进行了系统性创新。",
    "方法": "3.1 框架概述\nAllMatch框架包含两个核心创新：类特定自适应阈值（CAT）和二元分类一致性约束（BCC）。该框架采用双层次自适应机制，同时考虑全局模型置信度和类特定学习状态。\n\n3.2 问题定义\n给定标注数据集D_l和非标注数据集D_u（|D_u|≫|D_l|），SSL的目标是学习具有良好泛化能力的分类器f_θ。我们重点解决三个关键问题：\n1. 考虑类别差异的动态阈值调整；\n2. 低置信度样本的有效利用；\n3. 增强视图间的一致性保持。\n\n3.3 CAT机制\n类特定自适应阈值的计算公式为：\nτ_c^t = σ(||W_c^t||_2) · μ_t · τ_base\n其中σ(·)为sigmoid归一化函数，μ_t表示全局置信度估计。\n\n3.4 BCC策略\n对于样本x_j的预测分布p_j：\n1. 识别候选集C_j = {c | rank(p_j(c)) ≤ k(t)}\n2. 构建负集N_j = {c | c ∉ C_j}\n3. 计算一致性损失：\nL_b = D_KL(p_j^{A_s}(C_j) || p_j^{A_w}(C_j)) + λ·D_JS(p_j^{A"
  },
  "statistics": {
    "total_sections": 3,
    "total_words": 1841,
    "section_word_counts": {
      "引言": 838,
      "相关工作": 565,
      "方法": 438
    },
    "sections_generated": [
      "引言",
      "相关工作",
      "方法"
    ],
    "retrieved_papers_count": 10,
    "retrieved_papers": [
      "DNA-TEQ_An_Adaptive_Exponential_Quantization_of_Tensors_for_DNN_Inference",
      "3674734",
      "3656019.3676889",
      "3701993",
      "Retrospection_on_the_Performance_Analysis_Tools_for_Large-Scale_HPC_Programs",
      "0728",
      "2406.15763v2",
      "2309.11930v2",
      "Simulation_of_Large-Scale_HPC_Storage_Systems_Challenges_and_Methodologies",
      "Automatic_Code_Generation_for_High-Performance_Graph_Algorithms"
    ],
    "source_references": [
      {
        "paper_id": "Retrospection_on_the_Performance_Analysis_Tools_for_Large-Scale_HPC_Programs",
        "sections_used": [
          "方法"
        ],
        "purpose": "方法和实验参考"
      },
      {
        "paper_id": "Automatic_Code_Generation_for_High-Performance_Graph_Algorithms",
        "sections_used": [
          "实验评价"
        ],
        "purpose": "方法和实验参考"
      }
    ]
  },
  "generation_timestamp": "20250902_172703"
}