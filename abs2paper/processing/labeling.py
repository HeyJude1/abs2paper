"""
è®ºæ–‡æ ‡ç­¾å¤„ç†æ¨¡å—ï¼Œè´Ÿè´£åˆ†æè®ºæ–‡æ‘˜è¦å¹¶æ ‡è®°ä¸»é¢˜
"""

import os
import json
import re
import logging
import argparse
from typing import Dict, Any, List, Optional, Tuple, Union
import sys

# å¯¼å…¥LLMå®¢æˆ·ç«¯
from abs2paper.utils.llm_client import LLMClient
from abs2paper.utils.topic_manager import TopicManager

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class PaperLabeler:
    """è®ºæ–‡æ ‡ç­¾ç”Ÿæˆå™¨ï¼Œè´Ÿè´£åˆ†æè®ºæ–‡å¹¶ç”Ÿæˆä¸»é¢˜æ ‡ç­¾"""
    
    def __init__(self, topic_manager: Optional[TopicManager] = None):
        """
        åˆå§‹åŒ–è®ºæ–‡æ ‡ç­¾ç”Ÿæˆå™¨
        
        Args:
            topic_manager: å¯é€‰çš„ä¸»é¢˜ç®¡ç†å™¨å®ä¾‹
        """
        # ç¡®å®šé¡¹ç›®æ ¹ç›®å½•
        module_dir = os.path.dirname(os.path.abspath(__file__))
        self.project_root = os.path.dirname(os.path.dirname(module_dir))
        
        # åŠ è½½é…ç½®æ–‡ä»¶
        config_path = os.path.join(self.project_root, "config", "config.json")
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
            logger.info(f"å·²åŠ è½½é…ç½®: {config_path}")
        
        # åˆ›å»ºLLMå®¢æˆ·ç«¯
        self.llm_client = LLMClient()
        
        # åŠ è½½æç¤ºè¯æ¨¡æ¿
        self.prompt_template = self._load_prompt_template()
        
        # è·å–è·¯å¾„é…ç½®
        data_paths = self.config["data_paths"]
        abstract_extract_path = data_paths["abstract_extract"]["path"].lstrip('/')
        label_path = data_paths["label"]["path"].lstrip('/')
        
        # å›ºå®šçš„è¾“å…¥è¾“å‡ºè·¯å¾„
        self.input_dir = os.path.join(self.project_root, abstract_extract_path)
        self.output_dir = os.path.join(self.project_root, label_path)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.input_dir, exist_ok=True)
        os.makedirs(self.output_dir, exist_ok=True)
        
        logger.info(f"è¾“å…¥ç›®å½•: {self.input_dir}")
        logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        
        # åˆå§‹åŒ–æˆ–ä½¿ç”¨ä¼ å…¥çš„ä¸»é¢˜ç®¡ç†å™¨
        self.topic_manager = topic_manager or TopicManager()
    
    def _load_prompt_template(self) -> str:
        """
        åŠ è½½æç¤ºè¯æ¨¡æ¿
            
        Returns:
            æç¤ºè¯æ¨¡æ¿æ–‡æœ¬
            
        Raises:
            FileNotFoundError: å¦‚æœæç¤ºè¯æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨
        """
        # ä»é…ç½®ä¸­è¯»å–æç¤ºè¯æ¨¡æ¿è·¯å¾„
        prompt_kb_path = self.config["data_paths"]["prompt_kb"]["path"].lstrip('/')
        prompt_path = os.path.join(self.project_root, prompt_kb_path)
        
        with open(prompt_path, 'r', encoding='utf-8') as f:
            template = f.read().strip()
            logger.info(f"âœ… å·²åŠ è½½æç¤ºè¯æ¨¡æ¿: {prompt_path}")
            return template
    
    def extract_keywords_array(self, response: str) -> str:
        """
        ä»æ¨¡å‹å›å¤ä¸­æå–å…³é”®è¯æ•°ç»„ï¼Œå‚è€ƒlabel_paper_ori.pyçš„å®ç°
        
        Args:
            response: æ¨¡å‹å›å¤æ–‡æœ¬
            
        Returns:
            æå–çš„å…³é”®è¯æ•°ç»„æ–‡æœ¬
        """
        # ä½¿ç”¨æ›´çµæ´»çš„æ­£åˆ™è¡¨è¾¾å¼ï¼ŒåŒ¹é…å¤šç§å¯èƒ½çš„æ¨¡å¼
        # 1. å°è¯•åŒ¹é…"(æ•…)è¯¥è®ºæ–‡çš„ä¸»é¢˜å…³é”®è¯æ€»ç»“ä¸º[...]"çš„æ¨¡å¼
        match = re.search(r"(?:æ•…)?è¯¥è®ºæ–‡çš„ä¸»é¢˜å…³é”®è¯æ€»ç»“ä¸º\[(.*?)\]", response)
        if match:
            return match.group(1).strip()
            
        # 2. å°è¯•åŒ¹é…ä»»ä½•åŒ…å«"å…³é”®è¯æ€»ç»“ä¸º[...]"çš„æ¨¡å¼
        match = re.search(r"å…³é”®è¯æ€»ç»“ä¸º\[(.*?)\]", response)
        if match:
            return match.group(1).strip()
            
        # 3. å°è¯•ç›´æ¥åŒ¹é…ä»»ä½•æ–¹æ‹¬å·å†…å®¹ [...] ä½œä¸ºå¤‡ç”¨
        match = re.search(r"\[(.*?)\]", response)
        if match:
            return match.group(1).strip()
            
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œç›´æ¥è¿”å›åŸæ–‡æœ¬
        return response.strip()
    
    def update_prompt_with_topics(self, prompt: str) -> str:
        """
        ä½¿ç”¨æœ€æ–°çš„ä¸»é¢˜åˆ—è¡¨æ›´æ–°æç¤ºè¯æ¨¡æ¿
        
        Args:
            prompt: åŸå§‹æç¤ºè¯
            
        Returns:
            æ›´æ–°åçš„æç¤ºè¯
        """
        # ç”Ÿæˆä¸»é¢˜è¯åˆ—è¡¨æ–‡æœ¬
        topic_list = self.topic_manager.generate_topic_list_text()
        
        # æŸ¥æ‰¾çŸ¥è¯†åº“éƒ¨åˆ†å¹¶æ›¿æ¢
        pattern = r"##çŸ¥è¯†åº“ï¼š.*?(?=##|$)"
        replacement = self.topic_manager.generate_prompt_kb_text()
        
        # å°è¯•æ›¿æ¢
        updated_prompt = re.sub(pattern, replacement, prompt, flags=re.DOTALL)
        
        # å¦‚æœæ²¡æœ‰æˆåŠŸæ›¿æ¢ï¼Œä¿ç•™åŸæç¤ºè¯
        if updated_prompt == prompt:
            logger.warning("æ— æ³•åœ¨æç¤ºè¯ä¸­æ‰¾åˆ°çŸ¥è¯†åº“éƒ¨åˆ†è¿›è¡Œæ›¿æ¢")
            return prompt
            
        return updated_prompt
    
    def process_paper_file(self, file_path: str, result_list: Optional[List] = None) -> bool:
        """
        å¤„ç†å•ä¸ªè®ºæ–‡æ–‡ä»¶å¹¶è·å–ä¸»é¢˜æ ‡ç­¾
        
        Args:
            file_path: è®ºæ–‡æ–‡ä»¶è·¯å¾„
            result_list: å¯é€‰ï¼Œç”¨äºæ”¶é›†æ‰€æœ‰ç»“æœçš„åˆ—è¡¨
            
        Returns:
            å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
        
        # æ£€æŸ¥ç»“æœæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        paper_name = os.path.basename(file_path)
        output_file_path = os.path.join(self.output_dir, paper_name)
        
        # å¦‚æœä¹‹å‰å·²ç»ç”Ÿæˆè¿‡ç»“æœåˆ™è·³è¿‡å¤„ç†
        if os.path.exists(output_file_path):
            logger.info(f"â­ï¸ ç»“æœå·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†: {paper_name}")
            
            # å¦‚æœéœ€è¦æ”¶é›†ç»“æœï¼Œè¯»å–å·²æœ‰æ–‡ä»¶å†…å®¹
            if result_list is not None:
                try:
                    with open(output_file_path, "r", encoding="utf-8") as f:
                        content = f.read()
                        # ç§»é™¤å‰é¢çš„æ–‡ä»¶åéƒ¨åˆ†
                        response_part = content.split(':', 1)[1].strip() if ':' in content else content
                        self._add_paper_result(paper_name, response_part, result_list)
                except Exception as e:
                    logger.warning(f"âš ï¸ è¯»å–å·²æœ‰ç»“æœå¤±è´¥: {e}")
            return True
        
        # è¯»å–è®ºæ–‡å†…å®¹
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                paper_content = f.read().strip()
        except Exception as e:
            logger.error(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
            return False
        
        # ä½¿ç”¨æœ€æ–°çš„ä¸»é¢˜åˆ—è¡¨æ›´æ–°æç¤ºè¯
        current_prompt = self.update_prompt_with_topics(self.prompt_template)
        
        # æ„å»ºå®Œæ•´çš„æç¤ºè¯
        full_prompt = f"{current_prompt}\n\n{paper_content}"
        
        # è°ƒç”¨LLM
        logger.info(f"ğŸ”„ æ­£åœ¨å¤„ç†è®ºæ–‡: {paper_name}")
        response = self.llm_client.get_completion(full_prompt)
        
        if response:
            # ä¿å­˜ç»“æœ
            with open(output_file_path, "w", encoding="utf-8") as f:
                f.write(f"{paper_name}:\n{response}")
            logger.info(f"ğŸ“„ ç»“æœå·²ä¿å­˜è‡³: {output_file_path}")
            
            # å¦‚æœéœ€è¦æ”¶é›†ç»“æœï¼Œæ·»åŠ åˆ°åˆ—è¡¨
            if result_list is not None:
                self._add_paper_result(paper_name, response, result_list)
            
            return True
        else:
            logger.error(f"âŒ è·å–è®ºæ–‡æ ‡ç­¾å¤±è´¥: {paper_name}")
            return False
    
    def process_directory(self, rel_path: str = "", result_list: Optional[List] = None) -> Tuple[int, int, List]:
        """
        å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰TXTæ–‡ä»¶åŠå…¶å­ç›®å½•
        
        Args:
            rel_path: ç›¸å¯¹è·¯å¾„ï¼Œç”¨äºä¿æŒç›®å½•ç»“æ„
            result_list: å¯é€‰ï¼Œç”¨äºæ”¶é›†æ‰€æœ‰ç»“æœçš„åˆ—è¡¨
            
        Returns:
            æˆåŠŸå¤„ç†çš„æ–‡ä»¶æ•°ã€æ€»æ–‡ä»¶æ•°å’Œç»“æœåˆ—è¡¨çš„å…ƒç»„
        """
        if result_list is None:
            result_list = []
            
        success_count = 0
        total_count = 0
        
        # å®Œæ•´çš„è¾“å…¥ç›®å½•è·¯å¾„
        input_dir = self.input_dir
        if rel_path:
            input_dir = os.path.join(input_dir, rel_path)
            
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(input_dir):
            logger.warning(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            return success_count, total_count, result_list
        
        # éå†ç›®å½•ä¸­çš„æ‰€æœ‰é¡¹ç›®
        for item in os.listdir(input_dir):
            item_path = os.path.join(input_dir, item)
            
            # å¦‚æœæ˜¯ç›®å½•ï¼Œåˆ™é€’å½’å¤„ç†
            if os.path.isdir(item_path):
                new_rel_path = os.path.join(rel_path, item) if rel_path else item
                sub_success, sub_total, result_list = self.process_directory(new_rel_path, result_list)
                success_count += sub_success
                total_count += sub_total
            
            # å¦‚æœæ˜¯TXTæ–‡ä»¶ï¼Œåˆ™å¤„ç†å®ƒ
            elif item.endswith(".txt"):
                total_count += 1
                if self.process_paper_file(item_path, result_list):
                    success_count += 1
        
        return success_count, total_count, result_list
    
    def _add_paper_result(self, paper_name: str, labels: str, result_list: List) -> List:
        """
        å°†è®ºæ–‡ç»“æœæ·»åŠ åˆ°ç»“æœåˆ—è¡¨
        
        Args:
            paper_name: è®ºæ–‡æ–‡ä»¶å
            labels: æ ‡ç­¾æ–‡æœ¬
            result_list: ç»“æœåˆ—è¡¨
            
        Returns:
            æ›´æ–°åçš„ç»“æœåˆ—è¡¨
        """
        # æ¸…ç†æ ‡ç­¾æ–‡æœ¬
        clean_labels = labels.strip()
        
        # å°è¯•æå–å…³é”®è¯æ•°ç»„
        keywords_array = self.extract_keywords_array(clean_labels)
        
        # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
        result_list.append({
            "paper": paper_name,
            "labels": keywords_array
        })
        
        return result_list
    
    def save_results(self, result_list: List) -> Dict[str, int]:
        """
        ä¿å­˜æ±‡æ€»ç»“æœå’Œå…³é”®è¯ç»Ÿè®¡
        
        Args:
            result_list: ç»“æœåˆ—è¡¨
            
        Returns:
            å…³é”®è¯è®¡æ•°å­—å…¸
        """
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)
        
        # ä¿å­˜å®Œæ•´ç»“æœ
        results_file = os.path.join(self.output_dir, "paper_labels_results.json")
        with open(results_file, "w", encoding="utf-8") as f:
            json.dump(result_list, f, ensure_ascii=False, indent=2)
        
        # æå–æ‰€æœ‰å…³é”®è¯å¹¶è®¡æ•°
        keyword_counts = {}
        for paper_result in result_list:
            # å°è¯•æŒ‰é€—å·æˆ–å…¶ä»–åˆ†éš”ç¬¦åˆ†å‰²æ ‡ç­¾
            labels_text = paper_result.get("labels", "")
            
            # å¦‚æœåŒ…å«æ•°å­—å’Œé€—å·ï¼Œå¯èƒ½æ˜¯å…³é”®è¯æ•°ç»„æ ¼å¼
            if re.search(r'\d+,\s*\d+', labels_text):
                labels = re.findall(r'\d+', labels_text)
            else:
                labels = labels_text.replace("ï¼Œ", ",").split(",")
            
            for label in labels:
                label = label.strip()
                if label:
                    keyword_counts[label] = keyword_counts.get(label, 0) + 1
        
        # æŒ‰è®¡æ•°æ’åº
        sorted_keywords = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)
        
        # ä¿å­˜å…³é”®è¯ç»Ÿè®¡
        keywords_file = os.path.join(self.output_dir, "keyword_counts.json")
        with open(keywords_file, "w", encoding="utf-8") as f:
            json.dump(dict(sorted_keywords), f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“Š æ±‡æ€»ç»“æœå·²ä¿å­˜è‡³ {results_file}")
        logger.info(f"ğŸ“Š å…³é”®è¯ç»Ÿè®¡å·²ä¿å­˜è‡³ {keywords_file}")
        
        return dict(sorted_keywords)


def label_papers(input_dir: str = None, output_dir: str = None) -> bool:
    """
    å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰è®ºæ–‡å¹¶ç”Ÿæˆæ ‡ç­¾
    Args:
        input_dir: è¾“å…¥ç›®å½•ï¼Œå¦‚æœæä¾›åˆ™è¦†ç›–é»˜è®¤è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœæä¾›åˆ™è¦†ç›–é»˜è®¤è·¯å¾„
    Returns:
        å¤„ç†æ˜¯å¦æˆåŠŸï¼ˆè‡³å°‘æˆåŠŸå¤„ç†ä¸€ä¸ªæ–‡ä»¶ï¼‰
    """
    try:
        # åˆå§‹åŒ–è®ºæ–‡æ ‡ç­¾ç”Ÿæˆå™¨
        labeler = PaperLabeler()
        
        # å¦‚æœæä¾›äº†è‡ªå®šä¹‰è·¯å¾„ï¼Œåˆ™ä½¿ç”¨è‡ªå®šä¹‰è·¯å¾„
        if input_dir:
            labeler.input_dir = input_dir
        if output_dir:
            labeler.output_dir = output_dir
            
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(labeler.output_dir, exist_ok=True)
        
        # å¤„ç†æ‰€æœ‰è®ºæ–‡
        logger.info(f"ğŸš€ å¼€å§‹å¤„ç†è®ºæ–‡ï¼Œæºç›®å½•: {labeler.input_dir}")
        success_count, total_count, all_paper_results = labeler.process_directory()
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        if all_paper_results:
            keyword_counts = labeler.save_results(all_paper_results)
            logger.info(f"ğŸ“Š å…³é”®è¯ç»Ÿè®¡å®Œæˆï¼Œå…± {len(keyword_counts)} ä¸ªå…³é”®è¯")
            
        logger.info(f"ğŸ‰ å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {success_count}/{total_count} ä¸ªæ–‡ä»¶ã€‚")
        logger.info(f"ç»“æœå·²ä¿å­˜è‡³ {labeler.output_dir}")
        
        # å¦‚æœè‡³å°‘æœ‰ä¸€ä¸ªæ–‡ä»¶æˆåŠŸå¤„ç†ï¼Œåˆ™è®¤ä¸ºæ“ä½œæˆåŠŸ
        return success_count > 0
    except Exception as e:
        logger.error(f"å¤„ç†è®ºæ–‡æ ‡ç­¾æ—¶å‡ºé”™: {str(e)}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¤„ç†è®ºæ–‡æ‘˜è¦å¹¶ç”Ÿæˆä¸»é¢˜æ ‡ç­¾")
    
    args = parser.parse_args()
    
    label_papers()


if __name__ == "__main__":
    main()
