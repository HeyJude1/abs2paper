### 实验设计总结：

#### 1、核心目标:
- **验证多模态预训练模型的有效性**：通过六个下游任务（异构设备映射、线程粗化、循环向量化、OpenMP运行时配置调优、NUMA/预取器参数优化、CUDA线程块调优）评估模型在代码性能优化中的通用性。
- **降低深度学习优化的开销**：证明无需微调预训练模型，仅通过推理模式生成嵌入即可实现高性能，显著减少计算资源需求（如单GPU训练22M参数模型）。
- **多模态的必要性分析**：通过消融实验验证代码文本（IR）和代码图（graph）双模态对模型性能的互补作用。

#### 2、数据集:
- **异构设备映射**：Ben-Nun等发布的256个OpenCL内核数据集（来自AMD/NVIDIA SDK等7个基准套件），共1340个CPU/GPU标记数据点。
- **线程粗化**：68个数据点（17个OpenCL内核在4种GPU上），覆盖{1,2,4,8,16,32}粗化因子。
- **循环向量化**：Intel Skylake上生成的273K样本，包含(VF, IF)组合及运行时数据。
- **OpenMP调优**：Polybench的25个应用，504种配置×2输入尺寸，共25200样本。
- **NUMA/预取器优化**：57个并行内核（Rodinia/NAS等），13种关键配置，含编译器序列增强数据。
- **CUDA线程块调优**：LS-CAT数据集（19,683个CUDA内核），扩展至270万样本（NVIDIA A100）。

#### 3、关键设置:
- **模型架构**：22M参数的多模态编码器（IR文本+代码图），预训练后固定权重，下游任务仅训练顶层MLP。
- **评估协议**：
  - 设备映射/线程粗化：十折分层交叉验证/留一法验证。
  - NUMA/CUDA任务：10折验证，仅用5%数据训练（迁移学习）。
  - OpenMP调优：留一法应用级验证。
- **基线对比**：
  - 对比静态策略（如LLVM默认向量化）、SOTA方法（如PnP Tuner的GNN）。
  - 指标包括准确率、F1分数、几何平均加速比、相对错误率。
- **效率控制**：
  - 禁用预训练模型微调，推理时间比GNN方法快238倍。
  - 消融实验中单模态性能下降4%-37%（依赖任务特性）。