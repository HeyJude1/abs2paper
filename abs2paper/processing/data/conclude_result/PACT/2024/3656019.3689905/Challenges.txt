核心挑战总结：

挑战一：**非结构化稀疏性的存储与计算效率问题**  
分析:  
- 具体内容：ML模型中普遍存在的非结构化稀疏（随机分布的非零元素）导致内存访问不规律，传统稀疏矩阵存储格式（如CSR/COO）因需记录每个非零元素的位置而产生高额元数据开销。在中等稀疏度（≤90%）场景下，元数据存储成本可能超过量化后的数值数据本身，甚至劣于稠密格式。  
- 根源：  
  1. **问题复杂性**：非结构化稀疏的随机性破坏了硬件友好的数据局部性；  
  2. **技术瓶颈**：现有存储格式（如CSR/COO）为超稀疏矩阵（>99.9%稀疏度）设计，其元数据比例随矩阵密度上升急剧恶化；  
  3. **数据限制**：量化技术（如4-bit精度）大幅缩减数值数据体积，进一步凸显元数据开销的占比。

挑战二：**动态稀疏矩阵的硬件适配性不足**  
分析:  
- 具体内容：激活函数（如ReLU）和注意力机制生成的动态稀疏矩阵难以预定义结构，而现有加速器依赖结构化剪枝或固定格式（如CSR），无法高效处理此类动态不规则性。  
- 根源：  
  1. **技术瓶颈**：结构化剪枝需预先约束稀疏模式以匹配硬件特性，牺牲模型压缩率（结构化仅达70%压缩 vs. 非结构化90%）；  
  2. **问题复杂性**：动态生成的稀疏模式无法提前优化，导致传统加速器的静态数据流设计失效。

挑战三：**跨稀疏度范围的通用处理能力缺失**  
分析:  
- 具体内容：ML工作负载的稀疏度变化范围大（模型间/层间差异显著），而现有加速器仅针对超稀疏或特定稠密区间优化，在中等稀疏度下性能骤降。例如科学计算加速器依赖的粗粒度分块跳过策略在ML场景中因非零元素分布密集而失效。  
- 根源：  
  1. **技术瓶颈**：领域专用架构（如科学计算加速器）的设计假设与ML实际需求不匹配；  
  2. **问题复杂性**：ML模型多样性和层间异构性要求架构具备动态适应能力，而现有方案缺乏弹性数据流和存储层次设计。  

注：上述挑战均源于论文中对比实验（如CSR/COO存储开销分析）、领域现状综述（如Table中的加速器分类）及作者对技术局限性的直接论述（如动态稀疏不可预测性）。