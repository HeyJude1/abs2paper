### 度量指标总结  

#### 1、评估指标:  
**指标1 平均预测延迟（Average Predict Latency）**:  
- **衡量方面**: 每个输入样本的平均预测时间（单位为时间单位，如毫秒或微秒），反映模型的推理效率。  
- **应用场景**: 用于比较不同推理方案（如XGBoost、LightGBM、ONNX Runtime、OBF/ODF）在单线程/多线程、不同批次大小下的性能差异。  

**指标2 模型大小（Model Size）**:  
- **衡量方面**: 序列化模型文件的体积（单位为字节），反映存储和内存占用效率。  
- **应用场景**: 对比不同框架（如pickle序列化、ONNX文件、ELF二进制文件）的存储开销，优化部署资源占用。  

**指标3 变异系数（Coefficient of Variation, CV）**:  
- **衡量方面**: 预测延迟的标准差与均值的比值，衡量延迟的稳定性。  
- **应用场景**: 分析不同批次大小下延迟的波动性（如短批次的高变异性）。  

**指标4 百分位数延迟（95th/99th Percentile Latency）**:  
- **衡量方面**: 极端情况下的延迟表现，反映系统在高负载或异常情况下的鲁棒性。  
- **应用场景**: 评估实际部署中长尾延迟的影响。  

#### 2、选取理由:  
1. **全面覆盖性能维度**:  
   - **平均预测延迟**直接反映核心推理效率，是优化目标的核心指标；  
   - **模型大小**关联部署成本，尤其在边缘计算等资源受限场景中至关重要；  
   - **变异系数和百分位数**补充了平均值的局限性，揭示性能稳定性和极端情况表现。  

2. **实验需求匹配**:  
   - 论文聚焦于推理加速方案的对比（如SIMD指令、多线程优化），需量化时间效率和资源消耗；  
   - 批次大小敏感性分析要求引入变异系数和百分位数，以验证动态函数选择策略的鲁棒性。  

3. **与基线方法可比性**:  
   - ONNX Runtime、XGBoost等主流框架均以延迟和模型大小为通用基准指标，确保对比公平性；  
   - 引入AVX2/AVX-512和多线程的加速比（如11.4倍提升）进一步凸显方案优势。  

4. **实际部署考量**:  
   - 短批次的高变异性分析（如CV=1.2）为实时系统设计提供关键参考；  
   - 模型大小差异（如OBF/ODF的最小化）直接影响嵌入式设备的适用性。  

综上，所选指标从效率、稳定性、资源占用三个维度完整支撑了论文的核心论点——动态选择的OBF/ODF方案在推理加速和资源优化上的优越性。