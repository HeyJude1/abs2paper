### 实验结果分析总结

#### 1、主要发现:  
- **性能对比**：  
  - **g-SpMM性能**：在REDDIT、OGBN-PROTEINS和OGBN-PRODUCTS数据集上，G-Sparse平均分别比DGL（cuSPARSE实现）快3.2×、2.6×和1.5×；比FeatGraph平均快1.9×（最高3.4×）；比Sputnik平均快1.4×（最高2.1×）。REDDIT上的加速更显著，因其数据分布更不平衡且每行非零值更多。  
  - **g-SDDMM性能**：在所有测试案例中，G-Sparse均优于或匹配DGL和FeatGraph，平均加速比为1.46×（范围1.02×–3.37×）。对于特征长度小于32的情况，G-Sparse因支持更灵活的warp shuffle优化而表现更优。  

- **端到端训练与推理**：  
  - 在GCN、GAT和GraphSAGE模型的全批量训练中，G-Sparse集成至DGL后，模型训练和推理性能相比原生DGL提升1.37×–2.25×，且测试准确率与DGL一致（如GCN 94.0%，GraphSage 93.7%，GAT 93.1%）。

#### 2、消融研究结论:  
- **关键优化组件**：  
  - **2-D共享内存分块和行平衡**：对g-SpMM和g-SDDMM性能影响显著，且不受特征长度变化的明显影响。  
  - **Warp shuffle优化**：对g-SDDMM性能提升显著，但对特征长度的鲁棒性较差。  
  - **1-D stride寄存器分块**：贡献约10%的性能提升，但在特征长度为8时无收益（因GPU warp未充分利用）。  

#### 3、其他分析洞察:  
- **自动调优（Autotuning）**：  
  - 结合成本模型与遗传搜索算法，自动调优后的内核比手动调优快最多3.7×。成本模型的训练与推理相关系数分别为0.88/0.99（g-SpMM）和0.74/0.89（g-SDDMM），显示良好泛化性。  
  - 自动调优在GPU资源分配（如线程块数量、寄存器使用）上优于人工调优，尤其在处理相互约束的参数时更具优势。  

- **代码效率**：  
  - G-Sparse的核心代码量显著少于DGL（如g-SpMM仅需86行 vs DGL的313行），同时实现更高性能（g-SpMM和g-SDDMM分别平均快2.5×和1.45×）。  

- **局限性**：  
  - 当前自动调优仅支持GPU硬件，且需数秒生成最优程序；未来计划扩展至多硬件及采样训练的加速场景。  

- **可视化与案例研究**：  
  - Figure 10等图表显示，在特征长度为512/1024时，部分基线方法及G-Sparse在OGBN-PRODUCTS上出现内存不足问题。此外，成本模型在相同试验次数下比随机采样快1.0×–2.9×。