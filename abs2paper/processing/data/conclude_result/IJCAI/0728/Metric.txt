### 度量指标总结  

#### 1. 评估指标  
**多选任务（Multiple-Choice Tasks）:**  
- **MC1/MC2/MC3（Multiple-Choice Accuracy）**  
  - **衡量方面**: 模型在TruthfulQA基准测试中选择正确答案的能力。  
    - **MC1**: 仅评估模型对"最佳答案"（Best Answer）的选择准确性。  
    - **MC2/MC3**: 额外考虑其他"正确答案"（Correct Answers）的选择能力。  

**开放式生成任务（Open-Ended Generation Tasks）:**  
- **Truthfulness**  
  - **衡量方面**: 生成答案的真实性（是否与事实一致）。  
- **Informativeness**  
  - **衡量方面**: 生成答案的信息丰富度（是否提供充分且有价值的信息）。  
- **数学推理与常识推理性能**  
  - **衡量方面**: 在GSM8K、MultiArith、BoolQ和PIQA等数据集上的任务完成质量，通过模型输出与标准答案的匹配度评估。  

#### 2. 选取理由  
1. **任务适配性**:  
   - **MC1/MC2/MC3**：针对多选任务的特性，区分模型对最佳答案和其他正确答案的识别能力，全面评估知识对齐效果。  
   - **Truthfulness/Informativeness**：开放式生成任务需同时满足真实性和信息量，这两个指标直接反映生成内容的质量和实用性。  

2. **领域覆盖性**:  
   - 数学推理（GSM8K、MultiArith）和常识推理（BoolQ、PIQA）采用领域内标准数据集，确保指标可横向对比不同模型的泛化能力。  

3. **方法验证需求**:  
   - MC2/MC3的改进验证了TaD方法即使仅用<Question, Best Answer>训练，仍能提升对其他正确答案的捕捉能力。  
   - Truthfulness/Informativeness用于量化知识向量对齐对生成内容质量的直接影响。  

4. **对比实验兼容性**:  
   - 所选指标与基线方法（如CD、DoLa）的评估保持一致，确保结果可比性（如MC1用于超参数调优，MC2/MC3用于性能稳定性验证）。  

**综合合理性**: 指标覆盖了模型的核心能力（准确性、真实性、泛化性），且与任务目标高度对齐，同时支持对TaD方法优势的细粒度分析（如知识向量方向的影响）。