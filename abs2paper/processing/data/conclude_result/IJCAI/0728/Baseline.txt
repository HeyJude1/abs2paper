### Baseline选取总结：

1. **对比方法**:
   - **CD** (Contrastive Decoding)
   - **DoLa** (Decoding by Contrasting Layers)

2. **选取理由**:
   - **技术路线代表性**：  
     CD和DoLa是当前两种典型的解码策略优化方法，分别通过对比不同模型层或专家/业余模型的输出来改进生成质量。它们代表了不依赖知识适应（knowledge adaptation）的基线方法，与论文提出的TaD（基于知识向量调整的解码策略）形成直接对比。
   - **任务适配性**：  
     论文在多项选择（TruthfulQA）和数学推理任务（GSM8K、MultiArith）上验证TaD的通用性，而CD和DoLa此前已被证明在这些任务中存在局限性（如CD在数学推理中性能显著下降），因此选择它们能有效凸显TaD的优势。
   - **公平性控制**：  
     作者对CD和DoLa的超参数进行了细致调优以确保对比的公平性（例如基于MC1分数优化DoLa的间隔参数），并统一应用于微调后的模型，避免因实现差异导致偏差。
   - **性能边界验证**：  
     CD和DoLa作为SOTA解码优化方法，其性能波动（如CD在LLaMA-13b + LoRA下MC1优于TaD但MC2/3显著下降）有助于界定TaD的改进边界，证明后者在综合指标上的鲁棒性。

### 补充说明：
- **未选经典方法的考虑**：论文未选择更基础的解码策略（如Beam Search）作为基线，因实验已默认使用Greedy Search，且CD/DoLa本身是Greedy Search的改进版本，能更直接体现知识向量调整的增量贡献。