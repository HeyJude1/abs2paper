### 核心挑战总结：

#### 挑战一：**固有知识利用不足**  
**分析**:  
现有微调方法（如PEFT）主要关注算法优化或数据构建，但忽视了对预训练大语言模型（LLMs）固有知识的系统性挖掘与利用。研究表明，预训练LLMs的内部表征可能包含正确知识（即使输出错误），但当前微调范式缺乏有效机制将这些潜在知识显式整合到下游任务中。这一挑战源于对模型行为与知识表征之间关联性的理解不足，以及缺乏量化知识迁移的数学工具。

#### 挑战二：**知识适应方向不明确**  
**分析**:  
微调过程中，LLMs从通用预训练知识到任务特定知识的适应过程是隐式的（如概率分布偏移），现有方法无法显式捕捉和强化这种适应方向。例如，模型可能生成相同token（如"engage"），但其预测概率分布的变化隐含了专业化知识的转移（如"catalyze"概率提升）。这种挑战源于概率空间的高维复杂性，以及缺乏将分布差异转化为可操作信号的机制。

#### 挑战三：**数据稀缺下的性能瓶颈**  
**分析**:  
高质量人工标注数据集构建成本高昂，而现有数据增强方法（如输入输出对反转）难以充分激发模型潜力。在数据稀缺场景下，传统微调方法性能显著下降。这一挑战的根源在于过度依赖外部数据扩展，而未能有效利用模型内部已有的知识迁移动态（如token偏好变化）作为补充信号。

### 补充说明：  
论文通过构建**知识向量**（基于预训练与微调模型的输出概率分布差异）显式量化知识适应方向，并设计任务感知解码（TaD）动态增强目标token概率。该方法直接应对上述挑战：  
1. 将固有知识编码为可计算的语义向量；  
2. 通过分布差异显式建模适应方向；  
3. 减少对额外数据的依赖，激活模型内部知识迁移能力。