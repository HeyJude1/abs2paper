### 度量指标总结：

#### 1. 评估指标:
- **FairEval**：用于评估开放性问题回答的质量，通过多种方法减少评估偏差，提高与人类判断的一致性。  
- **HumanEval**：通过人工评分（志愿者）评估模型生成回答的**帮助性、可靠性、准确性和细节水平**，直接反映人类主观判断。  
- **Trivia Creative Writing Metric Score**：自动化指标，通过字符串匹配验证生成内容中 trivia 问题的正确答案提及数量，衡量模型**整合多领域知识的能力和事实准确性**。  

#### 2. 选取理由:  
论文选择的指标覆盖了**客观量化评估（自动化指标）和主观人工评估**两个维度，形成互补：  
- **FairEval + HumanEval**：针对开放性任务（如问答），需平衡自动化评估的效率和人类对文本质量的多维评判（如逻辑性、细节）。FairEval减少算法偏差，HumanEval提供真实用户体验反馈。  
- **Trivia Creative Writing Metric Score**：针对知识密集型任务（如创意写作），需严格量化模型对事实性知识的掌握程度。字符串匹配方法直接验证答案正确性，符合任务核心目标（知识整合）。  

此外，指标与实验设计高度契合：  
- **任务特性适配**：开放性问题侧重生成质量（FairEval/HumanEval），而创意写作侧重知识准确性（Trivia Score）。  
- **可复现性**：自动化指标（如Trivia Score）便于横向对比；人工评分（HumanEval）增强结论可信度。  

综上，指标选取全面覆盖了生成质量、事实准确性和用户体验，兼具严谨性与实用性。