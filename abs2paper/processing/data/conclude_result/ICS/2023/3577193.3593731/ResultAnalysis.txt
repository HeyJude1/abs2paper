实验结果分析总结：

1、主要发现:  
- BEAM算法在多数测试矩阵上显著优于GEPP（部分案例速度提升达5倍），同时保持与GEPP相当的数值稳定性。  
- 对于随机矩阵（如rand_dominant和rand），BEAM无需修正即可达到高精度；对于结构化矩阵（如orthog、zielkeNS），需结合Woodbury修正以处理病态问题。  
- 当τκ₂(A)≪1时，BEAM的迭代 refinement能收敛至双精度精度（η∞(x) < √n·2⁻⁵³）。但若τ过大（如τ=10⁻⁶且无Woodbury修正），部分病态矩阵（如fiedler、riemann）会因误差累积导致迭代 refinement失败。

2、消融研究结论:  
- **Woodbury修正的作用**：修正显著提升病态矩阵的稳定性（如orthog在τ=10⁻¹⁰时误差降低），但增加计算开销；无修正时，小τ（≤10⁻¹⁰）可避免扰动主导误差。  
- **块大小(nb)影响**：较小块（如nb=64）通常性能更优，但大块（如nb=512）能减少修正次数并提升精度（尤其对orthog矩阵）。  
- **容忍度(τ)选择**：τ=10⁻⁸~10⁻¹⁰是平衡点，过大的τ（如10⁻⁶）会导致过多修正并降低精度，尤其无Woodbury修正时。

3、其他分析洞察:  
- **参数敏感性**：τκ₂(A)≪1是关键条件，违反时（如zielkeNS的τ=10⁻⁴）易引发数值溢出（NaN）。  
- **性能权衡**：无Woodbury修正的BEAM在多数情况下时间更优，但对病态矩阵需启用修正以确保收敛。  
- **扩展性测试**：BEAM在n=250,000规模下仍保持优势，但需注意GPU内存限制（迭代 refinement需额外存储）。  

关键数据支持：  
- 随机矩阵中BEAM速度达GEPP的4~5倍，结构化矩阵中保持70%~144%优势。  
- orthog矩阵在nb=64、τ=10⁻⁸时修正次数显著减少，但需Woodbury修正以维持精度。  
- zielkeNS在τ>10⁻¹⁰时因病态性导致失败，凸显τ与κ₂(A)关联的重要性。