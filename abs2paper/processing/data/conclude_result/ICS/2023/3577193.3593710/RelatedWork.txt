## 相关工作总结

1、现有方法一：通用型解决方案 (General-purpose solution)
核心思想: 使用单一框架支持多种经典机器学习模型，如Scikit-learn、Spark MLlib、H2O等。这些框架旨在提供统一的接口和广泛模型支持。
主要局限性: 
- 仅支持CPU计算，存在严重的性能瓶颈
- 缺乏跨硬件平台的便携性(portability)支持
- 无法充分利用现代加速硬件(GPU/FPGA)的优势

2、现有方法二：专用型解决方案 (Specific-purpose solution)
核心思想: 专注于特定类型模型的优化实现，如LibLinear(逻辑回归/线性SVM)、LibSVM(SVM)、XGBoost(梯度提升树)等。
主要局限性:
- 模型支持范围极其有限(通常仅1-2种算法)
- 多数仍局限于CPU实现
- 部分工作(如XGBoost FPGA版)虽尝试硬件扩展，但优化不系统
- 无法形成统一的CML开发生态

3、现有方法三：基于深度学习的扩展方案 (Extension based on DL)
核心思想: 利用深度学习框架(TensorFlow/PyTorch)的基础设施支持经典机器学习，如TF-DF(决策森林)、Hummingbird(PyTorch扩展)。
主要局限性:
- 现有实现多为临时方案(ad-hoc)，丧失DL框架原有的便携性优势
- 直接套用DL抽象层，未针对CML特性进行专门优化
- 错过大量潜在的硬件优化机会
- CPU支持不完善(TF-DF仅限CPU)

研究缺口总结：
作者指出现有工作的核心共性问题在于：
1. 硬件支持不足：大多数方案未能系统性地解决跨平台(CPU/GPU/FPGA)部署问题
2. 优化不充分：未针对经典机器学习算法的独特计算模式进行深度硬件优化
3. 生态割裂：缺乏同时满足"广泛模型支持"和"跨硬件高效执行"的统一框架