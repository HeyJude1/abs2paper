本文创新点总结：

1. **Exclusive gradient selection（独占梯度选择）** (类型: [新方法])  
   - 通过梯度向量分区和独占分配机制消除梯度堆积问题，提升通信效率并降低计算成本。该方法显著提高了分布式DNN训练的可扩展性。

2. **Accurate threshold estimation（精确阈值估计）** (类型: [理论改进])  
   - 提出基于压缩比误差最小化的动态阈值估计方法，确保实际通信流量严格匹配用户设定密度，避免传统阈值方法的密度失控问题，从而加速训练过程。

3. **Multidimensional evaluation（多维评估）** (类型: [深入的实验分析])  
   - 通过全面的实验对比（包括收敛性、稀疏化效率、阈值准确性等维度），验证MiCRO在计算/通信开销和训练性能上优于现有稀疏化方法。

4. **Coarse-grained gradient vector partitioning（粗粒度梯度向量分区）** (类型: [新架构])  
   - 设计了一种并行友好的梯度向量分区策略，将梯度选择计算复杂度从O(n)降至O(n/p)（p为分区数），同时保留阈值过滤的数学不变性。

5. **Near-zero cost sparsification framework（近零成本稀疏化框架）** (类型: [系统优化])  
   - 整合上述创新点构建MiCRO系统，首次实现同时解决梯度堆积、阈值不准和计算冗余三大挑战，在分布式训练中达成计算与通信成本的协同优化。