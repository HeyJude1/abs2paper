方法概述：
1、方法名称: MiCRO (Minimizing Compression Ratio Error On-the-fly)
2、核心思想: 通过动态最小化压缩比误差的阈值估计和基于分区的独占梯度选择，实现高效、低成本的梯度稀疏化，以解决分布式DNN训练中的通信瓶颈问题。其核心创新在于同时消除梯度累积（gradient build-up）并保持模型保真度。

3、主要流程/组件
组件/步骤一: 粗粒度梯度向量分区
- 将整个梯度向量均等划分为n个分区（n为worker数量）
- 采用循环分配策略，每个worker在每n次迭代中可遍历完整梯度空间
- 分区设计符合GPU内存访问模式，避免内存发散导致的性能下降

组件/步骤二: 基于阈值的独占梯度选择
- 每个worker仅从专属分区中选择梯度（绝对值大于阈值）
- 通过非重叠搜索空间彻底消除梯度累积现象
- 将计算复杂度从O(n_g)降至O(n_g/n)，提升可扩展性

组件/步骤三: 阈值动态缩放机制
- 通过最小化压缩比误差|k - k_i,t|动态调整阈值（k为用户设定密度，k_i,t为实际选择数）
- 仅需条件判断和变量赋值操作，零计算开销
- 相比静态阈值和统计模型方法，对多样化训练设置具有更强鲁棒性

关键关系说明：
1. 分区机制为独占选择提供空间保障，同时支撑计算复杂度优化
2. 动态阈值调整与分区选择形成闭环：阈值缩放基于分区选择结果，而调整后的阈值又指导下一轮选择
3. 整体流程在反向传播后触发，与模型更新过程无缝衔接（见算法1的6-16行）