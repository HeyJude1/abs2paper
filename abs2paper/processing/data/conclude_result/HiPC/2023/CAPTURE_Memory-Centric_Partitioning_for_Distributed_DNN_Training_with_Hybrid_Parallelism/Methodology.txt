方法概述：
1、方法名称: CAPTURE (Memory-Centric Partitioner for Hybrid-Parallel DNN Training)
2、核心思想: 通过基于性能分析的统计建模方法，自动生成内存优化的混合并行（流水线并行+数据/张量并行）划分方案，以最小化GPU间的峰值内存使用差异。该方法具有深度学习框架无关性，适用于任意混合并行训练系统。

3、主要流程/组件
组件/步骤一: 性能分析阶段（Profiling Stage）
- 执行短时性能分析运行，收集DNN各层的两个关键内存指标：独立内存(M_i)和增量内存(M_a)
- 覆盖三种训练场景：纯流水线并行、数据/张量并行、不同批次大小
- 采用层合并技术减少分析运行次数

组件/步骤二: 预测模型（Predictor）
- 基于统计建模预测任意划分方案的内存使用：
  • 对流水线并行阶段：直接累加M_i和M_a
  • 对数据/张量并行阶段：拟合对数函数外推高并行度场景
- 支持目标批次大小的线性缩放预测

组件/步骤三: 推荐系统（Recommender）
- 枚举所有有效的层组划分和并行化配置组合
- 评估每个配置的峰值内存使用（基于预测器输出）
- 推荐全局内存最平衡的方案，采用剪枝策略加速搜索

关键关系：
1. Profiling→Predictor：分析数据作为建模基础
2. Predictor→Recommender：提供内存预测支持方案评估
3. Layer Merger贯穿全过程：减少分析复杂度和搜索空间

创新特性：
1. 混合并行统一建模（同时处理流水线+数据/张量并行）
2. 批次大小感知的内存预测
3. 框架无关的实现设计