问题背景总结：  
1、研究领域: 深度学习模型优化，具体聚焦于神经网络量化技术领域。  
2、核心问题: 如何设计一种无需重新训练、能联合量化权重与激活值、适用于不同DNN模型且能降低硬件复杂性的非均匀量化方法，以实现计算效率与模型精度的最优权衡。  
3、研究动机:  
   - **理论需求**：现代DNN模型（如Transformer）参数量剧增（如1.6万亿参数），导致存储、数据传输和计算能耗激增，而现有量化方法（如均匀8bit量化或对数量化）在更低比特宽度下存在精度损失或硬件适配不足的问题。  
   - **实践瓶颈**：现有技术（如剪枝）需高成本重新训练，且稀疏模型需要复杂硬件支持；而传统量化方法难以在低于8bit时保持精度，无法满足移动/嵌入式设备的部署需求。  
4、潜在应用:  
   - 移动设备与嵌入式系统（如自动驾驶汽车、语音识别终端）的高效DNN部署；  
   - 基于3D堆叠DRAM的专用DNN加速器设计，提升能效比与计算性能。  

（注：总结严格基于原文中关于DNN规模膨胀、能耗问题、现有技术局限及作者方案目标的描述。）