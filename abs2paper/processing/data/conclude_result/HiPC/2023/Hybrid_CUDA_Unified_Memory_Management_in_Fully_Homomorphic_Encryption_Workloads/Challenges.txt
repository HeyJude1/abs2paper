核心挑战总结：

挑战一：**GPU内存限制与高效管理的矛盾**  
分析:  
- 根源在于零售级GPU的物理内存容量有限（通常远小于主机DRAM），而FHE运算（尤其是bootstrapping）需要存储大量密钥和中间数据，导致内存需求激增。  
- 问题复杂性体现在：不同FHE参数集（如CKKS的安全参数、模数大小、密文槽数）会动态影响内存占用，传统静态内存分配策略难以适应这种变化。  

挑战二：**数据迁移与计算同步的开销**  
分析:  
- 源于CUDA统一内存(UM)的按需迁移机制：频繁的CPU-GPU数据迁移会引入延迟，尤其当FHE操作（如密文旋转、重缩放）需要交替访问主机/设备内存时。  
- 技术瓶颈表现为：现有UM的异步预取(cudaMemPrefetchAsync)虽能重叠计算与传输，但无法完全消除因安全参数增大导致的迁移频次上升问题。  

挑战三：**动态内存分配的实时性要求**  
分析:  
- 由FHE运算特性决定：不同操作（加法/乘法/自举）对内存的需求量和生命周期差异显著，传统同步式分配(cudaMalloc)会导致GPU流水线阻塞。  
- 现有技术局限：尽管cudaMallocAsync支持流序异步分配，但其依赖内存池阈值设置，在极端参数组合下仍可能因OS级分配延迟影响实时性。  

补充说明：  
论文通过混合策略（cudaMallocAsync + cudaMallocManaged）试图同时解决上述挑战：前者优化动态分配效率，后者缓解OOM风险。但需权衡两者带来的额外同步开销与性能收益。