方法概述：
1、方法名称: LO-SpMM (Low-cost Search for High-performance SpMM Kernels on GPUs)
2、核心思想: 通过两阶段搜索策略（分块空间缩减和代理评估）快速生成高性能的稀疏矩阵-稠密矩阵乘法(SpMM) GPU实现，同时显著降低传统编译器搜索成本。该方法结合GPU架构先验知识、稀疏矩阵重排序和机器学习排序模型，在保证性能的前提下实现低开销的自动优化。

3、主要流程/组件
组件/步骤一: 分层二维分块策略
- 将SpMM计算划分为线程级、线程束级和线程块级三层分块
- 通过(M1,N1)分块尺寸构建初始搜索空间，每个线程处理(M1,1)输出子矩阵

组件/步骤二: 搜索空间缩减约束
- 寄存器资源约束：排除超出GPU寄存器容量的分块配置
- 硬件利用率约束：确保线程块数量能充分利用GPU多处理器
- 负载均衡约束：通过变异系数(COV_row)和填充率(WASTE_col)指标保证计算负载均衡

组件/步骤三: 稀疏矩阵重排序（可选优化）
- 通过超图划分算法重组非零元素分布
- 目标：减少每个分块的非空列数(nnc)以降低内存访问次数
- 保持分块间计算负载平衡(约束nnz差异<α)

组件/步骤四: 排序模型筛选
- 使用LambdaMART构建listwise排序模型
- 基于分块配置特征预测性能排名，选择Top-K候选

组件/步骤五: 代理评估机制
- 为候选分块生成简化版CUDA代码(proxy)
- proxy保持与原实现相似的性能排名关系但评估成本更低
- 最终选择代理性能最优的分块配置生成实际SpMM内核

组件/步骤六: SpMM内核实现优化
- 完全展开循环+常数传播优化稀疏矩阵访问
- 寄存器存储累加器(Acc)加速访问
- B矩阵数据预取技术隐藏访存延迟

组件/步骤七: 端到端DNN推理集成
- 结合SparTA进行稀疏网络属性传播
- 使用Rammer进行算子融合和并行优化
- Conv2D通过隐式im2col转换为SpMM实现