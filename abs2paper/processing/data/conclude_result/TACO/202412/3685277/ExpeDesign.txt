### 实验设计总结：

#### 1. 核心目标：
- **验证代理评估方法的有效性**：通过简化代码（代理）减少编译时间，同时保持与原SpMM实现的相对性能排名一致性。
- **优化SpMM内核生成流程**：通过三阶段（代理生成、运行时参数配置、最优瓦片大小选择）实现高性能SpMM内核的低成本搜索。
- **评估性能与编译时间权衡**：比较LO-SpMM与现有方法（如cuSPARSE、Sputnik、SparTA等）的性能和编译时间成本。

#### 2. 数据集：
- **基准数据集**：从BERT、ResNet50、ShufflenetV2和MobilenetV2等神经网络中提取41种GEMM算子形状，随机裁剪生成205个SpMM内核（5种稀疏度）。
  - **形状范围**：`M∈[64,3072]`, `N∈[512,50176]`, `K∈[27,3072]`。
- **端到端评估模型**：
  - **BERT**（90.99%稀疏度，QQP任务准确率86.3%）。
  - **ResNet50**（90%稀疏度，ImageNet任务准确率66.0%）。

#### 3. 关键设置：
- **代理生成技术**：
  - **核函数简化**：避免硬编码瓦片大小，通过运行时参数支持多配置。
  - **线程块函数聚类**：基于内存访问和浮点操作特征，使用凝聚聚类减少编译代码量。
  - **循环块截断**：保留少量代理迭代（`N_NCP=min(N_NC,300/(1-sparsity))`）以缩短代码。
- **运行时参数配置**：
  - **共享内存调整**：通过公式动态分配共享内存以对齐GPU占用率（`SharedMemorySize=maxSmemUsage/NUM_ATB−Constant`）。
- **硬件环境**：
  - GPU平台：NVIDIA 2080Ti和V100。
  - 对比方法：cuSPARSE、TVM-S、Sputnik、SparTA、EC-SpMM、cuBLAS。
- **性能指标**：
  - **编译时间**：对比各方法的搜索成本（LO-SpMM比SparTA节省超一个数量级）。
  - **执行性能**：以相对加速比和MAPE（平均绝对百分比误差<2.1%）衡量代理准确性。