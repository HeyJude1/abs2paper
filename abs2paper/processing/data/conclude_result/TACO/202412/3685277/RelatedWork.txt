相关工作总结：

1、现有方法一：SpMM Kernel for DNN Inference（稀疏矩阵-矩阵乘法核的优化）
核心思想:
- 主要优化方向分为三类：
  (1) Tiling（分块）：通过行分割（row-splitting）和基于合并（merge-based）策略改进数据重用和负载均衡，如AspT的自适应稀疏分块、Sputnik的多线程块处理单行、SparseRT的动态负载分配。
  (2) Reordering（重排序）：通过带宽缩减算法（对称矩阵）或图划分（非对称矩阵）提升数据局部性。
  (3) Extracting regular components（规则成分提取）：通过多面体框架挖掘规则子区域或子矩阵分类存储，减少间接寻址开销。

主要局限性:
- 现有分块策略对GPU架构的适应性不足，数据重用效率仍有提升空间。
- 重排序算法未充分考虑内核内存访问最小化与负载均衡的协同优化。
- 规则成分提取技术需要额外的存储开销和间接寻址，可能抵消性能收益。

2、现有方法二：Auto-tuning for SpMM Kernel（自动调优技术）
核心思想:
- 通用技术（如OpenTuner/KernelTuner）将调优视为黑盒全局优化，结合硬件信息缩小搜索空间。
- 深度学习领域专用技术（如TVM/Ansor）通过张量IR抽象算子，但缺乏硬件和算法先验知识利用。
- 稀疏算子编译器（如TACO/SparTA）基于抽象表示构建搜索空间，但需完整编译导致调优耗时。

主要局限性:
- 现有张量编译器无法有效利用硬件/算法先验知识，产生冗余搜索成本。
- 性能测量依赖完整代码编译，对优化后的SpMM核效率低下。

3、现有方法三：Proxy Program（代理程序）
核心思想:
- 通过部分执行、采样模拟或缩减数据集构建低成本代理程序（如PerfProx利用硬件计数器）。
- 目标是通过简化性能评估流程加速调优过程。

主要局限性:
- 通用代理合成方法不适用于GPU上SpMM的快速评估需求。
- 现有代理未针对SpMM内核实现的代码规模进行极致精简。

研究缺口：
1. SpMM核缺乏同时优化内存访问效率与负载均衡的分层分块策略。
2. 自动调优过程存在搜索空间过大和测量成本高的问题，需结合领域知识约束。
3. 缺少面向GPU稀疏计算的轻量化专用代理程序构建方法。