方法概述：
1、方法名称: MobiRL
2、核心思想: MobiRL是一种基于强化学习（RL）的智能CPU/GPU频率调度机制，旨在通过动态调整移动设备的处理器频率，同时优化UI流畅性和功耗。其核心思想是利用定制化的DDPG模型，从系统状态中学习最优频率调度策略，以解决传统启发式方法在动态负载下的频率欠供给或过供给问题。

3、主要流程/组件
组件/步骤一: 环境模块（Environment）
- 功能：模拟移动系统环境，包含系统监视器和频率控制器。系统监视器收集OS运行时状态（如CPU/GPU负载、温度、缓存命中率等），频率控制器执行并验证频率调整动作，通过修改CPUFreq/devfreq子系统的配置文件实现频率限制的动态调整。

组件/步骤二: 智能体模块（Agent）
- 功能：采用定制化的DDPG模型（Actor-Critic框架），包含四个神经网络（Actor、Critic及其目标网络）。Actor网络根据当前系统状态输出频率调度动作的概率分布，Critic网络评估动作的长期收益（Q值）。通过软更新机制（soft updating）稳定训练过程，输出层使用Softmax将连续动作空间转化为离散分类问题以加速收敛。

组件/步骤三: 状态与动作设计
- 状态：输入特征包括24维标准化参数（20个OS相关特征如CPU负载/IPC/频率限制，4个TOP-APP相关特征如进程缓存命中率）。
- 动作：定义17种离散调度动作（8个参数的升频/降频+空闲动作），通过算法选择最高概率动作，并约束频率上下限关系以避免无效配置。

组件/步骤四: 奖励函数（Reward）
- 功能：分段设计以平衡UI流畅性与功耗。当出现帧丢失时仅优化流畅性（惩罚渲染时间超限）；无帧丢失时优化功耗（奖励接近TDP下限）。最终奖励为当前与历史奖励的加权和。

组件/步骤五: 控制流程
- 学习阶段：在服务器端通过adb交互收集经验数据（状态-动作-奖励元组），使用经验回放更新模型。
- 预测阶段：在移动端部署简化版Actor网络，以低开销实时执行频率调度（6次/秒决策频率）。

关键创新点：
1. 将连续频率调度问题转化为离散分类任务，降低动作空间复杂度；
2. 通过离线采样剪枝无效频率配置保障系统可靠性；
3. 动态奖励机制实现多目标优化（流畅性优先于功耗）。