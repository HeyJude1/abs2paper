### 实验设计总结：

#### 1. 核心目标:
- **验证模型压缩技术的有效性**：通过权重剪枝（weight pruning）、通道剪枝（channel pruning）和数据量化（float16/int8）三种方法，评估其对模型精度和推理性能的影响。
- **比较不同卷积算法的性能**：在CPU和GPU上测试直接卷积（direct）、GEMM和空间打包卷积（spatial pack）三种算法的效率，包括密集（dense）和稀疏（sparse）版本。
- **评估跨硬件平台的适应性**：分析模型在Intel CPU、Arm CPU（HiKey 970）、Arm GPU（HiKey 970）和Nvidia GPU（Xavier）上的表现差异。

#### 2. 数据集:
- **CIFAR-10**：小型图像分类数据集，包含10类60,000张32x32图像。实验中训练了ResNet18、MobileNet V1/V2和VGG-16模型。
- **ImageNet**：大规模图像分类数据集，包含1,000类约120万张图像。实验中使用了预训练的DenseNet161、EfficientNetB0、ResNet50和MobileNetV2模型。

#### 3. 关键设置:
- **训练与微调**：
  - CIFAR-10模型：SGD优化器（动量0.9，权重衰减5×10⁻⁴），初始学习率5×10⁻²，使用1cycle学习率调度器，训练200 epoch；剪枝后微调210 epoch。
  - ImageNet模型：预训练模型来自TorchVision，微调140 epoch，初始学习率1×10⁻³，使用余弦退火学习率调度器。
- **剪枝策略**：
  - **权重剪枝**：从50%开始，逐步增加至95%和99%，每次剪枝后微调。
  - **通道剪枝**：从5%开始，逐步增加至99%，采用更细粒度的微调补偿粗粒度剪枝。
- **量化实现**：
  - float16量化直接通过TVM工具转换，无额外校准。
  - int8量化使用ONNXRuntime后训练校准工具恢复精度。
- **硬件与软件环境**：
  - CPU：Intel i7（AVX指令集）和HiKey 970 Arm A73核心；GPU：HiKey Mali-G72和Nvidia Xavier。
  - 编译器框架：Apache TVM v0.8.0，使用Ansor自动调度器优化卷积算法（20,000次变体搜索）。
  - GPU稀疏计算限制：因TVM不支持自动调度稀疏卷积的跨线程归约问题，仅能评估未调优的稀疏模型。

#### 结构化补充说明：
- **实验分阶段设计**：
  1. **精度分析**：确定每种压缩技术的“肘点”（压缩比与精度下降的平衡点）。
  2. **推理性能测试**：在未调优（baseline）和自动调优（tuned）两种模式下，测量不同硬件上的中位推理时间。
  3. **跨数据集对比**：CIFAR-10（过参数化明显）与ImageNet（更大规模任务）的结果差异分析。