相关工作总结：

1、现有方法一：轻量化模型设计（如MobileNets、YOLO等）
核心思想: 通过滤波器分解、专用卷积核等技术减少计算量，保持精度的同时降低模型复杂度。
主要局限性: 虽然减少了计算开销，但可能无法完全适应边缘设备的极端资源约束，且模型压缩后精度损失仍需优化。

2、现有方法二：模型压缩技术（参数量化/剪枝/知识蒸馏）
核心思想: 通过量化、剪枝（如DeepIoT）和知识蒸馏等方法压缩已有模型，Fast Exiting等技术利用早期层输出实现近似分类。
主要局限性: 各方法独立使用时存在精度-效率权衡问题，组合优化方法（如AdaDeep）的协同效果仍有提升空间。

3、现有方法三：分布式推理基础策略
核心思想: 
- 流水线执行：通过算子级分布形成处理流水线（Guo等采用遗传算法进行垂直划分）
- 并行执行：将模型划分为无重叠子模型（如DeepThings）或重叠数据通信（如CoEdge）
主要局限性: 
- DeepThings忽略设备异构性
- CoEdge的贪心算法易陷入局部最优
- EdgeFlow未充分考虑算子执行顺序的影响

4、现有方法四：基于DAG结构的优化
核心思想: 利用有向无环图组织计算依赖关系，代表性工作包括：
- IOS：动态规划实现阶段内算子并行
- HMCOS：层次化内存优化
- AGO：针对特定卷积算子的子图划分
- PEFT：异构设备任务调度
主要局限性:
- IOS的粗粒度优化难以扩展
- AGO仅支持有限卷积类型
- PEFT未充分挖掘任务划分潜力且内存优化不足

研究缺口总结：
1. 现有边缘部署方案缺乏对设备极端资源约束与模型完整性的统一考量
2. 分布式优化中贪心算法普遍存在局部最优问题，且对算子执行顺序敏感性研究不足
3. DAG优化方法在细粒度划分、通用算子支持和内存利用率方面存在明显局限