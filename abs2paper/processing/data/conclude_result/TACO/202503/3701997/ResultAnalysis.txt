### 实验结果分析总结：

#### 1、主要发现:  
- **内存优化（BTSearch）**：  
  - 在ResNet-50、InceptionV3、GoogLeNet、BERT和Qwen2等复杂模型中，BTSearch通过探索所有合法拓扑顺序，显著优于基线方法（Random、PEFT、Greedy）。  
  - 相比随机选择，BTSearch最高可减少12%的内存开销。对于分支结构较少的模型（如VGG13、GPT-2），所有方法表现相同。  
  - BTSearch的时间复杂度较高（O(N!)，N为算子数量），但实际优化时间仍可接受（毫秒级）。  

- **推理延迟优化（GenEFlow）**：  
  - 在无内存约束条件下，GenEFlow的推理延迟比CoEdge降低33.9%，尤其在复杂模型（如BERT、Qwen2）中表现突出。  
  - 对于小模型（如SqueezeNet），GenEFlow与CoEdge性能相近；但对EfficientNet-b0，DeepThings略优。  
  - GenEFlow通过遗传算法全局优化算子的分布式划分，显著减少跨设备通信量，但优化时间较长（1.7~36.4小时）。  

#### 2、消融研究结论:  
- **BTSearch的关键性**：  
  - BTSearch通过剪枝策略大幅减少无效拓扑顺序的搜索空间（如BERT/Qwen2剪枝量显著），从而提升效率。  
  - 分支结构复杂的模型（如InceptionV3）受益于拓扑顺序优化，而单链模型（如GPT-2）无需剪枝。  

- **GenEFlow的组件作用**：  
  - **遗传算法参数**：种群大小（250,000）、迭代次数（50）和收敛阈值（1e-6）直接影响搜索空间覆盖和局部最优避免。  
  - **分区策略**：按特征图高度、输出通道或长度划分算子时，全局优化比CoEdge的逐层优化更有效。  

#### 3、其他分析洞察:  
- **内存约束影响**：  
  - GenEFlow在严格内存限制下仍能通过动态调整算子分区满足需求，而CoEdge和DeepThings因固定阈值导致适应性不足。  

- **设备异构性分析**：  
  - **设备数量**：推理延迟在4台设备时最低，超过4台后通信开销抵消计算增益。  
  - **算力配置**：设备算力（CFLOPS）越低，VGG13/ResNet50的延迟下降越明显（如配置6/7降低30%以上）。  

- **真实环境验证**：  
  - GenEFlow在边缘设备上对InceptionV3、ResNet50等模型的推理延迟优化效果最优，平均优于Local、DeepThings和CoEdge。  

---  
**关键数据支撑**：  
- BTSearch在BERT/Qwen2中剪枝量达数千次，搜索空间缩减90%以上。  
- GenEFlow对GPT-2的搜索空间上界为10^18量级，远高于VGG13（10^6）。