"""
è®ºæ–‡ç« èŠ‚æ™ºèƒ½åŒ¹é…æ¨¡å—ï¼Œè´Ÿè´£ä½¿ç”¨LLMå°†è®ºæ–‡çš„å®é™…ç« èŠ‚æ ‡é¢˜æ˜ å°„åˆ°æ ‡å‡†ç« èŠ‚ç±»åˆ«
"""

import os
import json
import logging
import sys
import argparse
import re
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path

# å¯¼å…¥LLMå®¢æˆ·ç«¯å’Œæ—¥å¿—å·¥å…·
from abs2paper.utils.llm_client import LLMClient
from abs2paper.utils.log_utils import setup_dual_logging, update_markdown_saver_output_dir

# è®¾ç½®åŒé‡æ—¥å¿—ç³»ç»Ÿ
log_buffer, markdown_saver = setup_dual_logging()
logger = logging.getLogger(__name__)


class SectionMatcher:
    """è®ºæ–‡ç« èŠ‚æ™ºèƒ½åŒ¹é…å™¨ï¼Œä½¿ç”¨LLMè¿›è¡Œç« èŠ‚æ ‡é¢˜åˆ°æ ‡å‡†ç±»åˆ«çš„æ˜ å°„"""
    
    # æ ‡å‡†ç« èŠ‚ç±»åˆ«åˆ—è¡¨
    STANDARD_SECTIONS = ["å¼•è¨€", "ç›¸å…³å·¥ä½œ", "æ–¹æ³•", "å®éªŒè¯„ä»·", "æ€»ç»“"]
    
    def __init__(self, force_overwrite=False):
        """åˆå§‹åŒ–ç« èŠ‚åŒ¹é…å™¨"""
        self.force_overwrite = force_overwrite
        
        # ç¡®å®šé¡¹ç›®æ ¹ç›®å½•
        module_dir = os.path.dirname(os.path.abspath(__file__))
        self.project_root = os.path.dirname(os.path.dirname(module_dir))
        
        # åŠ è½½é…ç½®æ–‡ä»¶
        config_path = os.path.join(self.project_root, "config", "config.json")
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
            logger.info(f"å·²åŠ è½½é…ç½®: {config_path}")
        
        # åˆ›å»ºLLMå®¢æˆ·ç«¯
        self.llm_client = LLMClient()
        
        # è·å–è·¯å¾„é…ç½®
        data_paths = self.config["data_paths"]
        component_extract_path = data_paths["component_extract"]["path"].lstrip('/')
        section_prompt_path = data_paths["section_prompt"]["path"].lstrip('/')
        
        # è®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„
        self.input_dir = os.path.join(self.project_root, component_extract_path)
        self.section_prompt_dir = os.path.join(self.project_root, section_prompt_path)
        self.section_match_dir = os.path.join(self.project_root, "abs2paper", "processing", "data", "section_match")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.section_match_dir, exist_ok=True)
        
        # æ›´æ–°markdownä¿å­˜å™¨çš„è¾“å‡ºç›®å½•
        update_markdown_saver_output_dir(markdown_saver, self.section_match_dir)
        
        logger.info(f"ğŸ“‚ è¾“å…¥ç›®å½•: {self.input_dir}")
        logger.info(f"ğŸ“‚ æç¤ºè¯ç›®å½•: {self.section_prompt_dir}")
        logger.info(f"ğŸ“‚ è¾“å‡ºç›®å½•: {self.section_match_dir}")
        
        # åŠ è½½ç« èŠ‚åŒ¹é…æç¤ºè¯
        self.section_prompt = self._load_section_prompt()
    
    def _load_section_prompt(self) -> str:
        """
        åŠ è½½ç« èŠ‚åŒ¹é…æç¤ºè¯
        
        Returns:
            section_prompt: ç« èŠ‚åŒ¹é…æç¤ºè¯
        """
        prompt_file = os.path.join(self.section_prompt_dir, "section_prompt")
        
        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                prompt_content = f.read().strip()
                logger.info(f"âœ… å·²åŠ è½½ç« èŠ‚åŒ¹é…æç¤ºè¯: {prompt_file}")
                return prompt_content
        except FileNotFoundError:
            logger.error(f"âŒ æœªæ‰¾åˆ°ç« èŠ‚åŒ¹é…æç¤ºè¯æ–‡ä»¶: {prompt_file}")
            raise
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ç« èŠ‚åŒ¹é…æç¤ºè¯æ—¶å‡ºé”™: {e}")
            raise
    
    def _extract_section_titles(self, paper_dir: str) -> List[str]:
        """
        ä»è®ºæ–‡ç›®å½•ä¸­æå–æ‰€æœ‰ç« èŠ‚æ ‡é¢˜
        
        Args:
            paper_dir: è®ºæ–‡ç›®å½•è·¯å¾„
            
        Returns:
            section_titles: ç« èŠ‚æ ‡é¢˜åˆ—è¡¨
        """
        section_titles = []
        
        if not os.path.exists(paper_dir):
            logger.warning(f"âš ï¸ è®ºæ–‡ç›®å½•ä¸å­˜åœ¨: {paper_dir}")
            return section_titles
        
        # éå†è®ºæ–‡ç›®å½•ä¸­çš„æ‰€æœ‰txtæ–‡ä»¶
        for filename in os.listdir(paper_dir):
            if filename.endswith('.txt'):
                # ä»æ–‡ä»¶åä¸­æå–ç« èŠ‚æ ‡é¢˜ï¼ˆå»æ‰.txtåç¼€ï¼‰
                section_title = filename[:-4]
                section_titles.append(section_title)
        
        logger.debug(f"ğŸ“„ æå–åˆ° {len(section_titles)} ä¸ªç« èŠ‚æ ‡é¢˜")
        return section_titles
    
    def _match_sections_with_llm(self, section_titles: List[str]) -> Dict[str, str]:
        """
        ä½¿ç”¨LLMåŒ¹é…ç« èŠ‚æ ‡é¢˜åˆ°æ ‡å‡†ç±»åˆ«
        
        Args:
            section_titles: ç« èŠ‚æ ‡é¢˜åˆ—è¡¨
            
        Returns:
            section_mapping: ç« èŠ‚æ˜ å°„å­—å…¸ {ç« èŠ‚æ ‡é¢˜: æ ‡å‡†ç±»åˆ«}
        """
        if not section_titles:
            logger.warning("âš ï¸ æ²¡æœ‰ç« èŠ‚æ ‡é¢˜éœ€è¦åŒ¹é…")
            return {}
        
        # æ„å»ºå®Œæ•´æç¤ºè¯
        titles_text = "\n".join(section_titles)
        full_prompt = f"{self.section_prompt}\n\n{titles_text}"
        
        # è°ƒç”¨LLM
        logger.info(f"ğŸ”„ æ­£åœ¨ä½¿ç”¨LLMåŒ¹é… {len(section_titles)} ä¸ªç« èŠ‚æ ‡é¢˜")
        try:
            response = self.llm_client.get_completion(full_prompt)
            
            if response:
                logger.info(f"âœ… LLMç« èŠ‚åŒ¹é…å®Œæˆ")
                return self._parse_llm_response(response, section_titles)
            else:
                logger.error(f"âŒ LLMç« èŠ‚åŒ¹é…å¤±è´¥ï¼šè¿”å›ç©ºç»“æœ")
                return {}
                
        except Exception as e:
            logger.error(f"âŒ LLMç« èŠ‚åŒ¹é…æ—¶å‡ºé”™: {e}")
            return {}
    
    def _parse_llm_response(self, response: str, section_titles: List[str]) -> Dict[str, str]:
        """
        è§£æLLMå“åº”ï¼Œæå–ç« èŠ‚æ˜ å°„å…³ç³»
        
        Args:
            response: LLMå“åº”æ–‡æœ¬
            section_titles: åŸå§‹ç« èŠ‚æ ‡é¢˜åˆ—è¡¨
            
        Returns:
            section_mapping: ç« èŠ‚æ˜ å°„å­—å…¸
        """
        section_mapping = {}
        
        # è§£æå“åº”ä¸­çš„æ˜ å°„å…³ç³»
        for line in response.split('\n'):
            line = line.strip()
            if not line or '->' not in line:
                continue
            
            try:
                # åˆ†å‰²ç« èŠ‚æ ‡é¢˜å’Œæ ‡å‡†ç±»åˆ«
                parts = line.split('->')
                if len(parts) == 2:
                    section_title = parts[0].strip()
                    standard_section = parts[1].strip()
                    
                    # éªŒè¯æ ‡å‡†ç±»åˆ«æ˜¯å¦æœ‰æ•ˆ
                    if standard_section in self.STANDARD_SECTIONS:
                        section_mapping[section_title] = standard_section
                        logger.debug(f"ğŸ“ åŒ¹é…: {section_title} -> {standard_section}")
                    else:
                        logger.warning(f"âš ï¸ æœªçŸ¥çš„æ ‡å‡†ç±»åˆ«: {standard_section}ï¼Œå°† {section_title} å½’ç±»ä¸º'æ–¹æ³•'")
                        section_mapping[section_title] = "æ–¹æ³•"
            
            except Exception as e:
                logger.error(f"âŒ è§£ææ˜ å°„è¡Œæ—¶å‡ºé”™: {line}, é”™è¯¯: {e}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é—æ¼çš„ç« èŠ‚æ ‡é¢˜ï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„
        for title in section_titles:
            if title not in section_mapping:
                logger.warning(f"âš ï¸ ç« èŠ‚ '{title}' æœªåœ¨LLMå“åº”ä¸­æ‰¾åˆ°åŒ¹é…ï¼Œé»˜è®¤å½’ç±»ä¸º'æ–¹æ³•'")
                section_mapping[title] = "æ–¹æ³•"
        
        logger.info(f"ğŸ“Š æˆåŠŸåŒ¹é… {len(section_mapping)} ä¸ªç« èŠ‚æ ‡é¢˜")
        return section_mapping
    
    # def _create_fallback_mapping(self, section_titles: List[str]) -> Dict[str, str]:
    #     """
    #     åˆ›å»ºå¤‡ç”¨æ˜ å°„ï¼ˆå½“LLMå¤±è´¥æ—¶ä½¿ç”¨ï¼‰
    #     
    #     Args:
    #         section_titles: ç« èŠ‚æ ‡é¢˜åˆ—è¡¨
    #         
    #     Returns:
    #         section_mapping: å¤‡ç”¨ç« èŠ‚æ˜ å°„å­—å…¸
    #     """
    #     logger.warning("âš ï¸ ä½¿ç”¨å¤‡ç”¨ç« èŠ‚æ˜ å°„ç­–ç•¥")
    #     section_mapping = {}
    #     
    #     for title in section_titles:
    #         # ç®€å•çš„å…³é”®è¯åŒ¹é…ä½œä¸ºå¤‡ç”¨
    #         title_lower = title.lower()
    #         
    #         if any(keyword in title_lower for keyword in ['introduction', 'background', 'preliminary']):
    #             section_mapping[title] = "å¼•è¨€"
    #         elif any(keyword in title_lower for keyword in ['related', 'literature', 'survey']):
    #             section_mapping[title] = "ç›¸å…³å·¥ä½œ"
    #         elif any(keyword in title_lower for keyword in ['evaluation', 'experiment', 'result', 'performance']):
    #             section_mapping[title] = "å®éªŒè¯„ä»·"
    #         elif any(keyword in title_lower for keyword in ['conclusion', 'discussion', 'future']):
    #             section_mapping[title] = "æ€»ç»“"
    #         else:
    #             section_mapping[title] = "æ–¹æ³•"  # é»˜è®¤åˆ†ç±»
    #     
    #     return section_mapping
    
    def _should_process_paper(self, paper_rel_path: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥å¤„ç†è¯¥è®ºæ–‡
        
        Args:
            paper_rel_path: è®ºæ–‡ç›¸å¯¹è·¯å¾„
            
        Returns:
            æ˜¯å¦åº”è¯¥å¤„ç†è¯¥è®ºæ–‡
        """
        # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡
        output_dir = os.path.join(self.section_match_dir, paper_rel_path)
        mapping_file = os.path.join(output_dir, "section_mapping.json")
        
        if not os.path.exists(mapping_file):
            # æ²¡æœ‰ç»“æœæ–‡ä»¶ï¼Œéœ€è¦å¤„ç†
            return True
        
        # æœ‰ç»“æœæ–‡ä»¶ï¼Œæ ¹æ®å¼ºåˆ¶æ¨¡å¼åˆ¤æ–­
        if self.force_overwrite:
            logger.info(f"ğŸ”„ å¼ºåˆ¶æ¨¡å¼ï¼šé‡æ–°ç”Ÿæˆ {paper_rel_path}")
            return True
        else:
            logger.info(f"â­ï¸ è·³è¿‡å·²å­˜åœ¨ç»“æœ: {paper_rel_path}")
            return False
    
    def match_paper_sections(self, paper_path: str) -> Dict[str, str]:
        """
        åŒ¹é…å•ç¯‡è®ºæ–‡çš„ç« èŠ‚
        
        Args:
            paper_path: è®ºæ–‡ç›®å½•è·¯å¾„
            
        Returns:
            section_mapping: ç« èŠ‚æ˜ å°„å­—å…¸
        """
        # æå–ç« èŠ‚æ ‡é¢˜
        section_titles = self._extract_section_titles(paper_path)
        
        if not section_titles:
            logger.error(f"âŒ æ— æ³•ä»è®ºæ–‡ç›®å½•ä¸­æå–ç« èŠ‚æ ‡é¢˜: {paper_path}")
            return {}
        
        # ä½¿ç”¨LLMè¿›è¡ŒåŒ¹é…
        section_mapping = self._match_sections_with_llm(section_titles)
        
        return section_mapping
    
    def save_section_mapping(self, section_mapping: Dict[str, str], paper_rel_path: str) -> bool:
        """
        ä¿å­˜ç« èŠ‚æ˜ å°„ç»“æœ
        
        Args:
            section_mapping: ç« èŠ‚æ˜ å°„å­—å…¸
            paper_rel_path: è®ºæ–‡ç›¸å¯¹è·¯å¾„ï¼ˆå¦‚ "ICS/2023/paper_name"ï¼‰
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
            output_dir = os.path.join(self.section_match_dir, paper_rel_path)
            os.makedirs(output_dir, exist_ok=True)
            
            # ä¿å­˜ç« èŠ‚æ˜ å°„ç»“æœä¸ºJSONæ–‡ä»¶
            mapping_file = os.path.join(output_dir, "section_mapping.json")
            with open(mapping_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "paper_path": paper_rel_path,
                    "section_mapping": section_mapping,
                    "standard_sections": self.STANDARD_SECTIONS,
                    "total_sections": len(section_mapping)
                }, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ“ ç« èŠ‚æ˜ å°„å·²ä¿å­˜è‡³: {mapping_file}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç« èŠ‚æ˜ å°„æ—¶å‡ºé”™: {e}")
            return False
    
    def process_directory(self, rel_path: str = "") -> Tuple[int, int]:
        """
        å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰è®ºæ–‡
        
        Args:
            rel_path: ç›¸å¯¹è·¯å¾„ï¼Œç”¨äºä¿æŒç›®å½•ç»“æ„
            
        Returns:
            (success_count, total_count): æˆåŠŸå¤„ç†çš„è®ºæ–‡æ•°å’Œæ€»è®ºæ–‡æ•°
        """
        success_count = 0
        total_count = 0
        
        # å®Œæ•´çš„è¾“å…¥ç›®å½•è·¯å¾„
        input_dir = self.input_dir
        if rel_path:
            input_dir = os.path.join(input_dir, rel_path)
        
        if not os.path.exists(input_dir):
            logger.warning(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            return success_count, total_count
        
        # éå†ç›®å½•
        for item in os.listdir(input_dir):
            item_path = os.path.join(input_dir, item)
            
            # å¦‚æœæ˜¯ç›®å½•
            if os.path.isdir(item_path):
                # æ£€æŸ¥æ˜¯å¦æ˜¯è®ºæ–‡ç›®å½•ï¼ˆåŒ…å«.txtæ–‡ä»¶ï¼‰
                txt_files = [f for f in os.listdir(item_path) if f.endswith('.txt')]
                
                if txt_files:
                    # è¿™æ˜¯ä¸€ä¸ªè®ºæ–‡ç›®å½•
                    total_count += 1
                    paper_rel_path = os.path.join(rel_path, item) if rel_path else item
                    
                    logger.info(f"ğŸ” å¤„ç†è®ºæ–‡: {paper_rel_path}")
                    
                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥å¤„ç†è¯¥è®ºæ–‡
                    if self._should_process_paper(paper_rel_path):
                        # åŒ¹é…è®ºæ–‡ç« èŠ‚
                        section_mapping = self.match_paper_sections(item_path)
                        
                        if section_mapping:
                            # ä¿å­˜ç»“æœ
                            if self.save_section_mapping(section_mapping, paper_rel_path):
                                success_count += 1
                            else:
                                logger.error(f"âŒ ä¿å­˜ç« èŠ‚æ˜ å°„å¤±è´¥: {paper_rel_path}")
                        else:
                            logger.error(f"âŒ ç« èŠ‚åŒ¹é…å¤±è´¥: {paper_rel_path}")
                    else:
                        # å¦‚æœè·³è¿‡ï¼Œåˆ™è®¡å…¥æˆåŠŸå¤„ç†
                        success_count += 1
                        logger.info(f"â­ï¸ è·³è¿‡å·²å­˜åœ¨ç»“æœ: {paper_rel_path}")
                
                else:
                    # è¿™æ˜¯ä¸€ä¸ªä¸­é—´ç›®å½•ï¼Œé€’å½’å¤„ç†
                    new_rel_path = os.path.join(rel_path, item) if rel_path else item
                    sub_success, sub_total = self.process_directory(new_rel_path)
                    success_count += sub_success
                    total_count += sub_total
        
        return success_count, total_count
    
    def match_all_papers(self) -> bool:
        """
        å¤„ç†æ‰€æœ‰è®ºæ–‡å¹¶ç”Ÿæˆç« èŠ‚æ˜ å°„
        
        Returns:
            å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info(f"ğŸš€ å¼€å§‹å¤„ç†æ‰€æœ‰è®ºæ–‡ï¼Œæºç›®å½•: {self.input_dir}")
            if self.force_overwrite:
                logger.info(f"ğŸ”„ å¼ºåˆ¶æ¨¡å¼ï¼šå°†é‡æ–°ç”Ÿæˆæ‰€æœ‰è®ºæ–‡çš„ç« èŠ‚åŒ¹é…ç»“æœ")
            else:
                logger.info(f"â­ï¸ é»˜è®¤æ¨¡å¼ï¼šå°†è·³è¿‡å·²å­˜åœ¨çš„ç»“æœï¼Œåªå¤„ç†æ–°è®ºæ–‡")
            
            # æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨
            if not os.path.exists(self.input_dir):
                logger.error(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {self.input_dir}")
                return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æç¤ºè¯
            if not self.section_prompt:
                logger.error(f"âŒ æœªåŠ è½½ç« èŠ‚åŒ¹é…æç¤ºè¯")
                return False
            
            # å¤„ç†æ‰€æœ‰è®ºæ–‡
            success_count, total_count = self.process_directory()
            
            logger.info(f"ğŸ‰ å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {success_count}/{total_count} ç¯‡è®ºæ–‡")
            logger.info(f"ğŸ“ ç»“æœå·²ä¿å­˜è‡³: {self.section_match_dir}")
            
            # ä¿å­˜å¤„ç†æ—¥å¿—åˆ°markdownæ–‡ä»¶
            config_info = {
                "è¾“å…¥ç›®å½•": self.input_dir,
                "æç¤ºè¯ç›®å½•": self.section_prompt_dir,
                "è¾“å‡ºç›®å½•": self.section_match_dir,
                "æ ‡å‡†ç« èŠ‚ç±»åˆ«": self.STANDARD_SECTIONS
            }
            summary_info = f"å¤„ç†å®Œæˆï¼ŒæˆåŠŸå¤„ç† {success_count}/{total_count} ç¯‡è®ºæ–‡ã€‚è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹ `{self.section_match_dir}` ç›®å½•ä¸‹çš„å„è®ºæ–‡ç« èŠ‚æ˜ å°„æ–‡ä»¶ã€‚"
            
            markdown_saver.save_log_to_markdown(
                title="è®ºæ–‡ç« èŠ‚æ™ºèƒ½åŒ¹é…å¤„ç†æ—¥å¿—",
                config_info=config_info,
                summary_info=summary_info
            )
            
            return success_count > 0
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†è®ºæ–‡ç« èŠ‚åŒ¹é…æ—¶å‡ºç°ä¸¥é‡é”™è¯¯: {e}")
            import traceback
            logger.error(traceback.format_exc())
            # å³ä½¿å‡ºé”™ä¹Ÿå°è¯•ä¿å­˜æ—¥å¿—
            config_info = {
                "è¾“å…¥ç›®å½•": getattr(self, 'input_dir', 'æœªçŸ¥'),
                "æç¤ºè¯ç›®å½•": getattr(self, 'section_prompt_dir', 'æœªçŸ¥'),
                "è¾“å‡ºç›®å½•": getattr(self, 'section_match_dir', 'æœªçŸ¥')
            }
            summary_info = f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}"
            
            markdown_saver.save_log_to_markdown(
                title="è®ºæ–‡ç« èŠ‚æ™ºèƒ½åŒ¹é…å¤„ç†æ—¥å¿—ï¼ˆé”™è¯¯ï¼‰",
                config_info=config_info,
                summary_info=summary_info
            )
            return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ™ºèƒ½åŒ¹é…è®ºæ–‡ç« èŠ‚æ ‡é¢˜åˆ°æ ‡å‡†ç±»åˆ«")
    parser.add_argument("--input_dir", type=str, help="è¾“å…¥ç›®å½•ï¼Œè¦†ç›–é»˜è®¤çš„component_extractè·¯å¾„")
    parser.add_argument("--output_dir", type=str, help="è¾“å‡ºç›®å½•ï¼Œè¦†ç›–é»˜è®¤çš„section_matchè·¯å¾„")
    
    args = parser.parse_args()
    
    # åˆ›å»ºç« èŠ‚åŒ¹é…å™¨
    matcher = SectionMatcher()
    
    # å¦‚æœæä¾›äº†è‡ªå®šä¹‰è·¯å¾„ï¼Œåˆ™æ›´æ–°
    if args.input_dir:
        matcher.input_dir = os.path.abspath(args.input_dir)
        logger.info(f"ä½¿ç”¨è‡ªå®šä¹‰è¾“å…¥ç›®å½•: {matcher.input_dir}")
    
    if args.output_dir:
        matcher.section_match_dir = os.path.abspath(args.output_dir)
        os.makedirs(matcher.section_match_dir, exist_ok=True)
        logger.info(f"ä½¿ç”¨è‡ªå®šä¹‰è¾“å‡ºç›®å½•: {matcher.section_match_dir}")
    
    # æ‰§è¡Œç« èŠ‚åŒ¹é…
    success = matcher.match_all_papers()
    
    # æ ¹æ®æ‰§è¡Œç»“æœè®¾ç½®é€€å‡ºç 
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main() 