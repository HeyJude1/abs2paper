相关工作总结：

1、现有方法一：基于内积的稀疏矩阵乘法加速器（如ALRESCHA、AS-CELLA）  
核心思想: 采用自定义存储格式解决索引匹配问题，支持输入流式处理。  
主要局限性: 未利用列向乘积（column-wise product）的优势，数据流灵活性不足。

2、现有方法二：基于外积的稀疏矩阵乘法加速器（如OuterSPACE、SpArch）  
核心思想: 通过序列化乘法和合并阶段实现外积计算，SpArch进一步采用压缩矩阵表示和Huffman树调度器提升输出复用。  
主要局限性: 未针对操作数间显著不同的稀疏度进行优化，在SpMM任务上性能提升有限。

3、现有方法三：基于行向数据流的加速器（如MatRaptor、InnerSP）  
核心思想: 通过定制存储格式实现流式处理（MatRaptor）或使用片上哈希表缓解内存膨胀（InnerSP）。  
主要局限性: 同样未充分利用列向计算潜力，且动态适应性不足。

4、现有方法四：通用稀疏张量计算架构（如Tensaurus）  
核心思想: 基于内积的SF3模式支持多种稀疏-稠密张量计算。  
主要局限性: 单一数据流难以适应不同计算问题的特性变化，未考虑操作数稀疏度差异。

5、现有方法五：混合数据流框架  
核心思想: 集成内积/外积/行向数据流，根据输入特征动态匹配最优数据流。  
主要局限性: 仍缺乏对双操作数极端稀疏度差异的专门优化。

6、现有方法六：领域专用加速设计（如GoSPA、SpAtten）  
核心思想: 针对特定神经网络计算（如CNN卷积、注意力机制）优化稀疏模式。  
主要局限性: 领域特异性强，难以泛化到通用SpMM任务。

7、现有方法七：软件预处理技术  
核心思想: 通过重排序算法（GAMMA）、非零调度（Sextans）、矩阵分块/定制存储格式等提升硬件效率。  
主要局限性: 现有方案多局限于特定硬件架构或稀疏模式（如注意力修剪），缺乏系统性协同设计。

研究缺口总结：
1. **数据流灵活性不足**：现有工作未能同时利用行向和列向计算优势；
2. **稀疏度适应性缺陷**：对双操作数极端稀疏度差异场景缺乏专门优化；
3. **协同设计不充分**：软件预处理与硬件架构的深度协同不足，限制性能上限；
4. **领域泛化能力弱**：神经网络专用方案难以迁移到通用SpMM任务。