实验结果分析总结：

1、主要发现:
- 在2080Ti和V100 GPU上，LO-SpMM相比现有解决方案展现出显著优势：
  - 2080Ti：比cuSPARSE快37.75倍，比TVM-S快35.24倍，比cuBLAS快3.32倍，比Sputnik快3.43倍，比SparTA快1.10倍，比EC-SpMM快1.06倍
  - V100：比cuSPARSE快31.65倍，比TVM-S快23.40倍，比cuBLAS快3.30倍，比Sputnik快2.56倍，比SparTA快1.09倍
- 与最先进的SparTA相比：
  - 2080Ti：93.66%的kernel达到至少95%相对性能，79.02%表现更优
  - V100：82.43%的kernel达到至少95%相对性能，69.27%表现更优
- 在高稀疏度场景下表现更优（稀疏矩阵重排序效果更显著）

2、消融研究结论:
- 代理方法（Proxy）的关键组件验证：
  a) Kernel函数简化：通过参数化tile size减少编译次数（单次编译评估多种tile size）
  b) 线程块函数聚类：基于内存访问和浮点操作特征进行聚类（欧氏距离度量），将N个线程块函数减少到N_P个代理函数
  c) 循环块截断：通过保留代表性迭代（N_NC_P次）缩短代码长度
- 代理有效性验证：性能损失<2.1%（MAPE指标），同时显著降低搜索成本

3、其他分析洞察:
- 编译时间优化：
  - LO-SpMM-Rank相比EC-SpMM在V100上实现18倍搜索成本降低
  - 代理方法使编译时间增长趋势更平缓（对非零元素数量增加不敏感）
  
- GPU资源利用分析：
  通过共享内存配置调整（公式5-6）对齐代理与原实现的occupancy指标，确保性能排序可靠性

- 端到端推理验证：
  - BERT模型：相比TensorRT加速1.84倍，相比SparTA加速1.34倍
  - ResNet50模型：与SparTA/EC-SpMM性能相当（因非空行较少限制了重排序收益）

- 参数敏感性：
  代理精度关键参数经实验确定：
  - 线程块函数聚类数=3×max(NUMS_ATB)
  - N_NC_P=min(N_NC,300/(1-sparsity))