相关工作总结：

1. 现有方法一：简化设计空间探索方法
核心思想: 通过减少DLAS（Deep Learning Acceleration Stack）中探索的参数数量或固定某些层参数，来降低设计空间复杂度。
主要局限性: 
- 忽略压缩技术或算法的影响（如Hadidi et al.）
- 过度依赖特定编译器框架和加速器（如VTA），缺乏通用性
- 无法捕捉跨堆栈层的交互效应

2. 现有方法二：DNN加速参数综述研究
核心思想: 全面梳理DNN加速相关参数（如Sze et al.）
主要局限性:
- 缺乏将复杂参数体系转化为简洁结构的框架
- 未提供有效的设计空间探索方法论
- 对NP-hard优化问题仅提供原则性启发式方法

3. 现有方法三：单一优化技术研究
核心思想: 针对特定技术（如剪枝、量化）进行独立优化：
(3.1) 剪枝技术：
核心思想: 通过权重剪枝/通道剪枝减少模型复杂度
局限性:
- 稀疏计算在GPU上效率低下（因不规则数据访问）
- 重训练成本被低估（Blalock et al.指出）
- 实际速度提升常低于预期（仅达预期30%）

(3.2) 量化技术：
核心思想: 降低数据精度（float16/int8）以加速计算
局限性:
- int8在EfficientNet等新型架构上准确率骤降（需架构修改如EfficientNet-Lite）
- float16在CPU上因软件模拟导致减速
- Ansor等编译器对int8优化支持不足

4. 现有方法四：算法优化研究
核心思想: 探索不同卷积算法（GEMM/direct/spatial-pack）的性能差异
局限性:
- TVM中GEMM实现未使用优化BLAS库
- Winograd等潜在高效算法未被探索
- 层间数据格式转换开销未被充分考虑

5. 现有方法五：自动调优系统
核心思想: 使用TVM/Ansor等工具自动优化计算图
局限性:
- Xavier GPU存在软件栈兼容性问题
- HiKey设备上调优时间过长（>140小时/模型）
- tensor core等硬件特性利用不足

研究缺口总结：
1. 跨堆栈交互效应：现有工作未能系统建模DLAS各层参数间的非线性交互作用
2. 可扩展性挑战：设计空间随参数增加呈指数增长，缺乏高效探索方法
3. 新型硬件适配：对异构计算单元（tensor core/big.LITTLE）的协同利用不足
4. 评估方法论缺陷：批量大小、预热周期等实验设置与实际部署场景存在偏差