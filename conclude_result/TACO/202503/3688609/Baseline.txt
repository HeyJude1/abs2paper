### Baseline选取总结：

1. **对比方法**:
   - **ResNet18**
   - **MobileNet V1**
   - **MobileNet V2**
   - **VGG-16** (CIFAR-10数据集)
   - **DenseNet161**
   - **EfficientNetB0**
   - **ResNet50** (ImageNet数据集)

2. **选取理由**:
   - **技术路线覆盖性**: 选择的模型涵盖了不同的神经网络架构设计路线（如残差连接、深度可分离卷积、密集连接等），能够代表主流的图像分类模型技术。
     - *经典大型模型*: ResNet18/VGG-16（CIFAR-10）和ResNet50/DenseNet161（ImageNet）作为参数较多的基准。
     - *轻量化模型*: MobileNet V1/V2和EfficientNetB0作为资源高效型设计的代表。
   - **SOTA与经典结合**: 
     - 包含长期广泛验证的经典架构（如VGG、ResNet）
     - 也纳入新型高效架构（如EfficientNetB0，作者特别指出其虽参数少但精度高）
   - **跨数据集适配性**:
     - CIFAR-10选用较小模型（如ResNet18）
     - ImageNet选用更大规模模型（如ResNet50）
   - **压缩敏感性分析需求**:
     作者明确说明选择不同规模模型是为了观察压缩技术对参数量差异模型的差异化影响（如5.1.1节指出MobileNets因参数少对剪枝更敏感）

补充说明：论文虽然没有显式列出"baseline"标题，但通过实验设计可以看出这些模型是作为未压缩的基准模型（dense models）与其他优化技术对比，例如：
- 表3/4中报告的"dense"精度作为基准值
- 图4/5中所有优化技术的性能均与原始模型对比
- 第5章多次提到"baseline (dense) top-1 accuracy"的对比