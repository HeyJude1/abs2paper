实验结果分析总结：

1、主要发现:  
- **CIFAR-10**：  
  - **权重剪枝（Weight Pruning）**：所有模型在剪枝率95%前均能保持准确率，99%时出现显著下降（MobileNetV1/V2下降更明显）。  
  - **通道剪枝（Channel Pruning）**：准确率下降更早（MobileNet在50%、VGG-16/ResNet18在80%时出现拐点），且下降幅度更大（最低至10%）。  
  - **量化**：float16几乎无精度损失；int8未校准时精度显著下降（MobileNetV1/V2降至10.0%/16.4%），校准后恢复至损失1.7%以内。  
  - **推理性能**：  
    - **CPU（未调优）**：i7上int8最快（3/4模型），HiKey上权重剪枝最快（3/4模型）；实际加速仅为理论预期的11.5%-21.8%（权重剪枝）和77.9%-83.9%（通道剪枝）。  
    - **GPU（未调优）**：HiKey GPU比CPU慢7倍；空间打包（spatial pack）在剪枝模型中表现最佳，但加速有限（权重剪枝仅达理论7.4%/2.2%）。  

- **ImageNet**：  
  - 小模型（EfficientNetB0/MobileNetV2）比大模型（DenseNet161/ResNet50）更早出现精度下降。  
  - int8量化中，MobileNetV2和EfficientNetB0校准后仍损失6.6%/0.43%精度，显示架构对量化敏感。  
  - **CPU推理**：通道剪枝在HiKey/i7上分别达到理论加速的60.2%/84.2%，优于CIFAR-10。  

2、消融研究结论:  
- **剪枝策略对比**：权重剪枝在高压缩比下更鲁棒，但通道剪枝实际加速效率更高（尤其在CPU上）。例如，CIFAR-10中通道剪枝达到理论加速的77.9%-83.9%，而权重剪枝仅11.5%-21.8%。  
- **算法选择关键性**：  
  - CPU上，GEMM算法在未调优时普遍最快；调优后空间打包成为密集模型最佳选择。  
  - GPU上，空间打包对稀疏模型表现最优，但受限于TVM对稀疏计算的支持不足。  

3、其他分析洞察:  
- **硬件依赖性**：i7 CPU的int8量化加速显著优于HiKey ARM CPU（157.2% vs 33.6%理论加速），凸显硬件优化差异。  
- **软件限制**：TVM无法在GPU上自动调度稀疏计算，导致权重/通道剪枝的潜在性能未充分释放。例如，Xavier GPU上稀疏直接卷积因内存问题无法完成。  
- **案例异常**：ImageNet的EfficientNetB0在int8量化后精度仅恢复至0.43%，作者归因于模型架构的量化不适应性（如深度可分离卷积）。  

关键结论：跨栈优化需协同设计，现有工具链（如TVM）对稀疏性和硬件特性的支持不足限制了理论性能的实现。