问题背景总结：  
1、研究领域: 机器学习系统与编译器技术（具体聚焦于经典机器学习模型的编译优化与跨平台部署）  

2、核心问题: 如何通过统一抽象和编译器设计，解决经典机器学习（CML）模型在跨硬件部署时面临的移植性差、性能低下问题，使其能复用深度学习（DL）生态的成熟编译框架。  

3、研究动机:  
- **理论价值**：现有CML框架缺乏统一抽象，导致模型移植需重复开发硬件适配代码（数千行/模型），且无法系统性优化多核/SIMD等现代硬件特性。  
- **实践价值**：CML占实际生产ML管道的40%（如Google数据），但其在GPU/FPGA/IoT等设备上的支持不足，制约混合部署（CML+DL）的效率和规模应用。  

4、潜在应用:  
- 在线服务系统的低延迟推理（如推荐系统特征处理）  
- 资源受限设备的实时ML应用（如物联网终端决策树推理）  
- 异构硬件平台上的混合ML工作流加速