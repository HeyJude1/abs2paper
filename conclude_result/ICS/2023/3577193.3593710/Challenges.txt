### 核心挑战总结：

#### 挑战一：**CML模型的抽象化与统一表示困难**  
**分析**:  
- **具体内容**: 经典机器学习（CML）模型（如决策树、随机森林）与深度学习（DL）模型在算子类型和模型结构上存在本质差异。DL依赖于张量运算和计算图抽象，而CML涉及标量、数组、表格等非结构化数据，且包含条件分支（如if语句），难以直接映射到DL的现有抽象（如计算图）。  
- **根源**:  
  1. **问题复杂性**: CML模型的异构性（多样化的算子和控制流）与DL的规则化结构（序列化张量操作）不兼容。  
  2. **技术瓶颈**: 现有DL编译器的抽象层（如TVM的计算图）无法原生支持CML的非神经网络结构。  

#### 挑战二：**CML框架的移植性与性能缺陷**  
**分析**:  
- **具体内容**: 当前CML框架（如Scikit-learn、Spark MLlib）多为CPU定制，缺乏跨硬件（GPU/FPGA/IoT）的统一支持，且优化技术落后（如未利用多核/SIMD指令）。混合部署CML与DL时，性能问题进一步加剧。  
- **根源**:  
  1. **技术瓶颈**: CML生态缺乏类似DL编译器的通用中间表示，导致硬件适配需逐模型逐设备开发（高代码冗余）。  
  2. **资源限制**: 为每个模型-硬件组合开发高性能库成本过高，尤其对长尾设备（如边缘端FPGA）。  

#### 挑战三：**现有混合部署方案的局限性**  
**分析**:  
- **具体内容**: 基于DL框架扩展的CML支持（如TF-DF、Hummingbird）仅覆盖部分模型或硬件，且未充分挖掘CML特性优化潜力。例如，TF-DF仅支持CPU，Hummingbird虽支持GPU但未针对CML算子设计专用优化。  
- **根源**:  
  1. **技术瓶颈**: 直接复用DL抽象导致模型表达能力受限（如无法处理条件分支）。  
  2. **设计缺陷**: 现有方案多为临时性实现（ad-hoc），未系统化解决泛用性与性能的统一问题。  

### 补充说明：  
论文通过提出**统一抽象层（算子表示+扩展计算图ECGs）**和**编译器框架**直接应对上述挑战，其核心创新在于将CML模型转换为DL兼容的中间表示，从而复用成熟的DL编译器生态（如TVM），实现跨硬件部署与优化。