### 实验设计总结：

1. **核心目标**:  
   - 验证生成式自动调优技术（GC）在Polybench和Exascale基准测试中的有效性，特别是在少样本迁移学习（few-shot TL）场景下的性能。  
   - 比较GC与现有自动调优方法（如贝叶斯优化BO、GPTune）的优劣，重点关注搜索空间剪枝、条件采样和性能提升效率。  
   - 分析GC在复杂大规模搜索空间（如Exascale应用）中的适应能力，以及其对部分优化代码的改进潜力。

2. **数据集**:  
   - **Polybench基准套件**：包含多种计算内核任务（如3mm、Covariance、LU、Floyd-Warshall等），特点是搜索空间较小且优化目标明确，用于验证GC在典型场景下的高效性。  
   - **Exascale小型应用基准**（如AMG、XSBench、SW4Lite）：搜索空间比Polybench大数个数量级，参数间交互复杂，代表实际高性能计算中的调优挑战。其中SW4Lite还涉及GPU硬件优化。

3. **关键设置**:  
   - **评估预算**：GC在有限评估次数内（如30次）进行少样本调优，对比其他方法在相同预算下的表现。  
   - **搜索空间剪枝**：通过条件采样和分布迁移技术减少无效探索，优先高质量候选配置。  
   - **性能指标**：以加速比（speedup）为核心指标，对比GC与其他方法的峰值性能和平均表现。  
   - **鲁棒性测试**：通过多随机种子实验验证GC的稳定性，并在极端案例（如Syr2k XL任务）中暴力枚举验证全局最优逼近能力。  

---  
### 结构化补充说明：
- **技术优势**：GC通过先验知识直接生成高性能配置，避免了传统方法（如BO/GPTune）因模型迭代导致的低效探索。  
- **局限性**：在超大预算或参数默认值已接近最优时（如Exascale的循环分块参数），GC改进空间有限；此时建议作为迭代技术的初始化工具。