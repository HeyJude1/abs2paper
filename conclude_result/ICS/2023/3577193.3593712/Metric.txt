根据论文内容，以下是关于度量指标选取策略的结构化总结：

---

### 度量指标总结

#### 1. 评估指标  
**a) 加速比（Speedup）**  
- **衡量方面**：比较优化技术（GC）与基线方法（如GPTune、BO）在任务执行时间上的性能提升倍数。例如，3mm XL任务中GC实现12.81倍加速比（33.39× vs. 20.58×）。  
- **细分场景**：包括首次评估（first evaluation）结果、预算内最佳评估（peak speedup within budget）以及与其他技术的峰值性能对比（如GC的峰值性能与基线差距≤5.5%）。  

**b) 评估效率（Evaluation Efficiency）**  
- **衡量方面**：通过配置采样质量（如“近最优评估比例”）和预算利用率（如“在预算内达到最佳性能的概率”）反映方法的收敛速度。例如，GC在Syr2k XL任务中所有评估均为近最优，而其他方法需多次探索低效区域。  

**c) 一致性（Consistency）**  
- **衡量方面**：在复杂任务（如Floyd-Warshall、LU）中，GC生成结果的稳定性。例如，即使面对不确定的优化信号，GC仍能输出高一致性的性能提升。  

**d) 性能边际（Performance Margin）**  
- **衡量方面**：与基线方法的最优结果差距上限。例如，在Exascale任务中，GC配置的性能最差仅比GPTune低2%。  

#### 2. 选取理由  
论文选择的指标综合覆盖了以下关键维度：  
1. **技术有效性验证**：加速比直接量化性能提升，是优化技术的核心目标；首次评估和预算内表现则体现方法的快速收敛能力。  
2. **鲁棒性评估**：通过一致性指标和性能边际，验证GC在复杂场景（如超大搜索空间、GPU硬件）下的稳定性和泛化性。  
3. **对比公平性**：所有指标均与基线方法（BO、GPTune）对比，确保实验结论的客观性。例如，通过随机采样阶段的性能差异分析GPTune的优势场景。  
4. **实际应用导向**：Exascale任务的指标设计考虑了现实调优场景的限制（如参数默认值已较优），避免过度依赖理论最优值。  

--- 

### 补充说明  
论文未显式列出传统分类指标（如Accuracy），因其研究问题聚焦于系统级性能优化而非模型预测质量。所选指标紧密贴合自动调优（autotuning）领域核心挑战——**高效探索高维参数空间并最大化硬件利用率**。