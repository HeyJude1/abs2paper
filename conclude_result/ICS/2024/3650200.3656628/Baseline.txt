### Baseline选取总结：

1. **对比方法**:
   - **BERT-large (940Mbps)**  
   - **1D-tiled WS (Weight-Slicing) manner**  
   - **2D-tiled WS manner**  
   - **CoEdge**  
   - **Serial execution (Local inference)**  

2. **选取理由**:  
   作者选择的Baseline涵盖了以下关键技术路线和代表性方法：  
   - **经典与SOTA方法**：  
     - BERT-large作为经典的大规模Transformer模型，是自然语言处理领域的基准模型之一，其性能表现具有广泛参考价值。  
     - 1D/2D-tiled WS是现有研究中针对Transformer模型并行推理的主流方法（如Megatron-LM等），代表了基于权重切片（Weight-Slicing）的技术路线。  
     - CoEdge是面向异构边缘设备的动态分区框架（CNN领域SOTA），用于对比动态分区算法的优劣。  
   - **技术多样性覆盖**：  
     - 1D-tiled WS和2D-tiled WS分别代表不同并行策略（一维与二维权重分割），可验证Hepti在通信开销和计算效率上的改进。  
     - Serial execution作为非并行化的基线，用于量化并行方法的性能增益。  
   - **针对性对比需求**：  
     - 与BERT-large和WS方法的对比突出Hepti在通信优化（如减少数据传输量）和计算效率（如减少加法操作）上的优势。  
     - 与CoEdge的对比验证Hepti动态分区算法在异构环境（网络带宽、内存变化）下的适应性优势。  

**补充说明**：论文还隐含了与相关工作（如DeepThings、MoDNN等CNN并行方法）的间接对比，但实验部分未直接纳入，因其仅适用于CNN架构而非Transformer模型。