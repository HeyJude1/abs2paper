相关工作总结：

1、现有方法一：**输入张量数据分布式推理（DeepThings、MoDNN、CoEdge、EdgeFlow）**
核心思想: 
- DeepThings通过分配输入张量数据的感受野，实现卷积层的独立推理；
- MoDNN采用贪心算法划分卷积层和全连接层的输入张量，按设备算力分配负载；
- CoEdge提出异构设备自适应负载划分技术，综合考虑计算资源和网络带宽；
- EdgeFlow基于DAG模型重构分区方法，通过分析模型图的输入输出关系分配层操作。
主要局限性: 
- 上述方法均针对CNN架构设计，未考虑Transformer等非CNN模型的并行需求；
- 分区策略对动态网络条件和设备异构性的适应性不足（仅CoEdge部分涉及）。

2、现有方法二：**Transformer模型并行（Megatron-LM）**
核心思想: 
- 利用矩阵乘法并行（Mat-Mul）分析Transformer运算行为；
- 通过算子级并行实现单层内的计算加速。
主要局限性: 
- 缺乏针对异构设备网络条件和计算能力的动态分区算法；
- 仅支持层内并行，无法有效利用跨层流水线机会。

3、现有方法三：**跨层流水线并行（PipeEdge）**
核心思想: 
- 将输入批次划分为微批次（micro-batches）；
- 在多设备间建立执行流水线，实现层间并行。
主要局限性: 
- 论文未明确提及该方法是否解决了动态资源调度问题；
- 对微批次划分粒度与延迟/吞吐量的权衡关系缺乏理论分析。

研究缺口：
1. CNN并行方法无法直接迁移至Transformer架构
2. 现有Transformer并行方案缺乏：
   - 异构设备感知的动态分区机制
   - 层内与层间并行的协同优化
3. 边缘环境下网络波动与计算资源变化的适应性不足