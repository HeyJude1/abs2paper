### 实验结果分析总结

#### 1、主要发现:  
- **性能优势显著**：  
  - **异构设备映射（Heterogeneous Device Mapping）**：在NVIDIA GPU上达到93.7%准确率和0.94 F1-score，AMD GPU上达到93.6%准确率和0.92 F1-score，均优于或等效于现有方法。静态映射的性能提升（speedups）为1.28×（NVIDIA）和2.24×（AMD），接近理论最优值（oracle speedups）。  
  - **线程粗化（Thread Coarsening）**：在所有测试设备（AMD Radeon 5900、Tahiti 7970，NVIDIA GTX 480、Tesla K20c）上均优于基线方法，几何平均加速比显著提升。  
  - **循环向量化（Loop Vectorization）**：相比LLVM默认启发式方法，平均加速比达1.32×。  
  - **OpenMP参数调优**：与当前最优方法（PnP Tuner）性能相当或更优，且无需训练复杂GNN模型。  
  - **NUMA/Prefetcher优化**：在SandyBridge和Skylake处理器上，错误率分别降低15%和29%，且仅需5%的训练数据。  

#### 2、消融研究结论:  
- **多模态关键性**：  
  - **设备映射任务**：移除代码图模态（Modality 2）导致性能显著下降（NVIDIA下降37%，AMD下降14%），而仅使用代码图时性能下降较小（8%/4%），表明代码语义对设备选择至关重要。  
  - **线程粗化任务**：仅使用IR文本模态时性能下降5%，仅使用代码图时下降11.7%，说明两种模态互补性强。  
  - **循环向量化任务**：单一模态导致性能下降12%-30%，验证了多模态联合建模的必要性。  

#### 3、其他分析洞察:  
- **计算效率优势**：  
  - **免微调设计**：直接使用预训练模型的嵌入（inference模式）结合简单MLP层即可达到高性能，相比微调全模型节省238倍训练时间，且性能损失<5%。  
  - **模型轻量化**：预训练模型仅2200万参数（远小于亿级参数的LLMs），单GPU可训练，显著降低资源需求。  
- **案例研究启示**：  
  - **代码语义依赖**（如`makea`内核）：代码图能更好捕捉函数调用依赖等语义信息，而纯NLP风格模型难以理解此类结构。  
- **参数敏感性**：在OpenMP调优中，动态修改运行时参数（线程数、调度策略等）对整体应用加速比影响显著，验证了嵌入的泛化能力。  

---  
### 结构化亮点提炼  
| **实验任务**               | **关键指标提升**                          | **核心优势**                                |  
|---------------------------|------------------------------------------|--------------------------------------------|  
| 异构设备映射              | 准确率↑93.7%，加速比1.28×-2.24×         | 多模态联合编码优于纯文本/图方法            |  
| NUMA/Prefetcher优化       | 错误率↓15%-29%（数据量仅需5%）          | 预训练嵌入大幅减少数据需求                 |  
| OpenMP调优                | 速度等效PnP Tuner，训练开销↓238×        | MLP层轻量化设计 vs GNN复杂模型             |