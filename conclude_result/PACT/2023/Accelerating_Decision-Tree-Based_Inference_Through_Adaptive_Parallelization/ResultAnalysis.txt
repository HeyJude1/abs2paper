实验结果分析总结：

1、主要发现:  
- 本文提出的OBF和ODF预测方案在所有测试的批量大小范围内均显著优于XGBoost、LightGBM、Scikit-Learn和ONNX Runtime等基线方法。  
- 单样本预测性能提升1-2个数量级，长批量预测性能提升2-10倍（具体取决于模型）。  
- AVX2实现的OBF/ODF平均比ONNX Runtime快4倍以上，比lleaves快3倍；AVX-512实现比AVX2进一步提速约1.5倍。  
- OBF/ODF在所有模型中实现了最小的序列化模型大小。

2、消融研究结论:  
- 并行化组件的关键作用：  
  - 仅使用AVX2或AVX-512 SIMD向量化分别带来约2倍和3倍的性能提升。  
  - 仅使用多线程可提升约6倍性能。  
  - SIMD向量化与多线程结合时，AVX2和AVX-512分别实现11.4倍和14.2倍的加速（平均值）。  
- 动态预测函数选择机制被证明对性能优化至关重要，特别是在不同批量大小和硬件配置下自动选择最优并行策略。

3、其他分析洞察:  
- **缓存行为分析**：多线程树遍历可能引发缓存冲突（"抖动"），其影响程度取决于并行遍历数量、树大小和活跃路径数（如图中热力图所示）。当树遍历并行处理多个输入样本时，样本特征数量和访问模式也会影响缓存冲突。  
- **参数敏感性**：  
  - Scikit-Learn随机森林模型在单线程模式下表现更好（与多线程相比）。  
  - 短批量场景下，采用SIMD向量化并行处理多树的预测函数（ti/it）表现最优；而同时启用多线程的树循环（Ti/iT）会因缓存冲突导致性能下降。  
- **延迟分布特性**：短批量的延迟变异系数最高（1.2），随着批量增大逐渐降低（长批量为0.027），95/99百分位延迟分别比平均值高28%/67%（短批量）和4.5%/4.8%（长批量）。  

关键创新点验证：动态预测函数选择机制结合OBF/ODF结构设计，成功解决了传统决策树推理在实时单样本预测和模型紧凑性方面的瓶颈问题。