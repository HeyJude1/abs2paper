### 度量指标总结：

#### 1. 评估指标：
- **峰值内存使用量（Peak Memory Usage）**：衡量并行训练过程中所有GPU的最大内存占用，反映系统对硬件资源的利用效率。
- **内存占用减少百分比（Memory Reduction Percentage）**：对比CAPTURE与Alpa的峰值内存差异，量化内存优化效果。
- **吞吐量损失（Throughput Loss）**：衡量因内存优化导致的训练速度下降，反映性能与资源占用的权衡。
- **预测误差分布（Prediction Error Distribution）**：统计CAPTURE对内存使用的预测精度（如2%、5%、11%误差区间内的预测比例），验证其模型的可靠性。
- **运行时开销（Runtime Overhead）**：记录CAPTURE与Alpa生成并行化计划的时间，评估算法实用性。

#### 2. 选取理由：
1. **核心目标匹配**：论文的核心贡献是优化混合并行训练的内存占用，因此**峰值内存使用量**和**内存减少百分比**直接体现CAPTURE的优化能力。  
2. **权衡分析需求**：通过**吞吐量损失**指标，明确揭示内存优化与计算效率的权衡关系（如牺牲11.5%-42.4%吞吐量换取18.4%-43.9%内存节省）。  
3. **技术验证严谨性**：  
   - **预测误差分布**验证了CAPTURE模型的准确性（97.1%的GPU级预测误差在11%以内），支持其方法的可靠性。  
   - **运行时开销**证明算法实用性（尽管CAPTURE耗时更长，但相比数周的模型训练可忽略不计）。  
4. **场景覆盖全面性**：指标覆盖不同并行策略（1F1B/GPipe）、模型架构（GPT-3/MoE/Wide-ResNet）和硬件配置（6/8/16 GPUs），确保结论普适性。  

### 结构化补充说明：
- **隐含指标逻辑链**：  
  峰值内存优化 → 允许更小硬件配置 → 通过吞吐量实验验证资源效率提升（如6 GPUs下吞吐量反增36.3%）。  
- **未选指标原因**：  
  论文明确指出模型统计性能不受并行化策略影响，故未包含准确率等传统ML指标。