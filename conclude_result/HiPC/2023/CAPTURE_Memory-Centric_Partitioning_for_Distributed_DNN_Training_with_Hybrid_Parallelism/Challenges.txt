### 核心挑战总结：

#### 挑战一：**内存瓶颈与资源限制**  
**分析**:  
- **问题表现**: 训练大规模DNN时，模型参数、激活值和梯度的存储需求远超单个GPU内存容量，即使采用混合并行（流水线/数据/张量并行）也难以完全解决。  
- **根源**:  
  1. **模型复杂性**: NLP和图像处理模型的参数量激增，导致内存需求指数增长。  
  2. **批大小限制**: 流水线并行需要微批次（microbatches），数据并行需要足够大的批次以维持硬件利用率，但增大批次会进一步增加内存压力。  
  3. **硬件约束**: 低成本云实例（如spot-VMs）缺乏高带宽互联，限制了张量并行的通信效率，加剧了内存不均衡问题。  

#### 挑战二：**混合并行中的内存不均衡**  
**分析**:  
- **问题表现**: 现有混合并行框架（如Alpa、Varuna）的划分策略以吞吐量为导向，导致不同GPU间的峰值内存使用不均衡，部分节点成为瓶颈。  
- **根源**:  
  1. **划分策略缺陷**: 现有方法仅基于简单指标（如参数量或层数）划分流水线阶段，未考虑各阶段内存需求的动态差异（如权重与激活值的比例）。  
  2. **并行模式交互影响**: 流水线、数据和张量并行的组合会引入额外通信开销（如allreduce操作），进一步扰乱内存分布。  

#### 挑战三：**通用性与自动化划分的缺失**  
**分析**:  
- **问题表现**: 当前系统（如Megatron-LM、Merak）专用于特定模型（如Transformer），缺乏通用的自动化划分工具；Alpa虽支持灵活划分，但未优化内存平衡。  
- **根源**:  
  1. **技术局限性**: 现有方法依赖静态规则或人工调优，无法动态预测不同并行策略的内存影响。  
  2. **框架依赖性**: 各系统实现差异大（如Varuna不支持张量并行），导致通用解决方案难以开发。  

---  
### 补充说明：  
论文提出的CAPTURE方法通过**基于分析的统计建模**和**分层内存分析**直接应对上述挑战：  
1. 针对挑战一，引入微批次内存预测和硬件无关的配置推荐；  
2. 针对挑战二，采用贝叶斯优化搜索均衡划分方案；  
3. 针对挑战三，实现框架无关的通用分析器（支持Alpa/Varuna）。