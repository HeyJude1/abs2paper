实验设计总结：  

1、核心目标:  
- 验证CAPTURE在混合并行训练（流水线并行与张量并行结合）中的内存优化效果。  
- 比较CAPTURE与Alpa框架在峰值内存占用和吞吐量上的性能差异。  
- 评估CAPTURE对内存使用预测的准确性（针对不同并行策略和调度方案）。  

2、数据集:  
- **随机生成数据**（基于Alpa的基准测试套件）：用于模拟典型输入维度，避免真实数据对优化结果（如激活值压缩）的干扰，作为性能与内存占用的最坏情况测试场景。  
- **模型数据集**：  
  - **GPT-3**：大规模语言模型。  
  - **GShard Mixture-of-Experts (MoE)**：稀疏混合专家模型。  
  - **Wide-ResNet**：宽残差网络，用于图像任务。  

3、关键设置:  
- **硬件环境**：4个计算节点，每节点配备4块NVIDIA A100 GPU（40GB HBM2显存），通过100Gbps InfiniBand互联。  
- **软件栈**：Alpa 0.2.3、JAX 0.3.22、CUDA 11.3。  
- **实验配置**：  
  - **并行策略**：混合并行（流水线+张量并行）与纯流水线并行对比，测试两种调度方案（1F1B和GPipe）。  
  - **评测指标**：峰值内存占用、吞吐量损失、预测误差（针对500种随机采样的并行计划）。  
  - **训练迭代**：仅运行2次迭代以缩短分析时间，使用随机输入数据保证结果泛化性。  
  - **自动化工具对比**：Alpa的自动分层（autolayering）与自动分阶段（autostaging）功能 vs. CAPTURE的层合并（layer merger）与剪枝优化。  

结构化补充说明：  
- **内存优化验证**：CAPTURE通过动态调整并行计划，在GPT-3、MoE和Wide-ResNet上实现峰值内存降低5.64%-43.92%，但需权衡吞吐量损失（11.5%-60%）。  
- **预测准确性**：97.1%的GPU级内存预测误差在11%以内，但1F1B调度因未动态调整位置相关内存行为导致部分高估/低估。