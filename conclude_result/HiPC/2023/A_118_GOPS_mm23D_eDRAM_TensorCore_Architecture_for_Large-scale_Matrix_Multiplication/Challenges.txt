核心挑战总结：

挑战一：**计算资源与能效瓶颈**  
分析: 现有大型Transformer和NeRF模型的计算需求极高（如1750亿参数、数百petaflops算力），而当前加速器架构受限于芯片面积和功耗密度，难以提供足够的计算吞吐量。根源在于：  
1. 传统方案依赖片外DRAM访问和集中式矩阵乘法单元，导致内存墙问题；  
2. 片上内存占用大量面积，挤压了计算单元的空间；  
3. 现有技术（如SIMD近HBM方案）仍无法满足算法侧快速变化的需求。  

挑战二：**3D内存计算的精度与性能权衡**  
分析: 采用单片3D集成eDRAM进行存内计算时面临：  
1. **精度问题**：2T单元设计因未选通单元的漏电流导致读位线（RBL）电压摆幅受限，影响计算准确性；  
2. **并行性限制**：传统内积数据流（inner-product）无法充分利用3D结构的并行潜力，且存在读写冲突；  
3. **工艺约束**：IGZO晶体管的BEOL集成需解决低温处理、晶体管泄漏等问题，同时需保证高写入耐久性（10^6次以上）和低写入能耗（~1pJ）。  

挑战三：**异构计算架构的协同设计**  
分析: 构建高效eDRAM张量核需解决多层级协同问题：  
1. **数据流适配性**：需开发支持INT8/BF16混合精度的外积数据流（outer-product），以实现全RBL摆幅和无泄漏累积；  
2. **数字-模拟接口**：部分和转换为数字域时，需设计低功耗ADC和基于IGZO的BEOL逻辑电路（如P/N器件互补逻辑），但当前工艺实现难度大；  
3. **系统集成瓶颈**：缓存、数据通路与DRAM访问组件的协同优化需平衡带宽需求与能效，尤其针对NeRF和LLaMA等动态负载。  

根源总结：上述挑战源于模型规模指数增长与硬件扩展性之间的根本矛盾，以及存内计算中模拟计算精度与数字控制灵活性的内在冲突。现有技术（如RRAM/CAM）在写入耐久性和能效上的不足进一步凸显了eDRAM方案的必要性与复杂性。