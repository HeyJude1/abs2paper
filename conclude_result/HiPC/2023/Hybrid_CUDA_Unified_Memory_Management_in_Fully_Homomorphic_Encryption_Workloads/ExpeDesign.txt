实验设计总结：

1、核心目标:  
- 验证三种内存管理方案（动态、静态、性能分析分配器）在不同GPU硬件上的性能表现  
- 分析异步内存分配阈值对同态加密操作（特别是bootstrapping和ResNet推理）的影响  
- 比较方案侵入性（代码修改程度）与性能收益的平衡关系  

2、数据集:  
- **BM-bootstrap**：包含连续bootstrapping操作的基准测试，涉及参数/密钥切换（约80GB内存占用）  
- **Homomorphic ResNet**：同态加密版本的预训练深度学习模型，测试推理阶段性能（约200GB内存占用）  
- **自定义HE函数测试集**：针对FGa/FGb/FVb等不同参数集的同态加密函数测试  

3、关键设置:  
- **硬件平台**：  
  - 高端：NVIDIA A40 (48GB VRAM) - 仅测试最优的性能分析方案  
  - 中端：GeForce GTX 1660 Ti (6GB VRAM)  
  - 低端：GeForce GTX 1050 (2GB VRAM)  
- **软件环境**：CUDA 12 + HEaaN库（C++定制修改），Python后处理脚本用于性能分析方案  
- **核心参数**：  
  - 异步内存分配阈值（A40：40-65%，1660Ti/1050：68%）  
  - 方案侵入性梯度：动态分配器（仅修改内存分配器）< 性能分析 < 静态方案（手动修改库代码）  
- **对比基线**：全托管内存方案（作为性能下限）、手动交换方案（红色基准线）  

结构化特点说明：实验采用阶梯式验证策略，高端GPU侧重大数据集验证最优方案，中低端GPU全面对比三种方案在不同参数规模下的表现，并通过阈值调优建立量化性能关系。