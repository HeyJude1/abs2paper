### 核心挑战总结：

#### 挑战一：**深度神经网络（DNNs）在移动和嵌入式设备上的部署困难**  
**分析**:  
- **问题表现**: DNNs的模型规模和计算复杂度急剧增长（例如Google的Switch Transformer拥有1.6万亿参数，需TB级存储和大量浮点运算），而移动/嵌入式设备的片上内存和计算资源有限。  
- **根源**:  
  1. **模型规模与性能的权衡**: 更高的准确性通常需要更多参数，但导致存储、数据传输和计算成本飙升。  
  2. **硬件限制**: 当前芯片的片上内存不足，频繁的片外内存访问成为能耗主要来源。  

#### 挑战二：**现有量化技术的精度与效率难以平衡**  
**分析**:  
- **问题表现**:  
  - **均匀量化（如INT8）**虽能降低存储和计算开销，但进一步降低位宽（如<8位）会导致显著精度损失。  
  - **非均匀量化（如对数量化LQ）**虽能压缩模型并简化硬件（如用移位代替乘法），但其固定的基（如基2）无法适配张量的实际分布，引入不可补偿的误差。  
- **根源**:  
  1. **分布适配不足**: 现有方法未充分考虑张量的非均匀分布特性（如接近指数分布）。  
  2. **重训练需求**: 部分方法（如APoT）需代价高昂的重训练以恢复精度。  

#### 挑战三：**稀疏性与硬件支持的开销矛盾**  
**分析**:  
- **问题表现**:  
  - **剪枝技术**通过移除冗余权重压缩模型，但需重训练恢复精度，且稀疏模型需复杂硬件解码支持。  
  - **混合精度方案**虽能动态分配位宽，但仍依赖均匀量化，无法彻底解决精度-效率矛盾。  
- **根源**:  
  1. **通用性不足**: 现有方法（如Mokey）仅针对特定模型（如Transformer），难以推广到其他DNN架构。  
  2. **额外处理成本**: 部分方案需后处理步骤（如离群值计算），增加实现复杂度。  

### 总结：
论文的核心挑战源于DNN模型规模膨胀与硬件资源限制的矛盾，以及现有量化技术对非均匀分布适配不足、重训练依赖性和硬件兼容性问题。作者提出的DNA-TEQ方法旨在通过自适应指数量化解决这些挑战，实现无需重训练、低硬件复杂度的高效部署。