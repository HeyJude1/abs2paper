### 度量指标总结：

#### 1、评估指标:
- **Speedup (加速比)**: 衡量优化技术相对于基准方法或原始代码的性能提升倍数，直接反映调优效果的核心指标。
- **Evaluation Budget Utilization (评估预算利用率)**: 衡量在限定评估次数内达到最优解的能力，体现算法在少样本场景下的效率。
- **Performance Margin (性能边际差)**: 与其他方法最优解的百分比差距（如文中提到的2%），用于横向对比不同技术的稳定性。
- **First Evaluation Performance (首次评估性能)**: 衡量算法在初始样本中的表现，反映先验知识迁移的有效性。
- **Consistency of Evaluations (评估一致性)**: 通过"避免低效评估"等描述体现，衡量算法输出结果的稳定性。

#### 2、选取理由:
论文选取的指标体系具有多维覆盖性和任务适配性：
1. **任务特性适配**：  
   - Polybench与Exascale任务的差异（如搜索空间规模、参数复杂性）要求同时使用绝对性能指标（Speedup）和相对鲁棒性指标（Performance Margin）。
   - 针对少样本调优场景（Few-shot TL），特别关注首次评估性能和预算利用率，以凸显算法在有限评估次数下的优势。

2. **技术优势验证**：  
   - Speedup直接验证空间剪枝（space pruning）和条件采样（conditional sampling）的有效性。
   - Consistency of Evaluations体现分布迁移策略的质量，对比传统方法（如BO/GPTune）需要探索低效区域的缺陷。

3. **对比实验需求**：  
   - Performance Margin提供量化基准，证明GC技术在极端情况下（如Exascale任务）仍能保持竞争力。
   - First Evaluation Performance突出其相比迭代式方法的差异化优势。

4. **实际应用考量**：  
   对GPU任务（SW4Lite）和隐藏参数场景（如core affinity）的指标观察，验证了黑箱特性在实际复杂系统中的适用性。

该指标体系完整覆盖了生成式自动调优技术（GC）的核心创新点——先验知识迁移效率、搜索空间压缩能力和少样本稳定性，同时满足学术严谨性与工程实用性要求。