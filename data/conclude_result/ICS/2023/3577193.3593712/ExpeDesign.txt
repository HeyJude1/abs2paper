实验设计总结：

1、核心目标:
- 验证生成式自动调优技术（GC）在Polybench和Exascale基准测试中的有效性
- 比较GC与现有技术（如GPTune和贝叶斯优化BO）的性能差异
- 评估GC在少样本迁移学习（few-shot TL）场景下的表现

2、数据集:
- Polybench基准测试套件：包含多种计算内核（如3mm、Covariance、LU等），用于测试自动调优技术在不同计算模式下的表现
- Exascale小型应用基准测试：包含更复杂的应用（如AMG、XSBench、SW4Lite等），具有更大的搜索空间和更复杂的参数交互

3、关键设置:
- 采用条件采样进行分布转移和搜索空间剪枝
- 对所有实验使用相同数量的源任务评估，确保迁移学习条件一致
- 在Syr2k XL任务上进行暴力搜索以验证全局最优性
- GPU加速测试（SW4Lite基准测试）
- 评估预算设置：当预算未定义时使用最大评估次数，同时测试固定预算下的表现