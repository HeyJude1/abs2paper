根据提供的论文内容，以下是关于Baseline选取策略的总结：

---

**Baseline选取总结：**

1. **对比方法:**  
   - **GPTune**  
   - **BO（Bayesian Optimization）**  
   - **BLISS**  
   - **Active Harmony**  
   - **ANGEL**  
   - **ParEGO**  

2. **选取理由:**  
   - **技术代表性**:  
     - GPTune和BO是当前最先进的（SOTA）自动调优方法，分别基于机器学习（如高斯过程）和贝叶斯优化框架，广泛用于少样本迁移学习（few-shot TL）场景。  
     - BLISS、Active Harmony、ANGEL和ParEGO代表多目标优化或大规模调优的经典方法，侧重于长期收敛性或帕累托前沿优化，与本文的“少样本快速调优”目标形成对比。  
   - **性能基准覆盖**:  
     - GPTune和BO作为核心对比对象，因其在Polybench和Exascale任务中的广泛使用，能够验证本文提出的GC（Generative Conditional Sampling）技术在搜索空间剪枝和快速收敛上的优势。  
     - 其他方法（如BLISS）被引用以说明传统TL调优在数据泛化和成本模型重建上的局限性。  
   - **实验场景适配性**:  
     - 在Exascale任务中，作者强调搜索空间复杂度剧增的挑战，因此选择GPTune和BO这类需迭代探索的方法作为基准，突出GC在少样本下的稳定性。  

--- 

**关键依据提取：**  
1. 论文明确提到GC与GPTune、BO的直接对比结果（如3mm XL任务中12.81倍加速比优势）。  
2. 相关工作部分指出，BLISS等方法因“难以泛化小数据集”或“长期收敛优先”被排除为少样本场景的理想基准。  
3. 实验设计强调“相同调优预算”下的公平性（如5.1节），进一步说明选择SOTA方法的必要性。  

此总结完全基于论文中明确的对比实验和相关工作论述，未引入外部假设。